# 🧠 AI对话代理自动化评估平台

## 🎯 平台概览
本平台是一个用于评估对话式 AI 助手在“实际业务目标 + 用户期望”下是否有效的评估系统，特别适配建筑工程等行业场景。

通过上传需求文档、配置被测 AI API，平台将自动解析上下文，模拟用户对话，并使用 DeepSeek 进行智能打分，生成完整的交互记录与专业报告。

---

## 📌 简洁流程图

```
前端上传需求文档 + 配置被测AI
      ↓
DeepSeek 分析员：
    解读需求 → 提取使用目标与用户画像
      ↓
DeepSeek 模拟用户：
    构造任务对话 → 向被测AI发起多轮交互
      ↓
DeepSeek 评估员：
    分析对话表现 → 打分 → 生成自然语言评语
      ↓
输出结果：
    完整对话记录 + 多维评分报告 + 改进建议
```

---

## 🔧 平台能力模块

| 模块          | 描述 |
|---------------|------|
| 📄 需求文档上传 | 提供上下文，让评估模型理解目标与用户 |
| 🔗 API配置     | 被测AI需提供标准HTTP POST接口 |
| 🤖 多轮对话模拟 | 自动模拟2~3轮任务型对话 |
| 🧠 DeepSeek评分 | 从4个维度给出1–5星评分并生成自然语言报告 |
| 📊 报告输出     | JSON结构，可导出，包含建议与评语 |

---

## 🧪 评估维度（每项1~5星）

| 维度           | 说明 |
|----------------|------|
| 🔍 模糊理解能力   | 能否理解模糊输入并主动追问补充 |
| ✅ 回答正确性     | 回答是否满足业务知识点、清晰完整 |
| 👤 用户画像匹配度 | 是否贴近目标用户的语言风格与表达方式 |
| 🎯 使用目标达成度 | 是否满足文档中定义的实际使用目标 |

---

## 🚀 快速开始

### 安装依赖
```bash
pip install fastapi httpx pydantic uvicorn
```

### 启动本地服务
```bash
uvicorn main:app --reload
```

---

## 📬 API接口说明

### POST `/api/evaluate-agent`

**请求示例**
```json
{
  "agent_api": {
    "url": "https://your-agent.com/api/converse"
  },
  "requirement_doc": "监理人员需要通过AI快速记录施工现场问题，语言简洁，自动补全责任单位。",
  "conversation_scenarios": [
    {
      "title": "墙面空鼓问题",
      "turns": [
        "三楼有个地方空鼓了",
        "是墙面",
        "差不多两平米"
      ]
    }
  ]
}
```

**响应示例**
```json
{
  "overall_score": 4.8,
  "dimensions": {
    "fuzzy_understanding": 5,
    "answer_correctness": 5,
    "persona_alignment": 4,
    "goal_alignment": 5
  },
  "comment": "AI 理解模糊输入良好，语气自然贴近监理，但未明确责任单位。",
  "suggestions": ["建议主动询问责任单位", "结构化输出建议更明确"]
}
```

---

## 💼 使用场景

- 🔍 验证AI是否满足业务目标（而不只是生成“看起来合理”的回答）
- 📊 多版本对话质量对比测试（A/B）
- 🧪 模型训练前后表现监控
- 🏗 面向建筑、制造、客服等真实用户的 AI 产品质量保障

---

## ✅ 平台核心价值

> 从用户目标、交互预期出发，构建可复用、高一致性的 AI 对话质量评估流程，助力企业构建可靠的 AI 产品。