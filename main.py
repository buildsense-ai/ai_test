import asyncio
import uvicorn
from fastapi import FastAPI, Request, HTTPException, UploadFile, File, Form
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field
from typing import Optional, Dict, Any, List
import httpx
import json
from datetime import datetime
import socket
from enum import Enum
import io
import os
import re
import tempfile
import logging
import traceback
import uuid
import hashlib
import time

# Database imports
try:
    import pymysql
    PYMYSQL_AVAILABLE = True
except ImportError:
    PYMYSQL_AVAILABLE = False
    print("âš ï¸ PyMySQL not available. Database features disabled.")

# Coze SDK imports
try:
    from cozepy import COZE_CN_BASE_URL
    from cozepy import Coze, TokenAuth, Message, ChatStatus, MessageContentType, ChatEventType
    COZE_SDK_AVAILABLE = True
except ImportError:
    COZE_SDK_AVAILABLE = False
    print("âš ï¸ Coze SDK not available. Using fallback HTTP requests.")

# Import configuration
import config

# â­ Memory monitoring
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    print("âš ï¸ psutil not available, memory monitoring disabled")

# Set up logging for better debugging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Add enhanced debugging for cloud deployment issues
import traceback
import logging

# Set up detailed logging for debugging cloud deployment issues
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

def check_memory_usage():
    """Check memory usage and prevent OOM crashes"""
    if not PSUTIL_AVAILABLE:
        print("âš ï¸ psutil not available, skipping memory check")
        return 0  # Return 0 instead of None for compatibility
    
    try:
        memory_percent = psutil.virtual_memory().percent
        if memory_percent > config.MEMORY_CRITICAL_THRESHOLD:
            error_msg = f"æœåŠ¡å™¨å†…å­˜ä½¿ç”¨ç‡å±é™©: {memory_percent:.1f}%"
            print(f"âŒ {error_msg}")
            raise HTTPException(status_code=507, detail=f"æœåŠ¡å™¨å†…å­˜ä¸è¶³ ({memory_percent:.1f}%)ï¼Œè¯·ç¨åé‡è¯•")
        
        if memory_percent > config.MEMORY_WARNING_THRESHOLD:
            print(f"âš ï¸ å†…å­˜ä½¿ç”¨ç‡è­¦å‘Š: {memory_percent:.1f}%")
        
        return memory_percent
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"âš ï¸ å†…å­˜æ£€æŸ¥å¤±è´¥: {str(e)}")
        return 0  # Return 0 instead of None for compatibility

# Document processing imports
try:
    import docx
    from PyPDF2 import PdfReader
    DOCUMENT_PROCESSING_AVAILABLE = True
except ImportError:
    DOCUMENT_PROCESSING_AVAILABLE = False

app = FastAPI(title="AI Agent Evaluation Platform", version="4.0.0")

# Add response compression middleware
from fastapi.middleware.gzip import GZipMiddleware
app.add_middleware(GZipMiddleware, minimum_size=1000)

# Create static directory if it doesn't exist
static_dir = "static"
if not os.path.exists(static_dir):
    os.makedirs(static_dir)

# Mount static files
app.mount("/static", StaticFiles(directory="static"), name="static")

templates = Jinja2Templates(directory="templates")

# Improved document processing functions based on user's approach
def read_docx_file(filepath: str) -> str:
    """Read content from DOCX file with enhanced cloud compatibility"""
    try:
        logger.info(f"ğŸ“– å¼€å§‹è§£æDOCXæ–‡ä»¶: {filepath}")
        print(f"ğŸ“– å¼€å§‹è§£æDOCXæ–‡ä»¶: {filepath}")
        
        # Check if file exists and is readable
        if not os.path.exists(filepath):
            error_msg = f"æ–‡ä»¶ä¸å­˜åœ¨: {filepath}"
            logger.error(error_msg)
            return f"é”™è¯¯ï¼š{error_msg}"
        
        file_size = os.path.getsize(filepath)
        logger.info(f"ğŸ“„ æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
        print(f"ğŸ“„ æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
        
        if file_size == 0:
            error_msg = "æ–‡ä»¶ä¸ºç©º"
            logger.error(error_msg)
            return f"é”™è¯¯ï¼š{error_msg}"
        
        # Cloud-compatible processing with multiple fallback methods
        extraction_methods = [
            ("python-docx", lambda: _extract_with_python_docx(filepath)),
            ("zip-xml-advanced", lambda: _extract_with_zip_xml_advanced(filepath)),
            ("zip-xml-simple", lambda: _extract_with_zip_xml_simple(filepath)),
            ("raw-text-extraction", lambda: _extract_raw_text_from_docx(filepath))
        ]
        
        best_result = ""
        successful_method = "none"
        
        for method_name, extraction_func in extraction_methods:
            try:
                logger.info(f"ğŸ”„ å°è¯•æ–¹æ³•: {method_name}")
                print(f"ğŸ”„ å°è¯•æ–¹æ³•: {method_name}")
                
                result = extraction_func()
                
                if result and len(result) > len(best_result):
                    best_result = result
                    successful_method = method_name
                    logger.info(f"âœ… {method_name} æˆåŠŸï¼Œæå–é•¿åº¦: {len(result)}")
                    print(f"âœ… {method_name} æˆåŠŸï¼Œæå–é•¿åº¦: {len(result)}")
                    
                    # If we get a good result (>100 chars), use it immediately
                    if len(result) > 100:
                        break
                else:
                    logger.warning(f"âš ï¸ {method_name} ç»“æœä¸ä½³: {len(result) if result else 0} å­—ç¬¦")
                    print(f"âš ï¸ {method_name} ç»“æœä¸ä½³: {len(result) if result else 0} å­—ç¬¦")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ {method_name} å¤±è´¥: {str(e)}")
                print(f"âš ï¸ {method_name} å¤±è´¥: {str(e)}")
                continue
        
        if not best_result:
            return "é”™è¯¯ï¼šæ‰€æœ‰è§£ææ–¹æ³•å‡å¤±è´¥ï¼Œå»ºè®®è½¬æ¢ä¸ºTXTæ ¼å¼åé‡è¯•"
        
        # Validate extraction result
        if len(best_result) < 20:
            logger.warning(f"âš ï¸ æå–å†…å®¹è¿‡çŸ­: {len(best_result)} å­—ç¬¦")
            print(f"âš ï¸ æå–å†…å®¹è¿‡çŸ­: {len(best_result)} å­—ç¬¦")
            
            if len(best_result) < 10:
                return f"é”™è¯¯ï¼šæå–å†…å®¹è¿‡çŸ­({len(best_result)}å­—ç¬¦)ï¼Œå»ºè®®è½¬æ¢ä¸ºTXTæ ¼å¼ï¼š\n\nğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š\n1. ä½¿ç”¨Wordæ‰“å¼€æ–‡æ¡£ï¼Œå¦å­˜ä¸º.txtæ ¼å¼\n2. æˆ–å¤åˆ¶æ–‡æ¡£å†…å®¹ï¼Œç›´æ¥ç²˜è´´åˆ°æ–‡æœ¬æ¡†ä¸­\n3. æ£€æŸ¥æ–‡æ¡£æ˜¯å¦åŒ…å«ä¸»è¦ä¸ºå›¾ç‰‡/è¡¨æ ¼å†…å®¹"
        
        logger.info(f"âœ… DOCXè§£ææˆåŠŸ (æ–¹æ³•: {successful_method})ï¼Œæå–é•¿åº¦: {len(best_result)} å­—ç¬¦")
        print(f"âœ… DOCXè§£ææˆåŠŸ (æ–¹æ³•: {successful_method})ï¼Œæå–é•¿åº¦: {len(best_result)} å­—ç¬¦")
        
        # Debug: Show first part of content to verify extraction
        content_preview = best_result[:200] + "..." if len(best_result) > 200 else best_result
        logger.debug(f"ğŸ“ å†…å®¹é¢„è§ˆ: {content_preview}")
        print(f"ğŸ“ å†…å®¹é¢„è§ˆ: {content_preview}")
        
        return best_result
        
    except Exception as e:
        error_msg = f"DOCXæ–‡ä»¶å¤„ç†å¼‚å¸¸: {str(e)}"
        logger.error(f"âŒ {error_msg}")
        logger.error(f"ğŸ“‹ å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
        print(f"âŒ {error_msg}")
        print(f"ğŸ“‹ å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
        return f"é”™è¯¯ï¼š{error_msg}\n\nğŸ’¡ äº‘ç¯å¢ƒè§£å†³æ–¹æ¡ˆï¼š\n1. è½¬æ¢ä¸ºTXTæ ¼å¼é‡æ–°ä¸Šä¼ \n2. å¤åˆ¶æ–‡æ¡£å†…å®¹ç›´æ¥ç²˜è´´\n3. æ£€æŸ¥æ–‡æ¡£æ˜¯å¦è¿‡äºå¤æ‚"

def _extract_with_python_docx(filepath: str) -> str:
    """Method 1: Standard python-docx extraction"""
    from docx import Document
    
    doc = Document(filepath)
    full_text = []
    
    # Extract paragraphs
    for paragraph in doc.paragraphs:
        if paragraph.text.strip():
            full_text.append(paragraph.text.strip())
    
    # Extract tables
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                if cell.text.strip():
                    full_text.append(cell.text.strip())
    
    return '\n'.join(full_text)

def _extract_with_zip_xml_advanced(filepath: str) -> str:
    """Method 2: Advanced ZIP+XML extraction with namespace handling"""
    import zipfile
    import xml.etree.ElementTree as ET
    
    with zipfile.ZipFile(filepath, 'r') as zip_file:
        # Try to get document.xml
        xml_content = zip_file.read('word/document.xml')
        
        # Parse with namespace awareness
        root = ET.fromstring(xml_content)
        
        # Define Word document namespaces
        namespaces = {
            'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main',
            'v': 'urn:schemas-microsoft-com:vml',
            'r': 'http://schemas.openxmlformats.org/officeDocument/2006/relationships'
        }
        
        text_parts = []
        
        # Extract text from paragraphs
        for para in root.findall('.//w:p', namespaces):
            para_text = ""
            for text_elem in para.findall('.//w:t', namespaces):
                if text_elem.text:
                    para_text += text_elem.text
            if para_text.strip():
                text_parts.append(para_text.strip())
        
        # Extract text from tables
        for table in root.findall('.//w:tbl', namespaces):
            for row in table.findall('.//w:tr', namespaces):
                row_text = ""
                for cell in row.findall('.//w:tc', namespaces):
                    cell_text = ""
                    for text_elem in cell.findall('.//w:t', namespaces):
                        if text_elem.text:
                            cell_text += text_elem.text
                    if cell_text.strip():
                        row_text += cell_text.strip() + " "
                if row_text.strip():
                    text_parts.append(row_text.strip())
        
        return '\n'.join(text_parts)

def _extract_with_zip_xml_simple(filepath: str) -> str:
    """Method 3: Simple ZIP+XML extraction (cloud fallback)"""
    import zipfile
    import xml.etree.ElementTree as ET
    
    with zipfile.ZipFile(filepath, 'r') as zip_file:
        xml_content = zip_file.read('word/document.xml')
        root = ET.fromstring(xml_content)
        
        # Simple text extraction - get all text elements
        text_content = []
        for elem in root.iter():
            if elem.text and elem.text.strip():
                text_content.append(elem.text.strip())
        
        # Remove duplicates while preserving order
        seen = set()
        unique_text = []
        for text in text_content:
            if text not in seen and len(text) > 1:  # Avoid single characters
                seen.add(text)
                unique_text.append(text)
        
        return ' '.join(unique_text)

def _extract_raw_text_from_docx(filepath: str) -> str:
    """Method 4: Raw text extraction from ZIP (last resort)"""
    import zipfile
    import re
    
    with zipfile.ZipFile(filepath, 'r') as zip_file:
        # Try to extract any readable text from the ZIP contents
        text_parts = []
        
        # Read document.xml as raw text and extract with regex
        try:
            xml_content = zip_file.read('word/document.xml').decode('utf-8', errors='ignore')
            
            # Use regex to find text between XML tags
            text_matches = re.findall(r'>([^<]+)<', xml_content)
            
            for match in text_matches:
                cleaned = match.strip()
                if len(cleaned) > 2 and not cleaned.isdigit():  # Skip numbers and short strings
                    text_parts.append(cleaned)
            
        except Exception:
            pass
        
        # Also try other XML files in the document
        for file_info in zip_file.filelist:
            if file_info.filename.endswith('.xml') and 'word/' in file_info.filename:
                try:
                    content = zip_file.read(file_info.filename).decode('utf-8', errors='ignore')
                    text_matches = re.findall(r'>([^<]+)<', content)
                    
                    for match in text_matches:
                        cleaned = match.strip()
                        if len(cleaned) > 2 and not cleaned.isdigit():
                            text_parts.append(cleaned)
                            
                except Exception:
                    continue
        
        # Remove duplicates and join
        unique_parts = list(dict.fromkeys(text_parts))  # Preserve order
        return ' '.join(unique_parts)

def read_pdf_file(filepath: str) -> str:
    """Read PDF document using direct file path approach"""
    try:
        if not DOCUMENT_PROCESSING_AVAILABLE:
            return "æ–‡æ¡£å¤„ç†åº“æœªå®‰è£…ï¼Œè¯·å®‰è£… PyPDF2ï¼špip install PyPDF2"
        
        with open(filepath, 'rb') as file:
            pdf_reader = PdfReader(file)
            text_parts = []
            
            for page_num, page in enumerate(pdf_reader.pages):
                text = page.extract_text()
                if text.strip():
                    text_parts.append(text.strip())
        
        # Join and clean the text
        full_text = "\n".join(text_parts)
        cleaned_text = full_text.replace("\r", "").replace("ã€€", "").strip()
        
        print(f"ğŸ“„ PDFæ–‡æ¡£æå–æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(cleaned_text)} å­—ç¬¦")
        return cleaned_text
        
    except Exception as e:
        error_msg = f"PDFæ–‡æ¡£è§£æå¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")
        return error_msg

def read_txt_file(filepath: str) -> str:
    """Read text file with proper encoding"""
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            text = f.read()
        
        # Clean the text
        cleaned_text = text.replace("\r", "").replace("ã€€", "").strip()
        
        print(f"ğŸ“„ æ–‡æœ¬æ–‡ä»¶æå–æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(cleaned_text)} å­—ç¬¦")
        return cleaned_text
        
    except UnicodeDecodeError:
        # Try with different encoding if UTF-8 fails
        try:
            with open(filepath, "r", encoding="gbk") as f:
                text = f.read()
            cleaned_text = text.replace("\r", "").replace("ã€€", "").strip()
            print(f"ğŸ“„ æ–‡æœ¬æ–‡ä»¶æå–æˆåŠŸ(GBKç¼–ç )ï¼Œå†…å®¹é•¿åº¦: {len(cleaned_text)} å­—ç¬¦")
            return cleaned_text
        except Exception as e:
            error_msg = f"æ–‡æœ¬æ–‡ä»¶è§£æå¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return error_msg
    except Exception as e:
        error_msg = f"æ–‡æœ¬æ–‡ä»¶è§£æå¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")
        return error_msg

async def process_uploaded_document_improved(file: UploadFile) -> str:
    """Process uploaded document using improved approach with comprehensive error handling"""
    if not file or not file.filename:
        logger.error("âš ï¸ æ–‡æ¡£ä¸Šä¼ ï¼šæ–‡ä»¶ä¸ºç©ºæˆ–æ— æ–‡ä»¶å")
        print("âš ï¸ æ–‡æ¡£ä¸Šä¼ ï¼šæ–‡ä»¶ä¸ºç©ºæˆ–æ— æ–‡ä»¶å")
        return "é”™è¯¯ï¼šæœªæä¾›æœ‰æ•ˆæ–‡ä»¶"
    
    # â­ Security: Validate filename
    if not validate_filename(file.filename):
        error_msg = f"ä¸å®‰å…¨çš„æ–‡ä»¶å: {file.filename}"
        logger.error(f"âŒ {error_msg}")
        print(f"âŒ {error_msg}")
        return f"é”™è¯¯ï¼š{error_msg}"
    
    # Log file info with detailed debugging
    logger.info(f"ğŸ“„ å¼€å§‹å¤„ç†ä¸Šä¼ æ–‡ä»¶: {file.filename}")
    logger.info(f"ğŸ“„ æ–‡ä»¶ç±»å‹: {getattr(file, 'content_type', 'æœªçŸ¥')}")
    print(f"ğŸ“„ å¼€å§‹å¤„ç†ä¸Šä¼ æ–‡ä»¶: {file.filename}")
    print(f"ğŸ“„ æ–‡ä»¶ç±»å‹: {getattr(file, 'content_type', 'æœªçŸ¥')}")
    
    # Create temporary file
    suffix = os.path.splitext(file.filename)[1].lower()
    logger.info(f"ğŸ“„ æ£€æµ‹æ–‡ä»¶æ‰©å±•å: {suffix}")
    print(f"ğŸ“„ æ£€æµ‹æ–‡ä»¶æ‰©å±•å: {suffix}")
    
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:
        try:
            # Write uploaded content to temporary file
            logger.info("ğŸ“¤ è¯»å–ä¸Šä¼ æ–‡ä»¶å†…å®¹...")
            print("ğŸ“¤ è¯»å–ä¸Šä¼ æ–‡ä»¶å†…å®¹...")
            content = await file.read()
            
            if not content:
                logger.error("âŒ ä¸Šä¼ æ–‡ä»¶å†…å®¹ä¸ºç©º")
                print("âŒ ä¸Šä¼ æ–‡ä»¶å†…å®¹ä¸ºç©º")
                return "é”™è¯¯ï¼šä¸Šä¼ æ–‡ä»¶å†…å®¹ä¸ºç©º"
            
            logger.info(f"ğŸ“¤ æ–‡ä»¶å¤§å°: {len(content)} å­—èŠ‚")
            print(f"ğŸ“¤ æ–‡ä»¶å¤§å°: {len(content)} å­—èŠ‚")
            
            # â­ Critical: File size limit to prevent memory issues
            if len(content) > config.MAX_FILE_SIZE:
                error_msg = f"æ–‡ä»¶å¤§å° {len(content)} å­—èŠ‚è¶…è¿‡10MBé™åˆ¶"
                logger.error(f"âŒ {error_msg}")
                print(f"âŒ {error_msg}")
                return f"é”™è¯¯ï¼š{error_msg}"
            
            tmp_file.write(content)
            tmp_file.flush()
            
            logger.info(f"ğŸ’¾ ä¸´æ—¶æ–‡ä»¶å·²åˆ›å»º: {tmp_file.name}")
            print(f"ğŸ’¾ ä¸´æ—¶æ–‡ä»¶å·²åˆ›å»º: {tmp_file.name}")
            
            # Process based on file extension with enhanced debugging
            try:
                if suffix in ['.doc', '.docx']:
                    logger.info("ğŸ“– ä½¿ç”¨Wordæ–‡æ¡£è§£æå™¨...")
                    print("ğŸ“– ä½¿ç”¨Wordæ–‡æ¡£è§£æå™¨...")
                    result = read_docx_file(tmp_file.name)
                elif suffix == '.pdf':
                    logger.info("ğŸ“– ä½¿ç”¨PDFæ–‡æ¡£è§£æå™¨...")
                    print("ğŸ“– ä½¿ç”¨PDFæ–‡æ¡£è§£æå™¨...")
                    result = read_pdf_file(tmp_file.name)
                elif suffix == '.txt':
                    logger.info("ğŸ“– ä½¿ç”¨æ–‡æœ¬æ–‡ä»¶è§£æå™¨...")
                    print("ğŸ“– ä½¿ç”¨æ–‡æœ¬æ–‡ä»¶è§£æå™¨...")
                    result = read_txt_file(tmp_file.name)
                else:
                    error_msg = f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {suffix}ã€‚æ”¯æŒæ ¼å¼: Word (.docx), PDF (.pdf), æ–‡æœ¬ (.txt)"
                    logger.error(f"âŒ {error_msg}")
                    print(f"âŒ {error_msg}")
                    return error_msg
            except Exception as parse_error:
                logger.error(f"âŒ æ–‡æ¡£è§£æå¼‚å¸¸: {str(parse_error)}")
                logger.error(f"ğŸ“‹ è§£æå¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
                print(f"âŒ æ–‡æ¡£è§£æå¼‚å¸¸: {str(parse_error)}")
                print(f"ğŸ“‹ è§£æå¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
                return f"é”™è¯¯ï¼šæ–‡æ¡£è§£æå¤±è´¥ - {type(parse_error).__name__}: {str(parse_error)}"
            
            # Validate result with enhanced debugging
            if not result:
                logger.error("âŒ æ–‡æ¡£è§£æç»“æœä¸ºç©º")
                print("âŒ æ–‡æ¡£è§£æç»“æœä¸ºç©º")
                return "é”™è¯¯ï¼šæ–‡æ¡£è§£æç»“æœä¸ºç©ºï¼Œå¯èƒ½æ–‡ä»¶å·²æŸåæˆ–æ ¼å¼ä¸æ­£ç¡®"
            
            if len(result) < 10:
                logger.warning(f"âš ï¸ æ–‡æ¡£è§£æç»“æœè¿‡çŸ­: {len(result)} å­—ç¬¦")
                print(f"âš ï¸ æ–‡æ¡£è§£æç»“æœè¿‡çŸ­: {len(result)} å­—ç¬¦")
                return f"é”™è¯¯ï¼šæ–‡æ¡£å†…å®¹è¿‡çŸ­({len(result)}å­—ç¬¦)ï¼Œå¯èƒ½è§£æå¤±è´¥"
            
            # Check for error messages in result
            error_indicators = ['error', 'exception', 'traceback', 'failed', 'Error:', 'Exception:', 'å¤„ç†å¤±è´¥', 'è§£æå¤±è´¥']
            if any(indicator in result for indicator in error_indicators):
                logger.warning("âš ï¸ è§£æç»“æœä¸­åŒ…å«é”™è¯¯ä¿¡æ¯")
                print("âš ï¸ è§£æç»“æœä¸­åŒ…å«é”™è¯¯ä¿¡æ¯")
                return "é”™è¯¯ï¼šæ–‡æ¡£è§£æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æˆ–å†…å®¹"
            
            # Debug: Log partial content to help with debugging
            content_preview = result[:500] + "..." if len(result) > 500 else result
            logger.info(f"âœ… æ–‡æ¡£å¤„ç†æˆåŠŸï¼Œæå–å†…å®¹é•¿åº¦: {len(result)} å­—ç¬¦")
            logger.debug(f"ğŸ“ æ–‡æ¡£å†…å®¹é¢„è§ˆ: {content_preview}")
            print(f"âœ… æ–‡æ¡£å¤„ç†æˆåŠŸï¼Œæå–å†…å®¹é•¿åº¦: {len(result)} å­—ç¬¦")
            print(f"ğŸ“ æ–‡æ¡£å†…å®¹é¢„è§ˆ: {content_preview}")
            
            return result
            
        except Exception as e:
            error_msg = f"æ–‡æ¡£å¤„ç†å¼‚å¸¸: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            logger.error(f"ğŸ“‹ å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            logger.error(f"ğŸ“‹ å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            print(f"âŒ {error_msg}")
            print(f"ğŸ“‹ å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            print(f"ğŸ“‹ å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            
            # Return a clean error message instead of the raw exception
            return f"é”™è¯¯ï¼šæ–‡æ¡£å¤„ç†å¤±è´¥ - {type(e).__name__}: {str(e)}ã€‚è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚"
        finally:
            # Clean up temporary file
            try:
                if os.path.exists(tmp_file.name):
                    os.unlink(tmp_file.name)
                    logger.info(f"ğŸ—‘ï¸ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†: {tmp_file.name}")
                    print(f"ğŸ—‘ï¸ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†: {tmp_file.name}")
            except Exception as cleanup_error:
                logger.warning(f"âš ï¸ ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥: {str(cleanup_error)}")
                print(f"âš ï¸ ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥: {str(cleanup_error)}")
                pass

# Legacy functions for backward compatibility (but using improved approach)
async def extract_text_from_docx(file_content: bytes) -> str:
    """Legacy function - now uses improved approach with temporary file"""
    with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp_file:
        try:
            tmp_file.write(file_content)
            tmp_file.flush()
            return read_docx_file(tmp_file.name)
        finally:
            try:
                os.unlink(tmp_file.name)
            except:
                pass

async def extract_text_from_pdf(file_content: bytes) -> str:
    """Legacy function - now uses improved approach with temporary file"""
    with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
        try:
            tmp_file.write(file_content)
            tmp_file.flush()
            return read_pdf_file(tmp_file.name)
        finally:
            try:
                os.unlink(tmp_file.name)
            except:
                pass

async def process_uploaded_document(file: UploadFile) -> str:
    """Legacy function - now uses improved approach"""
    return await process_uploaded_document_improved(file)

# Core Models according to README specifications
class APIConfig(BaseModel):
    """API Configuration for AI Agent"""
    type: str = Field(default="http", description="API Type")
    url: str = Field(..., description="AI Agent API URL")
    method: str = Field(default="POST", description="HTTP Method")
    headers: Dict[str, str] = Field(default={}, description="Request Headers")
    timeout: int = Field(default=30, description="Request timeout in seconds")
    
    # Coze Agent specific fields
    agentId: Optional[str] = Field(default=None, description="Coze Agent ID")
    region: Optional[str] = Field(default="global", description="Coze region")
    
    # Coze Bot specific fields  
    botId: Optional[str] = Field(default=None, description="Coze Bot ID")
    botVersion: Optional[str] = Field(default=None, description="Coze Bot Version")

class ConversationScenario(BaseModel):
    """Test scenario for multi-turn conversation"""
    title: str = Field(..., description="Scenario title")
    turns: List[str] = Field(..., description="User conversation turns")
    context: Optional[str] = Field(default="", description="Business context")
    user_profile: Optional[str] = Field(default="", description="User persona")

class EvaluationRequest(BaseModel):
    """Main evaluation request following README structure"""
    agent_api: APIConfig = Field(..., description="AI Agent API Configuration")
    requirement_doc: Optional[str] = Field(default="", description="Requirement document for context")
    conversation_scenarios: List[ConversationScenario] = Field(..., description="Test scenarios")
    
    # Message processing options
    use_raw_messages: Optional[bool] = Field(default=False, description="Use raw user messages without persona enhancement")
    
    # Coze compatibility (temporary until full API support)
    coze_bot_id: Optional[str] = Field(default=None, description="Coze Bot ID for current implementation")

class EvaluationDimensions(BaseModel):
    """3-dimension evaluation framework from README"""
    fuzzy_understanding: float = Field(..., description="æ¨¡ç³Šç†è§£ä¸è¿½é—®èƒ½åŠ›")
    answer_correctness: float = Field(..., description="å›ç­”å‡†ç¡®æ€§ä¸ä¸“ä¸šæ€§") 
    persona_alignment: float = Field(..., description="ç”¨æˆ·é€‚é…åº¦")
    goal_alignment: Optional[float] = Field(default=None, description="ç›®æ ‡å¯¹é½åº¦")

class EvaluationResponse(BaseModel):
    """Response structure matching README output format"""
    evaluation_summary: Dict[str, Any] = Field(..., description="Evaluation summary")
    conversation_records: List[Dict[str, Any]] = Field(..., description="Detailed conversation records")
    recommendations: List[str] = Field(..., description="Improvement suggestions")
    timestamp: str = Field(..., description="Evaluation timestamp")

# Configuration - Using config.py for direct API key management
# All constants are now accessed directly from config module

print(f"âœ… Configuration loaded from config.py - DeepSeek API configured")

# Conversation continuity management
class ConversationManager:
    """Manage conversation continuity across API calls"""
    
    def __init__(self, api_config: 'APIConfig'):
        self.api_config = api_config
        self.conversation_id = ""
        self.api_type = self._determine_api_type()
        
    def _determine_api_type(self) -> str:
        """Determine the API type based on URL"""
        if "/v1/chat-messages" in self.api_config.url or "dify" in self.api_config.url.lower():
            return "dify"
        elif "coze" in self.api_config.url.lower():
            return "coze"
        else:
            return "custom"
    
    def start_new_conversation(self) -> str:
        """Start a new conversation and return conversation ID"""
        if self.api_type == "dify":
            # For Dify, conversation_id will be extracted from first response
            self.conversation_id = ""
        else:
            # For other APIs, generate a unique conversation ID
            self.conversation_id = f"conv_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"
        
        return self.conversation_id
    
    def get_conversation_id(self) -> str:
        """Get current conversation ID"""
        return self.conversation_id
    
    def update_conversation_id(self, new_id: str):
        """Update conversation ID (used when extracted from API response)"""
        if new_id and new_id != self.conversation_id:
            self.conversation_id = new_id
            print(f"ğŸ”— æ›´æ–°å¯¹è¯ID: {new_id[:20]}...")

async def call_deepseek_api(prompt: str, max_retries: int = 2) -> str:
    """
    Call DeepSeek API with improved error handling
    """
    headers = {
        "Authorization": f"Bearer {config.DEEPSEEK_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": "deepseek-chat",
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 1000,
        "temperature": config.DEFAULT_TEMPERATURE
    }
    
    for attempt in range(max_retries):
        try:
            timeout = httpx.Timeout(config.DEEPSEEK_TIMEOUT, connect=10.0)
            async with httpx.AsyncClient(timeout=timeout) as client:
                response = await client.post(config.DEEPSEEK_API_URL, headers=headers, json=payload)
                
                if response.status_code == 200:
                    result = response.json()
                    if "choices" in result and len(result["choices"]) > 0:
                        return result["choices"][0]["message"]["content"].strip()
                    else:
                        raise Exception("No valid response from API")
                elif response.status_code == 401:
                    raise Exception("API authentication failed - check API key")
                elif response.status_code == 429:
                    if attempt < max_retries - 1:
                        await asyncio.sleep(2 ** attempt)
                        continue
                    raise Exception("API rate limited")
                else:
                    error_text = response.text if hasattr(response, 'text') else 'Unknown error'
                    raise Exception(f"API error {response.status_code}: {error_text}")
                    
        except (asyncio.TimeoutError, httpx.TimeoutException):
            if attempt < max_retries - 1:
                await asyncio.sleep(1)
                continue
            raise Exception(f"API timeout after {config.DEEPSEEK_TIMEOUT}s")
        except httpx.RequestError as e:
            if attempt < max_retries - 1:
                await asyncio.sleep(1)
                continue
            raise Exception(f"Network error: {str(e)}")
        except Exception as e:
            raise e
            
    raise Exception("All API attempts failed")

async def call_ai_agent_api(api_config: APIConfig, message: str, conversation_manager: ConversationManager = None, use_raw_message: bool = False) -> str:
    """Call AI Agent API - supports Coze, Dify, and custom APIs with conversation continuity"""
    try:
        # ğŸ“ Debug log for message processing mode
        message_preview = message[:80] + "..." if len(message) > 80 else message
        if use_raw_message:
            print(f"ğŸ” [RAW MODE] {message_preview}")
        else:
            print(f"ğŸ” [ENHANCED MODE] {message_preview}")
        
        # Check if we should use Coze API (either explicit coze URL or fallback URL)
        if "coze" in api_config.url.lower() or "fallback" in api_config.url.lower():
            return await call_coze_api_fallback(message, use_raw_message=use_raw_message)
        # Check if this is a Dify API (based on URL pattern)
        elif "/v1/chat-messages" in api_config.url or "dify" in api_config.url.lower():
            conversation_id = conversation_manager.get_conversation_id() if conversation_manager else ""
            response_content, new_conversation_id = await call_dify_api(api_config, message, conversation_id, use_raw_message=use_raw_message)
            
            # Update conversation manager with new conversation ID
            if conversation_manager and new_conversation_id:
                conversation_manager.update_conversation_id(new_conversation_id)
            
            return response_content
        else:
            # Generic API support
            headers = api_config.headers.copy()
            headers.setdefault("Content-Type", "application/json")
            
            # Use appropriate payload field based on raw message mode
            if use_raw_message:
                payload = {"input": message, "question": message, "query": message}  # Raw user input fields
            else:
                payload = {"message": message, "query": message}  # Enhanced message fields
            
            async with httpx.AsyncClient(timeout=httpx.Timeout(api_config.timeout)) as client:
                response = await client.request(
                    method=api_config.method,
                    url=api_config.url,
                    headers=headers,
                    json=payload
                )
                
                if response.status_code == 200:
                    result = response.json()
                    # Try common response paths
                    raw_response = ""
                    if "response" in result:
                        raw_response = result["response"]
                    elif "answer" in result:
                        raw_response = result["answer"]
                    elif "message" in result:
                        raw_response = result["message"]
                    else:
                        raw_response = str(result)
                    
                    # ğŸ”§ UNIVERSAL FIX: Apply plugin extraction to generic API responses too
                    if raw_response:
                        cleaned_response = clean_ai_response(raw_response)
                        if cleaned_response:
                            print(f"ğŸ§¹ é€šç”¨APIå“åº”ç»è¿‡æ’ä»¶æå–å¤„ç†: {cleaned_response[:100]}...")
                            return cleaned_response
                        return raw_response
                    else:
                        return "Empty response from API"
                else:
                    return f"APIè°ƒç”¨å¤±è´¥: {response.status_code}"
                    
    except Exception as e:
        print(f"âŒ AI Agent APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
        return "AI Agent APIè°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®"

async def call_dify_api(api_config: APIConfig, message: str, conversation_id: str = "", use_raw_message: bool = False) -> tuple:
    """
    Call Dify API with proper payload format and conversation continuity
    Returns: (response_content, conversation_id)
    """
    try:
        print(f"ğŸ” è°ƒç”¨Dify API: {api_config.url}")
        
        headers = api_config.headers.copy()
        headers.setdefault("Content-Type", "application/json")
        
        # Dify API specific payload format with conversation continuity
        # ğŸ“ Debug log for Dify message processing  
        message_preview = message[:60] + "..." if len(message) > 60 else message
        if use_raw_message:
            print(f"ğŸ” [DIFY RAW] {message_preview}")
            user_field = "evaluation-user-raw"
        else:
            print(f"ğŸ” [DIFY ENHANCED] {message_preview}")
            user_field = "evaluation-user"
            
        payload = {
            "inputs": {},
            "query": message,
            "response_mode": "streaming",
            "conversation_id": conversation_id,  # Use provided conversation_id for continuity
            "user": user_field,
            "files": []
        }
        
        print(f"ğŸ“¤ Dify APIè¯·æ±‚è½½è·: {json.dumps(payload, ensure_ascii=False)[:200]}...")
        if conversation_id:
            print(f"ğŸ”— ä½¿ç”¨å¯¹è¯ID: {conversation_id[:20]}...")
        
        async with httpx.AsyncClient(timeout=httpx.Timeout(api_config.timeout)) as client:
            response = await client.post(api_config.url, headers=headers, json=payload)
            
            print(f"ğŸ” Dify APIå“åº”çŠ¶æ€: {response.status_code}")
            
            if response.status_code == 200:
                # Check if response is streaming
                content_type = response.headers.get("content-type", "").lower()
                
                if "text/event-stream" in content_type or payload.get("response_mode") == "streaming":
                    # Handle streaming response
                    response_text = response.text
                    print(f"ğŸ” å¤„ç†Difyæµå¼å“åº” ({len(response_text)} chars)")
                    
                    if not response_text.strip():
                        raise Exception("Empty streaming response from Dify API")
                    
                    # Parse Dify streaming format
                    lines = response_text.strip().split('\n')
                    collected_content = ""
                    conversation_id_extracted = conversation_id  # Start with input conversation_id
                    
                    for line in lines:
                        line = line.strip()
                        if not line:
                            continue
                        
                        if line.startswith("data: "):
                            data_content = line[6:]  # Remove "data: " prefix
                            
                            # Skip end marker
                            if data_content.strip() in ['"[DONE]"', "[DONE]"]:
                                break
                            
                            try:
                                data_json = json.loads(data_content)
                                
                                # Extract conversation_id for future continuity
                                if "conversation_id" in data_json and data_json["conversation_id"]:
                                    conversation_id_extracted = data_json["conversation_id"]
                                
                                # Extract content from Dify response
                                if "answer" in data_json:
                                    collected_content += data_json["answer"]
                                elif "data" in data_json and "answer" in data_json["data"]:
                                    collected_content += data_json["data"]["answer"]
                                elif "message" in data_json:
                                    collected_content += data_json["message"]
                                    
                            except json.JSONDecodeError:
                                continue
                    
                    if collected_content:
                        print(f"âœ… Difyæµå¼å“åº”è§£ææˆåŠŸ: {collected_content[:100]}...")
                        # ğŸ”§ UNIVERSAL FIX: Apply plugin extraction to Dify responses too
                        cleaned_content = clean_ai_response(collected_content)
                        if cleaned_content and cleaned_content != collected_content:
                            print(f"ğŸ§¹ Difyå“åº”ç»è¿‡æ’ä»¶æå–å¤„ç†: {cleaned_content[:100]}...")
                            collected_content = cleaned_content
                        
                        if conversation_id_extracted and conversation_id_extracted != conversation_id:
                            print(f"ğŸ”— æå–åˆ°å¯¹è¯ID: {conversation_id_extracted[:20]}...")
                        return collected_content.strip(), conversation_id_extracted
                    else:
                        print("âŒ æœªä»Difyæµå¼å“åº”ä¸­æå–åˆ°æœ‰æ•ˆå†…å®¹")
                        raise Exception("No valid content in Dify streaming response")
                
                else:
                    # Handle regular JSON response
                    result = response.json()
                    print(f"ğŸ” Dify JSONå“åº”: {json.dumps(result, ensure_ascii=False)[:300]}...")
                    
                    # Try to extract answer from various possible response formats
                    response_content = ""
                    conversation_id_extracted = conversation_id
                    
                    if "answer" in result:
                        response_content = result["answer"].strip()
                    elif "data" in result and isinstance(result["data"], dict):
                        if "answer" in result["data"]:
                            response_content = result["data"]["answer"].strip()
                        elif "message" in result["data"]:
                            response_content = result["data"]["message"].strip()
                    elif "message" in result:
                        response_content = result["message"].strip()
                    else:
                        print(f"âš ï¸ æœªçŸ¥çš„Difyå“åº”æ ¼å¼ï¼Œå°è¯•è¿”å›å®Œæ•´å“åº”")
                        response_content = str(result)
                    
                    # Extract conversation_id from JSON response
                    if "conversation_id" in result and result["conversation_id"]:
                        conversation_id_extracted = result["conversation_id"]
                    
                    # ğŸ”§ UNIVERSAL FIX: Apply plugin extraction to Dify JSON responses too
                    if response_content:
                        cleaned_content = clean_ai_response(response_content)
                        if cleaned_content:
                            response_content = cleaned_content
                            print(f"ğŸ§¹ Dify JSONå“åº”ç»è¿‡æ’ä»¶æå–å¤„ç†: {response_content[:100]}...")
                    
                    return response_content, conversation_id_extracted
            else:
                error_text = response.text if hasattr(response, 'text') else 'Unknown error'
                print(f"âŒ Dify API HTTPé”™è¯¯ {response.status_code}: {error_text}")
                raise Exception(f"Dify API HTTP error {response.status_code}: {error_text}")
                
    except (asyncio.TimeoutError, httpx.TimeoutException):
        print(f"âŒ Dify APIè¶…æ—¶ after {api_config.timeout}s")
        raise Exception(f"Dify API timeout after {api_config.timeout}s")
    except httpx.RequestError as e:
        print(f"âŒ Dify APIç½‘ç»œé”™è¯¯: {str(e)}")
        raise Exception(f"Dify API network error: {str(e)}")
    except Exception as e:
        print(f"âŒ Dify APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
        raise e

async def call_coze_api_fallback(message: str, bot_id: str = None, use_raw_message: bool = False) -> str:
    """
    Enhanced Coze API with proper plugin response extraction
    """
    if not bot_id:
        bot_id = config.DEFAULT_COZE_BOT_ID
    
    url = f"{config.COZE_API_BASE}/v3/chat"
    headers = {
        "Authorization": f"Bearer {config.COZE_API_TOKEN}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "parameters": {},
        "bot_id": bot_id,
        "user_id": "123",
        "additional_messages": [
            {
                "content_type": "text",
                "type": "question",
                "role": "user",
                "content": message
            }
        ],
        "auto_save_history": True,
        "stream": True
    }

    # ğŸ“ Clean debug logging
    message_preview = message[:60] + "..." if len(message) > 60 else message
    print(f"ğŸ” [COZE] {message_preview}")

    try:
        async with httpx.AsyncClient(timeout=config.COZE_TIMEOUT) as client:
            response = await client.post(url, json=payload, headers=headers)
            
            if response.status_code == 200:
                content_type = response.headers.get("Content-Type", "")
                response_text = response.text
                
                print(f"ğŸ” Coze API Response Status: {response.status_code}")
                print(f"ğŸ” Handling SSE streaming response ({len(response_text)} chars)")
                
                # Raw response length for debugging
                # print(f"ğŸ” RAW RESPONSE (first 1000 chars): {response_text[:1000]}...") # Disabled for cleaner output

                if "text/event-stream" in content_type or "stream" in response_text:
                    # Parse SSE streaming response
                    lines = response_text.strip().split('\n')
                    current_event = None
                    main_answer = ""
                    assistant_messages = []
                    collected_content = ""
                    plugin_responses = []  # ğŸ”§ NEW: Collect plugin responses
                    
                    # ğŸ” PATTERN SEARCH: Look for tool output patterns in raw response
                    import re
                    tool_output_patterns = [
                        r'"tool_output_content":"([^"]+)"',
                        r'"tool_output_content":\s*"([^"]+)"',
                        r'ç­”æ¡ˆï¼š([^"\\n]+)',
                        r'"answer":"([^"]+)"',
                        r'"response":"([^"]+)"',
                        r'"result":"([^"]+)"'
                    ]
                    
                    for pattern in tool_output_patterns:
                        matches = re.findall(pattern, response_text, re.IGNORECASE | re.DOTALL)
                        for match in matches:
                            # Clean up escape characters
                            cleaned_match = match.replace('\\n', '\n').replace('\\"', '"').replace('\\t', '\t')
                            if len(cleaned_match.strip()) > 20:  # Substantial content
                                plugin_responses.append(cleaned_match.strip())
                    
                    for line in lines:
                        line = line.strip()
                        
                        if line.startswith("event:"):
                            current_event = line[6:].strip()
                        elif line.startswith("data:") and len(line) > 5:
                            data_content = line[5:].strip()
                            
                            if data_content in ["[DONE]", ""]:
                                continue
                                
                            try:
                                data_json = json.loads(data_content)
                                
                                if current_event == "conversation.message.delta":
                                    # This is streaming content chunk
                                    if "content" in data_json:
                                        content_chunk = data_json["content"]
                                        # Don't collect plugin invocation chunks
                                        if not (content_chunk.strip().startswith('{"name":"') or 
                                                '"plugin_id":' in content_chunk or
                                                '"arguments":' in content_chunk):
                                            collected_content += content_chunk
                                        
                                elif current_event == "conversation.message.completed":
                                    # This is a completed message
                                    if "content" in data_json:
                                        message_content = data_json["content"]
                                        role = data_json.get("role", "unknown")
                                        msg_type = data_json.get("type", "text")
                                        
                                        # ğŸ”§ NEW: Enhanced plugin response handling
                                        if role == "assistant" and message_content:
                                            # Check if content is a plugin invocation JSON
                                            if (message_content.strip().startswith('{"name":"') and 
                                                '"arguments":' in message_content and
                                                '"plugin_id":' in message_content):
                                                print(f"ğŸ”§ Found plugin invocation: {message_content[:200]}...")
                                                
                                                # Try to extract tool output from plugin response
                                                try:
                                                    plugin_data = json.loads(message_content)
                                                    
                                                    # Look for tool output in various possible fields
                                                    tool_output_fields = [
                                                        'tool_output_content',
                                                        'output',
                                                        'result', 
                                                        'content',
                                                        'answer',
                                                        'response',
                                                        'text',
                                                        'data'
                                                    ]
                                                    
                                                    found_output = False
                                                    
                                                    # Check top-level fields
                                                    for field in tool_output_fields:
                                                        if field in plugin_data and plugin_data[field]:
                                                            tool_output = str(plugin_data[field])
                                                            if len(tool_output.strip()) > 10:  # Substantial content
                                                                print(f"âœ… Extracted plugin output from {field}: {tool_output[:100]}...")
                                                                plugin_responses.append(tool_output)
                                                                found_output = True
                                                                break
                                                    
                                                    # Check nested arguments if not found yet
                                                    if not found_output and 'arguments' in plugin_data and isinstance(plugin_data['arguments'], dict):
                                                        args = plugin_data['arguments']
                                                        for field in tool_output_fields:
                                                            if field in args and args[field]:
                                                                tool_output = str(args[field])
                                                                if len(tool_output.strip()) > 10:
                                                                    print(f"âœ… Extracted plugin output from args.{field}: {tool_output[:100]}...")
                                                                    plugin_responses.append(tool_output)
                                                                    found_output = True
                                                                    break
                                                    
                                                except json.JSONDecodeError as e:
                                                    print(f"âš ï¸ Failed to parse plugin JSON: {e}")
                                                
                                                continue  # Skip adding to assistant_messages
                                            
                                            # Regular assistant message
                                            assistant_messages.append({
                                                "content": message_content,
                                                "type": msg_type,
                                                "length": len(message_content)
                                            })
                                        
                                        # Set main answer if this is substantial content and not plugin invocation
                                        if (message_content and len(message_content) > 20 and 
                                            not (message_content.strip().startswith('{"name":"') and 
                                                 '"arguments":' in message_content and
                                                 '"plugin_id":' in message_content)):
                                            if not main_answer or len(message_content) > len(main_answer):
                                                main_answer = message_content
                                
                                elif current_event == "conversation.chat.completed":
                                    # Chat completion event - might have final answer
                                    if "last_message" in data_json and data_json["last_message"].get("content"):
                                        final_content = data_json["last_message"]["content"]
                                        if len(final_content) > 20:
                                            main_answer = final_content
                                
                                # ğŸ”§ NEW: Check for tool output events
                                elif current_event == "conversation.message.plugin.finish":
                                    if "content" in data_json:
                                        plugin_output = data_json["content"]
                                        if len(plugin_output.strip()) > 10:
                                            print(f"âœ… Plugin finish event with output: {plugin_output[:100]}...")
                                            plugin_responses.append(plugin_output)
                                
                                # ğŸ”§ CRITICAL: Extract plugin content from stream_plugin_finish events
                                if current_event == "conversation.message.completed" and "content" in data_json:
                                    content = data_json["content"]
                                    # Check if this is a stream_plugin_finish event with tool_output_content
                                    if isinstance(content, str) and '"msg_type":"stream_plugin_finish"' in content:
                                        try:
                                            # Parse the JSON content to extract tool_output_content
                                            inner_json = json.loads(content)
                                            if inner_json.get("msg_type") == "stream_plugin_finish" and "data" in inner_json:
                                                data_str = inner_json["data"]
                                                if isinstance(data_str, str):
                                                    data_content = json.loads(data_str)
                                                    if "tool_output_content" in data_content:
                                                        tool_output = data_content["tool_output_content"]
                                                        if tool_output and len(tool_output.strip()) > 20:
                                                            print(f"âœ… Extracted plugin output: {tool_output[:200]}...")
                                                            plugin_responses.append(tool_output)
                                        except (json.JSONDecodeError, KeyError) as e:
                                            print(f"âš ï¸ Failed to parse plugin content: {e}")
                                
                                # Minimal logging for debugging
                                # if current_event in ["conversation.message.completed", "conversation.message.delta"] and "content" in data_json:
                                #     content_preview = str(data_json["content"])[:100] if data_json["content"] else "empty"
                                #     print(f"ğŸ” {current_event}: {content_preview}...")
                                
                                # Check for tool output in tool_response type messages
                                if current_event == "conversation.message.completed" and data_json.get("type") == "tool_response":
                                    if "content" in data_json:
                                        tool_content = data_json["content"]
                                        if tool_content and len(str(tool_content).strip()) > 10:
                                            print(f"âœ… Found tool response: {str(tool_content)[:200]}...")
                                            # Skip the generic "directly streaming reply" message
                                            if "directly streaming reply" not in str(tool_content):
                                                plugin_responses.append(str(tool_content))
                                
                                # Also check for direct content fields regardless of event
                                elif "content" in data_json and not data_json.get("msg_type"):
                                    content = data_json["content"]
                                    if (content and len(content) > 20 and 
                                        not any(keyword in content for keyword in [
                                            'ç”¨æˆ·ç¼–å†™çš„ä¿¡æ¯', 'ç”¨æˆ·ç”»åƒä¿¡æ¯', 'ç”¨æˆ·è®°å¿†ç‚¹ä¿¡æ¯'
                                        ]) and
                                        not (content.strip().startswith('{"name":"') and 
                                             '"arguments":' in content and
                                             '"plugin_id":' in content)):
                                        if not main_answer or len(content) > len(main_answer):
                                            main_answer = content
                                
                            except json.JSONDecodeError as e:
                                continue
                    
                    # ğŸ”§ ENHANCED: Priority order for response content 
                    print(f"ğŸ” Response content summary: {len(plugin_responses)} plugins, {len(assistant_messages)} messages, main_answer: {len(main_answer) if main_answer else 0} chars")
                    
                    # 1. Plugin responses (highest priority for technical queries)
                    if plugin_responses:
                        # Use the longest/most substantial plugin response
                        best_plugin_response = max(plugin_responses, key=len)
                        if len(best_plugin_response) > 20:
                            print(f"âœ… Using plugin response ({len(best_plugin_response)} chars)")
                            return clean_ai_response(best_plugin_response)
                    
                    # 2. Main answer (from completed messages)
                    if main_answer and not any(keyword in main_answer for keyword in [
                        'ç”¨æˆ·ç¼–å†™çš„ä¿¡æ¯', 'ç”¨æˆ·ç”»åƒä¿¡æ¯', 'ç”¨æˆ·è®°å¿†ç‚¹ä¿¡æ¯', 'wraped_text', 'origin_search_results'
                    ]):
                        print(f"âœ… Using main answer ({len(main_answer)} chars): {main_answer[:100]}...")
                        return clean_ai_response(main_answer)
                    
                    # 3. Look for non-system assistant messages
                    for i, msg in enumerate(assistant_messages):
                        content = msg["content"]
                        if (not any(keyword in content for keyword in [
                            'ç”¨æˆ·ç¼–å†™çš„ä¿¡æ¯', 'ç”¨æˆ·ç”»åƒä¿¡æ¯', 'ç”¨æˆ·è®°å¿†ç‚¹ä¿¡æ¯', 'wraped_text', 'origin_search_results'
                        ]) and
                        not (content.strip().startswith('{"name":"') and 
                             '"arguments":' in content and
                             '"plugin_id":' in content)):
                            print(f"âœ… Using assistant message ({len(content)} chars): {content[:100]}...")
                            return clean_ai_response(content)
                    
                    # 4. Collected streaming content (delta)
                    if (collected_content and 
                        not any(keyword in collected_content for keyword in [
                            'ç”¨æˆ·ç¼–å†™çš„ä¿¡æ¯', 'ç”¨æˆ·ç”»åƒä¿¡æ¯', 'ç”¨æˆ·è®°å¿†ç‚¹ä¿¡æ¯', 'wraped_text', 'origin_search_results'
                        ]) and
                        not (collected_content.strip().startswith('{"name":"') and 
                             '"arguments":' in collected_content and
                             '"plugin_id":' in collected_content)):
                        print(f"âœ… Using streaming content ({len(collected_content)} chars): {collected_content[:100]}...")
                        return clean_ai_response(collected_content)
                    
                    # 5. Check for billing errors before returning empty
                    if "unpaid bills" in response_text or "code\":4027" in response_text:
                        print("ğŸ’° âŒ Cozeè´¦æˆ·ä½™é¢ä¸è¶³æˆ–æœ‰æœªä»˜è´¦å•")
                        print("ğŸ’° è¯¦æƒ…: https://console.volcengine.com/coze-pro/overview")
                        return "âŒ API Error: Cozeè´¦æˆ·ä½™é¢ä¸è¶³ï¼Œè¯·è”ç³»ç®¡ç†å‘˜å……å€¼è´¦æˆ·åé‡è¯•"
                    
                    # 6. If all content was system messages, return empty
                    print("âŒ No conversational content found (system messages only)")
                    print(f"ğŸ” COMPLETE RAW RESPONSE FOR DEBUGGING: {response_text}")
                    return ""  # Return empty to trigger proper handling
                
                else:
                    # Handle regular JSON response
                    result = response.json()
                    print(f"ğŸ” Coze API Response Structure: {json.dumps(result, indent=2)[:500]}...")
                    
                    if result.get("code") == 0 and "data" in result:
                        data = result["data"]
                        
                        # Handle non-streaming response format
                        if "messages" in data and len(data["messages"]) > 0:
                            # Get the last assistant message
                            for msg in reversed(data["messages"]):
                                if msg.get("role") == "assistant" and msg.get("content"):
                                    print(f"âœ… Found assistant response: {msg['content'][:100]}...")
                                    return clean_ai_response(msg["content"])
                            
                            # Fallback to any message content
                            for msg in data["messages"]:
                                if msg.get("content"):
                                    print(f"âœ… Found fallback response: {msg['content'][:100]}...")
                                    return clean_ai_response(msg["content"])
                        
                        # Check for other possible response formats
                        if "answer" in data:
                            print(f"âœ… Found answer field: {data['answer'][:100]}...")
                            return clean_ai_response(data["answer"])
                        
                        if "content" in data:
                            print(f"âœ… Found content field: {data['content'][:100]}...")
                            return clean_ai_response(data["content"])
                        
                        print(f"âš ï¸ No response content found in data: {list(data.keys())}")
                        raise Exception("No valid response content in Coze API result")
                    else:
                        error_msg = result.get("msg", "Unknown Coze API error")
                        print(f"âŒ Coze API returned error: {error_msg}")
                        raise Exception(f"Coze API error: {error_msg}")
            else:
                error_text = response.text if hasattr(response, 'text') else 'Unknown error'
                print(f"âŒ HTTP error {response.status_code}: {error_text}")
                raise Exception(f"Coze API HTTP error {response.status_code}: {error_text}")
                
    except (asyncio.TimeoutError, httpx.TimeoutException):
        print(f"âŒ Coze API timeout after {config.COZE_TIMEOUT}s")
        raise Exception(f"Coze API timeout after {config.COZE_TIMEOUT}s")
    except httpx.RequestError as e:
        print(f"âŒ Coze API network error: {str(e)}")
        raise Exception(f"Coze API network error: {str(e)}")
    except Exception as e:
        print(f"âŒ Coze API unexpected error: {str(e)}")
        raise e

def extract_score_from_response(response: str) -> float:
    """Extract numerical score from DeepSeek response (1-100 scale)"""
    try:
        # Look for patterns like "è¯„åˆ†ï¼š85åˆ†", "å¾—åˆ†ï¼š75", "85/100", etc.
        patterns = [
            r'è¯„åˆ†[ï¼š:]\s*(\d+(?:\.\d+)?)',
            r'å¾—åˆ†[ï¼š:]\s*(\d+(?:\.\d+)?)',
            r'(\d+(?:\.\d+)?)\s*åˆ†',
            r'(\d+(?:\.\d+)?)\s*/\s*100',
            r'(\d+(?:\.\d+)?)\s*æ˜Ÿ'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response)
            if match:
                score = float(match.group(1))
                # If score appears to be on 1-5 scale, convert to 1-100
                if score <= 5.0:
                    score = score * 20  # Convert 1-5 to 20-100
                return min(max(score, 1.0), 100.0)  # Clamp between 1-100
        
        # If no pattern found, try to find any number
        numbers = re.findall(r'\d+(?:\.\d+)?', response)
        if numbers:
            for num in numbers:
                score = float(num)
                if 1 <= score <= 5:
                    return score * 20  # Convert 1-5 to 20-100
                elif 1 <= score <= 100:
                    return score
        
        # Default fallback
        return 60.0  # Middle score
        
    except Exception:
        return 60.0  # Middle score on error

async def call_coze_api_sdk(bot_id: str, message: str) -> str:
    """
    Use official Coze SDK for API calls (preferred method)
    """
    if not COZE_SDK_AVAILABLE:
        print("âš ï¸ Coze SDKä¸å¯ç”¨ï¼Œä½¿ç”¨HTTP fallback")
        return await call_coze_api_fallback(message, bot_id)
    
    try:
        # Initialize Coze client with config settings
        coze = Coze(
            auth=TokenAuth(token=config.COZE_API_TOKEN), 
            base_url=COZE_CN_BASE_URL
        )
        
        # Generate a unique user ID for this conversation
        user_id = f"eval_user_{int(time.time())}"
        
        print(f"ğŸ”„ ä½¿ç”¨Coze SDKè°ƒç”¨ Bot {bot_id}")
        
        # Collect response content
        response_content = ""
        token_count = 0
        
        # Track plugin responses like in the HTTP fallback method
        plugin_responses = []
        collected_content = ""
        
        # Create streaming chat
        for event in coze.chat.stream(
            bot_id=bot_id,
            user_id=user_id,
            additional_messages=[
                Message.build_user_question_text(message),
            ],
        ):
            # Enhanced logging for debugging
            print(f"[ğŸ“¡ EVENT] {event.event}")
            
            if event.event == ChatEventType.CONVERSATION_MESSAGE_DELTA:
                content = event.message.content or ""
                print(f"[ğŸ“¦ DELTA CONTENT] {content[:100]}...")
                
                # ğŸ”§ Enhanced plugin detection using existing patterns from HTTP fallback
                # Check if content contains plugin JSON data
                if ('"tool_output_content"' in content or 
                    '"plugin_id"' in content or
                    '"msg_type":"stream_plugin_finish"' in content):
                    
                    print(f"ğŸ”§ Detected plugin content in delta: {content[:150]}...")
                    
                    # Try to extract plugin tool output using same logic as HTTP fallback
                    try:
                        if '"tool_output_content"' in content:
                            # Extract tool_output_content directly
                            import re
                            match = re.search(r'"tool_output_content":"([^"]+)"', content)
                            if match:
                                tool_output = match.group(1).replace('\\n', '\n').replace('\\"', '"')
                                print(f"âœ… Extracted tool_output_content: {tool_output[:100]}...")
                                plugin_responses.append(tool_output)
                                continue  # Skip adding to response_content to avoid duplication
                        
                        # Handle stream_plugin_finish format  
                        if '"msg_type":"stream_plugin_finish"' in content:
                            try:
                                import json
                                plugin_data = json.loads(content)
                                data_content = plugin_data.get('data', {})
                                if isinstance(data_content, str):
                                    # Parse nested JSON in data field
                                    try:
                                        data_obj = json.loads(data_content)
                                        tool_output = data_obj.get('tool_output_content', '')
                                        if tool_output and len(tool_output.strip()) > 5:
                                            print(f"âœ… Extracted from stream_plugin_finish: {tool_output[:100]}...")
                                            plugin_responses.append(tool_output)
                                            continue
                                    except:
                                        pass
                                elif isinstance(data_content, dict):
                                    tool_output = data_content.get('tool_output_content', '')
                                    if tool_output and len(tool_output.strip()) > 5:
                                        print(f"âœ… Extracted from nested JSON: {tool_output[:100]}...")
                                        plugin_responses.append(tool_output)
                                        continue
                            except json.JSONDecodeError:
                                print(f"âš ï¸ Failed to parse stream_plugin_finish JSON")
                        
                        # Try to parse as plugin invocation JSON
                        if '"plugin_id"' in content:
                            try:
                                import json
                                plugin_data = json.loads(content)
                                
                                # Look for tool output in various possible fields
                                tool_output_fields = [
                                    'tool_output_content', 'output', 'result', 
                                    'content', 'answer', 'response'
                                ]
                                
                                for field in tool_output_fields:
                                    if field in plugin_data and plugin_data[field]:
                                        tool_output = str(plugin_data[field])
                                        if len(tool_output.strip()) > 10:
                                            print(f"âœ… Extracted plugin output from {field}: {tool_output[:100]}...")
                                            plugin_responses.append(tool_output)
                                            break
                                
                                # Also check in arguments field
                                if 'arguments' in plugin_data and isinstance(plugin_data['arguments'], dict):
                                    args = plugin_data['arguments']
                                    for field in tool_output_fields:
                                        if field in args and args[field]:
                                            tool_output = str(args[field])
                                            if len(tool_output.strip()) > 10:
                                                print(f"âœ… Extracted tool output from args.{field}: {tool_output[:100]}...")
                                                plugin_responses.append(tool_output)
                                                break
                                continue  # Skip adding plugin JSON to response_content
                            except json.JSONDecodeError:
                                print(f"âš ï¸ Failed to parse plugin JSON")
                    
                    except Exception as e:
                        print(f"âš ï¸ Error processing plugin content: {e}")
                
                # Only add to collected content if it's not plugin invocation JSON
                if not ('"plugin_id"' in content and content.strip().startswith('{')):
                    collected_content += content
                    response_content += content
                
            # Handle direct plugin results (if SDK supports these attributes)
            elif hasattr(event, 'plugin_result') and event.plugin_result:
                plugin_content = str(event.plugin_result)
                response_content += f"\n{plugin_content}"
                plugin_responses.append(plugin_content)
                print(f"[ğŸ”Œ PLUGIN RESULT] {plugin_content[:100]}...")
                
            # Handle tool outputs (alternative event type for plugins)
            elif hasattr(event, 'tool_output') and event.tool_output:
                tool_content = str(event.tool_output)
                response_content += f"\n{tool_content}"
                plugin_responses.append(tool_content)
                print(f"[ğŸ”§ TOOL OUTPUT] {tool_content[:100]}...")
                
            # Handle any other message content (fallback for other content types)
            elif hasattr(event, 'message') and hasattr(event.message, 'content') and event.message.content:
                if event.event != ChatEventType.CONVERSATION_MESSAGE_DELTA:  # Avoid duplicates
                    content = event.message.content
                    response_content += content
                    print(f"[ğŸ“„ OTHER MESSAGE] {content[:100]}...")
                    
            elif event.event == ChatEventType.CONVERSATION_CHAT_COMPLETED:
                if hasattr(event.chat, 'usage') and event.chat.usage:
                    token_count = event.chat.usage.token_count
                print(f"[âœ… CHAT COMPLETED] Token count: {token_count}")
                break
                
            # Log any unhandled events for debugging
            else:
                print(f"[â“ UNHANDLED EVENT] {event.event} - {type(event)}")
                # Try to extract any content from unknown event types
                if hasattr(event, 'content'):
                    content = str(event.content)
                    response_content += f"\n{content}"
                    print(f"[â“ UNKNOWN CONTENT] {content[:100]}...")
        
        # ğŸ”§ Priority order for response content with plugin support (same as HTTP fallback)
        # 1. Plugin responses (highest priority for technical queries)
        if plugin_responses:
            # Use the longest/most substantial plugin response
            best_plugin_response = max(plugin_responses, key=len)
            if len(best_plugin_response) > 20:
                print(f"âœ… Using plugin response ({len(best_plugin_response)} chars)")
                response_content = best_plugin_response
            
        # Apply the same cleaning as the HTTP fallback
        if response_content:
            response_content = clean_ai_response(response_content)
        
        if not response_content.strip():
            raise Exception("Empty response from Coze SDK")
            
        print(f"âœ… SDKè°ƒç”¨æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(response_content)}, Token: {token_count}")
        return response_content.strip()
        
    except Exception as e:
        print(f"âŒ Coze SDKè°ƒç”¨å¤±è´¥: {str(e)}")
        print("ğŸ”„ åˆ‡æ¢åˆ°HTTP fallback")
        return await call_coze_api_fallback(message, bot_id)

async def call_coze_api(bot_id: str, message: str) -> str:
    """
    Main Coze API call function - tries SDK first, then fallback
    """
    return await call_coze_api_sdk(bot_id, message)

async def call_api(api_config: APIConfig, message: str) -> str:
    """Generic API call function"""
    return await call_ai_agent_api(api_config, message)

async def conduct_conversation(api_config: APIConfig, scenario: ConversationScenario) -> List[Dict]:
    """Conduct a conversation based on the scenario"""
    conversation_history = []
    
    print(f"ğŸ”§ API é…ç½®ç±»å‹: {api_config.type}")
    print(f"ğŸ”§ API é…ç½®è¯¦æƒ…: {api_config}")
    
    for turn_num, user_message in enumerate(scenario.turns, 1):
        print(f"  ç¬¬{turn_num}è½®: {user_message}")
        
        # Get AI response based on API type
        if api_config.type == 'coze-agent':
            print("ğŸ¤– ä½¿ç”¨ Coze Agent API")
            # Extract access token properly
            access_token = api_config.headers.get('Authorization', '')
            if access_token.startswith('Bearer '):
                access_token = access_token.replace('Bearer ', '')
            
            print(f"ğŸ”‘ Agent ID: {getattr(api_config, 'agentId', 'Not found')}")
            print(f"ğŸ”‘ Region: {getattr(api_config, 'region', 'Not found')}")
            
            ai_response = await call_coze_agent_api(
                agent_id=getattr(api_config, 'agentId', ''),
                access_token=access_token,
                message=user_message,
                region=getattr(api_config, 'region', 'global')
            )
        elif api_config.type == 'coze-bot' or hasattr(api_config, 'botId'):
            print("ğŸ¤– ä½¿ç”¨ Coze Bot API")
            bot_id = getattr(api_config, 'botId', '')
            ai_response = await call_coze_api(bot_id, user_message)
        elif api_config.type == 'custom-api':
            print("ğŸ¤– ä½¿ç”¨è‡ªå®šä¹‰ API")
            ai_response = await call_api(api_config, user_message)
        else:
            print(f"âŒ æœªçŸ¥çš„APIç±»å‹: {api_config.type}")
            ai_response = f"APIé…ç½®é”™è¯¯ï¼Œæ— æ³•è¯†åˆ«çš„APIç±»å‹: {api_config.type}"
        
        conversation_history.append({
            "turn": turn_num,
            "user_message": user_message,
            "ai_response": ai_response
        })
        
        # Truncate long responses for display
        display_response = ai_response[:100] + "..." if len(ai_response) > 100 else ai_response
        print(f"  AIå›å¤: {display_response}")
    
    return conversation_history

async def evaluate_conversation_deepseek(
    conversation_history: List[Dict], 
    scenario: Dict, 
    requirement_context: str = "",
    evaluation_mode: str = "manual",
    user_persona_info: Dict = None
) -> tuple:
    """
    Enhanced DeepSeek evaluation with persona awareness
    """
    try:
        print("ğŸ§  å¼€å§‹DeepSeekæ™ºèƒ½è¯„ä¼°...")
        
        # Build enhanced context section
        context_section = f"""
ä¸šåŠ¡åœºæ™¯: {scenario.get('context', 'é€šç”¨AIåŠ©æ‰‹åœºæ™¯')}
ç”¨æˆ·ç”»åƒ: {scenario.get('user_profile', 'æ™®é€šç”¨æˆ·')}
å¯¹è¯ä¸»é¢˜: {scenario.get('title', '')}
è¯„ä¼°æ¨¡å¼: {evaluation_mode}
"""
        
        # Add persona information if available
        if evaluation_mode == "auto" and user_persona_info:
            persona = user_persona_info.get('user_persona', {})
            context_section += f"""
æå–çš„ç”¨æˆ·è§’è‰²: {persona.get('role', '')}
ç”¨æˆ·ç»éªŒæ°´å¹³: {persona.get('experience_level', '')}
æ²Ÿé€šé£æ ¼: {persona.get('communication_style', '')}
å·¥ä½œç¯å¢ƒ: {persona.get('work_environment', '')}
"""
        
        if requirement_context:
            context_section += f"\néœ€æ±‚æ–‡æ¡£ä¸Šä¸‹æ–‡:\n{requirement_context[:1000]}"
        
        # Build conversation context
        conversation_text = ""
        for turn in conversation_history:
            conversation_text += f"ç”¨æˆ·: {turn['user_message']}\nAI: {turn['ai_response']}\n\n"
        
        # Enhanced evaluation prompts with persona awareness
        base_context = f"{context_section}\n\nå¯¹è¯è®°å½•:\n{conversation_text}\n"
        
        # Call the evaluation function
        return await perform_deepseek_evaluations({}, base_context, requirement_context)
        
    except Exception as e:
        print(f"âŒ DeepSeekè¯„ä¼°å¤±è´¥: {str(e)}")
        return {}, {}

def generate_enhanced_recommendations(evaluation_results: List[Dict], user_persona_info: Dict = None) -> List[str]:
    """
    Generate enhanced recommendations based on evaluation results and user persona
    """
    recommendations = []
    
    if not evaluation_results:
        return [
            "æ— æ³•ç”Ÿæˆæ¨èå»ºè®®ï¼Œè¯·å…ˆå®Œæˆæœ‰æ•ˆçš„è¯„ä¼°",
            "æ£€æŸ¥AI Agenté…ç½®å’Œç½‘ç»œè¿æ¥",
            "ç¡®ä¿å¯¹è¯åœºæ™¯é…ç½®æ­£ç¡®"
        ]
    
    persona = user_persona_info.get('user_persona', {}) if user_persona_info else {}
    context = user_persona_info.get('usage_context', {}) if user_persona_info else {}
    requirements = user_persona_info.get('extracted_requirements', {}) if user_persona_info else {}
    
    # Calculate dimension averages from evaluation results
    all_scores = {}
    for result in evaluation_results:
        scores = result.get("evaluation_scores", {})
        for dimension, score in scores.items():
            if dimension not in all_scores:
                all_scores[dimension] = []
            all_scores[dimension].append(score)
    
    dimension_averages = {}
    for dimension, scores in all_scores.items():
        dimension_averages[dimension] = sum(scores) / len(scores) if scores else 0
    
    # Overall performance assessment based on extracted persona
    overall_avg = sum(dimension_averages.values()) / len(dimension_averages) if dimension_averages else 0
    
    if overall_avg >= 4.5:
        recommendations.append(f"ğŸŸ¢ é’ˆå¯¹{persona.get('role', 'ç”¨æˆ·')}çš„æ•´ä½“è¡¨ç°ä¼˜ç§€ï¼AIä»£ç†èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†{context.get('business_domain', 'ä¸šåŠ¡')}éœ€æ±‚")
    elif overall_avg >= 4.0:
        recommendations.append(f"ğŸŸ¡ å¯¹{persona.get('role', 'ç”¨æˆ·')}çš„æœåŠ¡è‰¯å¥½ï¼ŒåŸºæœ¬æ»¡è¶³{context.get('business_domain', 'ä¸šåŠ¡')}éœ€æ±‚ï¼Œæœ‰è¿›ä¸€æ­¥ä¼˜åŒ–ç©ºé—´")
    elif overall_avg >= 3.0:
        recommendations.append(f"ğŸŸ  æœåŠ¡{persona.get('role', 'ç”¨æˆ·')}çš„èƒ½åŠ›ä¸­ç­‰ï¼Œå»ºè®®é’ˆå¯¹{context.get('business_domain', 'ä¸šåŠ¡é¢†åŸŸ')}ç‰¹ç‚¹è¿›è¡Œæ”¹è¿›")
    else:
        recommendations.append(f"ğŸ”´ éœ€è¦æ˜¾è‘—æ”¹è¿›å¯¹{persona.get('role', 'ç”¨æˆ·')}çš„æœåŠ¡èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯{context.get('business_domain', 'ä¸šåŠ¡')}ç›¸å…³åŠŸèƒ½")
    
    # Dimension-specific recommendations with persona context
    if dimension_averages.get('fuzzy_understanding', 0) < 3.5:
        pain_points = context.get('pain_points', [])
        pain_context = f"ï¼Œç‰¹åˆ«æ˜¯{', '.join(pain_points[:2])}" if pain_points else ""
        recommendations.append(f"ğŸ’¡ é’ˆå¯¹{persona.get('role', 'ç”¨æˆ·')}çš„æ¨¡ç³Šç†è§£èƒ½åŠ›éœ€è¦åŠ å¼ºï¼šå¢åŠ è¿½é—®å¼•å¯¼æœºåˆ¶{pain_context}")
    
    if dimension_averages.get('answer_correctness', 0) < 3.5:
        expertise_areas = persona.get('expertise_areas', [])
        expertise_context = f"ï¼Œç‰¹åˆ«æ˜¯{', '.join(expertise_areas[:2])}é¢†åŸŸ" if expertise_areas else ""
        recommendations.append(f"ğŸ“š é’ˆå¯¹{persona.get('role', 'ç”¨æˆ·')}çš„ä¸“ä¸šå‡†ç¡®æ€§éœ€è¦æå‡ï¼šåŠ å¼ºçŸ¥è¯†åº“å»ºè®¾{expertise_context}")
    
    if dimension_averages.get('persona_alignment', 0) < 3.5:
        comm_style = persona.get('communication_style', 'ä¸“ä¸šæ²Ÿé€š')
        recommendations.append(f"ğŸ‘¥ ç”¨æˆ·åŒ¹é…åº¦æœ‰å¾…æ”¹å–„ï¼šä¼˜åŒ–è¯­è¨€é£æ ¼ä»¥é€‚åº”{comm_style}ï¼ŒåŒ¹é…{persona.get('experience_level', 'ç”¨æˆ·ç»éªŒæ°´å¹³')}")
    
    if dimension_averages.get('goal_alignment', 0) < 3.5:
        core_functions = requirements.get('core_functions', [])
        function_context = f"ï¼Œé‡ç‚¹å…³æ³¨{', '.join(core_functions[:2])}" if core_functions else ""
        recommendations.append(f"ğŸ¯ ä¸šåŠ¡ç›®æ ‡å¯¹é½åº¦éœ€è¦æ”¹è¿›ï¼šç¡®ä¿å›ç­”èƒ½å¤Ÿæ»¡è¶³{context.get('business_domain', 'ä¸šåŠ¡')}çš„å®é™…éœ€æ±‚{function_context}")
    
    # Add persona-specific targeted recommendations
    role = persona.get('role', '')
    work_env = persona.get('work_environment', '')
    
    if 'å®¢æœ' in role:
        recommendations.append(f"ğŸ§ å®¢æœåœºæ™¯ä¼˜åŒ–ï¼šé’ˆå¯¹{work_env}ç¯å¢ƒï¼Œæå‡å“åº”æ•ˆç‡å’Œæ ‡å‡†åŒ–å›ç­”")
        quality_expectations = requirements.get('quality_expectations', [])
        if quality_expectations:
            recommendations.append(f"â±ï¸ æœåŠ¡è´¨é‡æå‡ï¼šé‡ç‚¹æ»¡è¶³{', '.join(quality_expectations[:2])}ç­‰å®¢æœè´¨é‡è¦æ±‚")
    elif 'å·¥ç¨‹å¸ˆ' in role or 'ç›‘ç†' in role:
        recommendations.append(f"ğŸ”§ æŠ€æœ¯ä¸“ä¸šæ€§ï¼šåŠ å¼ºå¯¹{work_env}ç¯å¢ƒä¸‹æŠ€æœ¯è§„èŒƒå’Œæ ‡å‡†çš„æ”¯æŒ")
        if 'è§„èŒƒ' in str(context.get('primary_scenarios', [])):
            recommendations.append("ğŸ“‹ è§„èŒƒæŸ¥è¯¢ä¼˜åŒ–ï¼šå¢å¼ºå¯¹æŠ€æœ¯æ ‡å‡†å’Œæ–½å·¥è§„èŒƒçš„å¿«é€Ÿæ£€ç´¢å’Œè§£é‡Šèƒ½åŠ›")
    elif 'ç®¡ç†' in role:
        recommendations.append("ğŸ“Š ç®¡ç†å†³ç­–æ”¯æŒï¼šæä¾›æ›´å¤šæ•°æ®åˆ†æå’Œå†³ç­–å»ºè®®åŠŸèƒ½")
    
    # Add interaction preference recommendations
    interaction_goals = context.get('interaction_goals', [])
    if interaction_goals:
        recommendations.append(f"ğŸ¯ äº¤äº’ç›®æ ‡ä¼˜åŒ–ï¼šé‡ç‚¹æå‡{', '.join(interaction_goals[:2])}çš„å®ç°æ•ˆæœ")
    
    # Quality expectations based recommendations  
    quality_expectations = requirements.get('quality_expectations', [])
    if quality_expectations:
        recommendations.append(f"â­ è´¨é‡æ ‡å‡†å¯¹é½ï¼šç¡®ä¿è¾¾åˆ°{', '.join(quality_expectations[:2])}ç­‰è´¨é‡æœŸæœ›")
    
    # Limit to 6-8 most relevant recommendations
    unique_recommendations = list(dict.fromkeys(recommendations))
    return unique_recommendations[:8]

@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

@app.get("/health")
async def health_check():
    """Simple health check endpoint for debugging"""
    try:
        memory_usage = check_memory_usage()
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "memory_usage": memory_usage,
            "version": "4.0.0",
            "features": {
                "database": PYMYSQL_AVAILABLE,
                "coze_sdk": COZE_SDK_AVAILABLE,
                "document_processing": DOCUMENT_PROCESSING_AVAILABLE,
                "memory_monitoring": PSUTIL_AVAILABLE
            }
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@app.post("/api/evaluate-agent-with-file", response_model=EvaluationResponse)
async def evaluate_agent_with_file(
    agent_api_config: str = Form(...),
    requirement_file: UploadFile = File(None),
    requirement_text: str = Form(None),
    conversation_scenarios: str = Form(...),
    coze_bot_id: str = Form(None),
    evaluation_mode: str = Form("manual"),  # "auto" or "manual"
    extracted_persona: str = Form(None)     # JSON string of extracted persona
):
    """
    Enhanced evaluation endpoint supporting both automatic persona extraction and manual input
    """
    try:
        print("ğŸ¤–============================================================ğŸ¤–")
        print("   AI Agent è¯„ä¼°å¹³å° v3.0 (å¢å¼ºæ¨¡å¼)")
        print("ğŸ¤–============================================================ğŸ¤–")
        
        # Parse API configuration
        try:
            # â­ Security: Validate input length
            if len(agent_api_config) > 50000:  # 50KB limit
                raise HTTPException(status_code=413, detail="APIé…ç½®è¿‡é•¿ï¼Œè¯·æ£€æŸ¥é…ç½®å†…å®¹")
            
            api_config_dict = json.loads(agent_api_config)
            
            # â­ Security: Validate API URL if present
            if 'url' in api_config_dict and not validate_api_url(api_config_dict['url']):
                raise HTTPException(status_code=400, detail="ä¸å®‰å…¨çš„API URL")
            
            # Debug: log the received configuration structure
            print(f"ğŸ” Received API config structure: {json.dumps(api_config_dict, indent=2)}")
            logger.info(f"ğŸ” Received API config: {api_config_dict}")
            
            # Enhanced data cleaning for common frontend issues
            if isinstance(api_config_dict, dict):
                # Strategy 1: Look for common wrapping patterns
                if 'config' in api_config_dict and isinstance(api_config_dict['config'], dict):
                    print("âš ï¸ Detected config wrapped in 'config' key, unwrapping...")
                    api_config_dict = api_config_dict['config']
                elif 'api_config' in api_config_dict and isinstance(api_config_dict['api_config'], dict):
                    print("âš ï¸ Detected config wrapped in 'api_config' key, unwrapping...")
                    api_config_dict = api_config_dict['api_config']
                
                # Strategy 2: Fix the nested headers issue (common user error)
                if 'headers' in api_config_dict and isinstance(api_config_dict['headers'], dict):
                    headers = api_config_dict['headers']
                    
                    # Check if user pasted entire config into headers field
                    if 'url' in headers and 'method' in headers and 'type' in headers:
                        print("âš ï¸ Detected full config pasted in headers field, extracting...")
                        # The real config is nested in headers, extract it
                        real_config = headers.copy()
                        
                        # Clean the nested headers if it exists
                        if 'headers' in real_config and isinstance(real_config['headers'], dict):
                            real_config['headers'] = real_config['headers']
                        else:
                            real_config['headers'] = {'Content-Type': 'application/json'}
                        
                        api_config_dict = real_config
                        print(f"âœ… Extracted real config from nested headers: {api_config_dict['type']}")
                    
                    # Check for duplicate nested structure in headers
                    elif any(key in headers for key in ['type', 'url', 'method', 'timeout']):
                        print("âš ï¸ Detected config properties mixed in headers, cleaning...")
                        # Extract only valid header properties
                        valid_headers = {}
                        for key, value in headers.items():
                            if key.lower() in ['authorization', 'content-type', 'user-agent', 'accept', 'x-api-key']:
                                valid_headers[key] = value
                        
                        # If no valid headers found, use default
                        if not valid_headers:
                            valid_headers = {'Content-Type': 'application/json'}
                        
                        api_config_dict['headers'] = valid_headers
                        print(f"âœ… Cleaned headers: {valid_headers}")
                
                # Strategy 3: Ensure required fields and proper data types
                if 'timeout' in api_config_dict:
                    try:
                        api_config_dict['timeout'] = int(api_config_dict['timeout'])
                    except (ValueError, TypeError):
                        api_config_dict['timeout'] = 30
                        print("âš ï¸ Invalid timeout value, defaulting to 30 seconds")
                
                # Ensure headers is a dictionary
                if 'headers' not in api_config_dict or not isinstance(api_config_dict['headers'], dict):
                    print(f"âš ï¸ Missing or invalid headers, setting default")
                    api_config_dict['headers'] = {'Content-Type': 'application/json'}
                
                # Strategy 4: Validate required fields based on type
                config_type = api_config_dict.get('type', '')
                if config_type == 'custom-api':
                    if 'url' not in api_config_dict:
                        raise ValueError("Custom API configuration missing required 'url' field")
                    if 'method' not in api_config_dict:
                        api_config_dict['method'] = 'POST'
                        print("âš ï¸ Missing method, defaulting to POST")
                elif config_type in ['coze-agent', 'coze-bot']:
                    if 'url' not in api_config_dict:
                        # Set default Coze URL based on type
                        if config_type == 'coze-agent':
                            api_config_dict['url'] = 'https://api.coze.cn/open_api/v2/chat'
                        else:
                            api_config_dict['url'] = 'https://api.coze.cn/open_api/v2/chat'
                        print(f"âš ï¸ Missing URL for {config_type}, using default")
            
            print(f"ğŸ”§ Cleaned API config: {json.dumps(api_config_dict, indent=2)}")
            
            api_config = APIConfig(**api_config_dict)
            logger.info(f"âœ… API config parsed successfully: {api_config.type}")
        except json.JSONDecodeError as je:
            error_msg = f"JSONæ ¼å¼é”™è¯¯: {str(je)}"
            logger.error(f"âŒ JSON parsing failed: {error_msg}")
            logger.error(f"âŒ Original config string: {agent_api_config}")
            raise HTTPException(status_code=400, detail=f"APIé…ç½®JSONæ ¼å¼é”™è¯¯: {error_msg}")
        except ValueError as ve:
            error_msg = str(ve)
            logger.error(f"âŒ Config validation failed: {error_msg}")
            logger.error(f"âŒ Original config string: {agent_api_config}")
            raise HTTPException(status_code=400, detail=f"APIé…ç½®éªŒè¯å¤±è´¥: {error_msg}")
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ API config parsing failed: {error_msg}")
            logger.error(f"âŒ Original config string: {agent_api_config}")
            raise HTTPException(status_code=400, detail=f"APIé…ç½®è§£æå¤±è´¥: {error_msg}")
        
        # Handle requirement document
        requirement_context = ""
        user_persona_info = None
        
        if evaluation_mode == "auto" and extracted_persona:
            # Use extracted persona information
            try:
                user_persona_info = json.loads(extracted_persona)
                print("ğŸ­ Using extracted user persona information")
            except:
                print("âš ï¸ Failed to parse extracted persona, falling back to manual mode")
                evaluation_mode = "manual"
        
        if requirement_file and requirement_file.filename:
            print(f"ğŸ“„ Processing uploaded file: {requirement_file.filename}")
            file_content = await requirement_file.read()
            
            if requirement_file.filename.endswith('.docx'):
                requirement_context = await extract_text_from_docx(file_content)
            elif requirement_file.filename.endswith('.pdf'):
                requirement_context = await extract_text_from_pdf(file_content)
            elif requirement_file.filename.endswith('.txt'):
                requirement_context = file_content.decode('utf-8', errors='ignore')
            else:
                print("âš ï¸ Unsupported file format, using text input instead")
                
        if not requirement_context and requirement_text:
            # â­ Security: Sanitize user input
            requirement_context = sanitize_user_input(requirement_text, max_length=100000)
        
        # Parse conversation scenarios
        scenarios = []
        
        if evaluation_mode == "auto" and user_persona_info:
            # Auto mode: generate scenarios based on extracted persona
            print("ğŸ¯ Auto mode: Generating conversation scenarios based on extracted persona...")
            scenarios = await generate_conversation_scenarios_from_persona(user_persona_info)
            print(f"âœ… Generated {len(scenarios)} scenarios based on user persona: {user_persona_info['user_persona']['role']}")
            
        else:
            # Manual mode or fallback: parse provided scenarios
            try:
                scenarios = json.loads(conversation_scenarios)
            except Exception as e:
                if evaluation_mode == "manual":
                    raise HTTPException(status_code=400, detail=f"åœºæ™¯é…ç½®è§£æå¤±è´¥: {str(e)}")
                else:
                    # Auto mode but no valid persona - generate basic scenarios
                    print("âš ï¸ Auto mode but no persona available, generating basic scenarios...")
                    scenarios = [
                        {
                            "title": "åŸºç¡€å’¨è¯¢åœºæ™¯",
                            "context": "é€šç”¨å’¨è¯¢ç¯å¢ƒ",
                            "user_profile": "æ™®é€šç”¨æˆ·",
                            "turns": ["æˆ‘æœ‰ä¸ªé—®é¢˜", "èƒ½è¯¦ç»†è¯´æ˜ä¸€ä¸‹å—", "è°¢è°¢"]
                        }
                    ]

        if not scenarios:
            if evaluation_mode == "auto":
                raise HTTPException(status_code=400, detail="è‡ªåŠ¨æ¨¡å¼ä¸‹æ— æ³•ç”Ÿæˆå¯¹è¯åœºæ™¯ï¼Œè¯·æ£€æŸ¥ç”¨æˆ·ç”»åƒæå–æ˜¯å¦æˆåŠŸ")
            else:
                raise HTTPException(status_code=400, detail="è¯·è‡³å°‘é…ç½®ä¸€ä¸ªå¯¹è¯åœºæ™¯")

        print(f"ğŸ“‹ Total scenarios to evaluate: {len(scenarios)}")
        
        # Enhanced evaluation with persona-aware context
        evaluation_results = []
        
        for i, scenario in enumerate(scenarios, 1):
            print(f"ğŸ“‹ åœºæ™¯ {i}/{len(scenarios)}: {scenario.get('title', 'æœªå‘½ååœºæ™¯')}")
            
            # Enhance scenario with extracted persona if available
            if evaluation_mode == "auto" and user_persona_info:
                scenario = enhance_scenario_with_persona(scenario, user_persona_info)
                print(f"ğŸ­ Enhanced scenario with extracted persona: {user_persona_info['user_persona']['role']}")
            
            result = await evaluate_single_conversation_scenario(
                api_config=api_config,
                scenario=scenario,
                requirement_context=requirement_context,
                evaluation_mode=evaluation_mode,
                user_persona_info=user_persona_info
            )
            
            if result:
                evaluation_results.append(result)
            else:
                print(f"âš ï¸ åœºæ™¯ {i} è¯„ä¼°å¤±è´¥ï¼Œè·³è¿‡")

        if not evaluation_results:
            raise HTTPException(status_code=500, detail="æ‰€æœ‰åœºæ™¯è¯„ä¼°å‡å¤±è´¥ï¼Œè¯·æ£€æŸ¥AI Agenté…ç½®")

        # Generate summary
        summary = generate_evaluation_summary(evaluation_results, requirement_context)
        
        # Enhanced recommendations with persona awareness
        recommendations = generate_enhanced_recommendations(evaluation_results, user_persona_info)
        
        response_data = {
            "evaluation_summary": summary,
            "conversation_records": evaluation_results,
            "recommendations": recommendations,
            "evaluation_mode": evaluation_mode,
            "user_persona_info": user_persona_info,
                "timestamp": datetime.now().isoformat()
        }
        
        print(f"ğŸ¯ æ€»ä½“è¯„ä¼°å®Œæˆï¼ç»¼åˆå¾—åˆ†: {summary.get('overall_score', 0):.2f}/5.0")
        print(f"ğŸ“Š è¯„ä¼°æ¨¡å¼: {evaluation_mode}")
        if user_persona_info:
            print(f"ğŸ­ ç”¨æˆ·ç”»åƒ: {user_persona_info['user_persona']['role']}")
        
        return response_data
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Evaluation failed with error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è¯„ä¼°è¿‡ç¨‹å‡ºé”™: {str(e)}")

@app.post("/api/evaluate-agent-dynamic", response_model=EvaluationResponse)
async def evaluate_agent_dynamic(
    agent_api_config: str = Form(...),
    requirement_file: UploadFile = File(None),
    requirement_text: str = Form(None),
    extracted_persona: str = Form(None),  # JSON string of extracted persona
    use_raw_messages: bool = Form(False)  # Use raw user messages without persona enhancement
):
    """
    New dynamic evaluation endpoint implementing conversational workflow:
    1. Extract persona from document
    2. Generate 2 scenarios with dynamic conversations
    3. Conduct 2-3 rounds per scenario based on AI responses
    4. Generate comprehensive final report
    """
    # Add timeout protection for the entire evaluation (increased to 10 minutes)
    evaluation_timeout = 600  # 10 minutes total timeout
    
    # Check memory usage before starting evaluation
    memory_usage = check_memory_usage()
    if memory_usage and memory_usage > config.MEMORY_WARNING_THRESHOLD:
        logger.warning(f"âš ï¸ High memory usage detected: {memory_usage:.1f}%")
    
    try:
        # Wrap the entire evaluation in a timeout
        evaluation_result = await asyncio.wait_for(
            _perform_dynamic_evaluation_internal(
                agent_api_config, requirement_file, requirement_text, extracted_persona, use_raw_messages
            ),
            timeout=evaluation_timeout
        )
        return evaluation_result
        
    except asyncio.TimeoutError:
        logger.error(f"â° Dynamic evaluation timed out after {evaluation_timeout} seconds")
        raise HTTPException(
            status_code=408, 
            detail=f"è¯„ä¼°è¶…æ—¶ï¼šè¯„ä¼°è¿‡ç¨‹è¶…è¿‡{evaluation_timeout//60}åˆ†é’Ÿé™åˆ¶ã€‚å»ºè®®ï¼š1) æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œ2) ç®€åŒ–éœ€æ±‚æ–‡æ¡£å†…å®¹ï¼Œ3) ç¡®è®¤AI Agentå“åº”é€Ÿåº¦æ­£å¸¸ï¼Œ4) é‡æ–°å¯åŠ¨æœåŠ¡å™¨é‡Šæ”¾å†…å­˜ã€‚"
        )
    except HTTPException:
        # Re-raise HTTP exceptions as-is
        raise
    except Exception as e:
        # Catch any other unexpected exceptions
        logger.error(f"âŒ Unexpected error in dynamic evaluation: {str(e)}")
        logger.error(f"Full traceback: {traceback.format_exc()}")
        raise HTTPException(
            status_code=500, 
            detail=f"åŠ¨æ€è¯„ä¼°è¿‡ç¨‹å‡ºç°æ„å¤–é”™è¯¯: {str(e)}. è¯·æ£€æŸ¥æœåŠ¡å™¨æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚"
        )

async def _perform_dynamic_evaluation_internal(
    agent_api_config: str,
    requirement_file: UploadFile,
    requirement_text: str,
    extracted_persona: str,
    use_raw_messages: bool = False
) -> Dict:
    """
    Internal function to perform dynamic evaluation with proper error handling
    """
    try:
        logger.info("ğŸš€ Starting dynamic evaluation...")
        print("ğŸš€============================================================ğŸš€")
        print("   AI Agent åŠ¨æ€å¯¹è¯è¯„ä¼°å¹³å° v4.0")
        print(f"ğŸ” æ¶ˆæ¯å¤„ç†æ¨¡å¼: {'åŸå§‹æ¶ˆæ¯æ¨¡å¼ (RAW)' if use_raw_messages else 'å¢å¼ºæ¶ˆæ¯æ¨¡å¼ (ENHANCED)'}")
        print("ğŸš€============================================================ğŸš€")
        
        # Parse API configuration
        try:
            # â­ Security: Validate input length
            if len(agent_api_config) > 50000:  # 50KB limit
                raise HTTPException(status_code=413, detail="APIé…ç½®è¿‡é•¿ï¼Œè¯·æ£€æŸ¥é…ç½®å†…å®¹")
            
            api_config_dict = json.loads(agent_api_config)
            
            # â­ Security: Validate API URL if present
            if 'url' in api_config_dict and not validate_api_url(api_config_dict['url']):
                raise HTTPException(status_code=400, detail="ä¸å®‰å…¨çš„API URL")
            
            # Debug: log the received configuration structure
            print(f"ğŸ” Received API config structure: {json.dumps(api_config_dict, indent=2)}")
            logger.info(f"ğŸ” Received API config: {api_config_dict}")
            
            # Check if the config is wrapped in an extra layer (common frontend issue)
            if isinstance(api_config_dict, dict):
                # Look for common wrapping patterns
                if 'config' in api_config_dict and isinstance(api_config_dict['config'], dict):
                    print("âš ï¸ Detected config wrapped in 'config' key, unwrapping...")
                    api_config_dict = api_config_dict['config']
                elif 'headers' in api_config_dict and 'url' in api_config_dict.get('headers', {}):
                    print("âš ï¸ Detected config wrapped in 'headers' key, unwrapping...")
                    api_config_dict = api_config_dict['headers']
                elif 'api_config' in api_config_dict and isinstance(api_config_dict['api_config'], dict):
                    print("âš ï¸ Detected config wrapped in 'api_config' key, unwrapping...")
                    api_config_dict = api_config_dict['api_config']
            
            # Additional data cleaning for common frontend issues
            if isinstance(api_config_dict, dict):
                # Ensure timeout is an integer
                if 'timeout' in api_config_dict:
                    try:
                        api_config_dict['timeout'] = int(api_config_dict['timeout'])
                    except (ValueError, TypeError):
                        api_config_dict['timeout'] = 30
                
                # Ensure headers is a dictionary
                if 'headers' in api_config_dict and not isinstance(api_config_dict['headers'], dict):
                    print(f"âš ï¸ Invalid headers format: {type(api_config_dict['headers'])}, resetting to empty dict")
                    api_config_dict['headers'] = {}
            
            print(f"ğŸ”§ Cleaned API config: {json.dumps(api_config_dict, indent=2)}")
            
            api_config = APIConfig(**api_config_dict)
            logger.info(f"âœ… API config parsed successfully: {api_config.type}")
        except Exception as e:
            logger.error(f"âŒ API config parsing failed: {str(e)}")
            logger.error(f"âŒ Original config string: {agent_api_config}")
            raise HTTPException(status_code=400, detail=f"APIé…ç½®è§£æå¤±è´¥: {str(e)}")
        
        # Handle requirement document
        requirement_context = ""
        user_persona_info = None
        
        # Step 1: Process requirement document and extract persona
        try:
            # â­ Memory check before document processing
            memory_usage = check_memory_usage()
            if memory_usage > config.MEMORY_CRITICAL_THRESHOLD:
                raise HTTPException(status_code=507, detail=f"å†…å­˜ä¸è¶³ ({memory_usage:.1f}%)")
            
            if requirement_file and requirement_file.filename:
                logger.info(f"ğŸ“„ Processing uploaded file: {requirement_file.filename}")
                print(f"ğŸ“„ Processing uploaded file: {requirement_file.filename}")
                requirement_context = await process_uploaded_document_improved(requirement_file)
            elif requirement_text:
                logger.info("ğŸ“ Using provided text content")
                # â­ Security: Sanitize user input
                requirement_context = sanitize_user_input(requirement_text, max_length=100000)
            
            if not requirement_context:
                raise HTTPException(status_code=400, detail="è¯·æä¾›éœ€æ±‚æ–‡æ¡£æˆ–æ–‡æœ¬å†…å®¹")
                
            logger.info(f"âœ… Document processed, length: {len(requirement_context)} characters")
        except Exception as e:
            logger.error(f"âŒ Document processing failed: {str(e)}")
            raise HTTPException(status_code=400, detail=f"æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}")
        
        # Step 2: Extract user persona from requirement document using DeepSeek
        try:
            if extracted_persona:
                try:
                    user_persona_info = json.loads(extracted_persona)
                    logger.info(f"ğŸ­ Using provided persona: {user_persona_info.get('user_persona', {}).get('role', 'æœªçŸ¥è§’è‰²')}")
                    print(f"ğŸ­ ä½¿ç”¨æå–çš„ç”¨æˆ·ç”»åƒ: {user_persona_info.get('user_persona', {}).get('role', 'æœªçŸ¥è§’è‰²')}")
                except Exception as pe:
                    logger.warning(f"âš ï¸ Persona parsing failed: {str(pe)}")
                    print("âš ï¸ ç”»åƒæ•°æ®è§£æå¤±è´¥ï¼Œé‡æ–°æå–...")
                    user_persona_info = None
            
            if not user_persona_info:
                logger.info("ğŸ§  Extracting user persona from document...")
                print("ğŸ§  ä»éœ€æ±‚æ–‡æ¡£ä¸­æå–ç”¨æˆ·ç”»åƒ...")
                user_persona_info = await extract_user_persona_with_deepseek(requirement_context)
                if not user_persona_info:
                    raise HTTPException(status_code=400, detail="æ— æ³•ä»éœ€æ±‚æ–‡æ¡£ä¸­æå–æœ‰æ•ˆçš„ç”¨æˆ·ç”»åƒä¿¡æ¯")
                    
            logger.info("âœ… User persona extracted successfully")
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"âŒ Persona extraction failed: {str(e)}")
            logger.error(f"Full traceback: {traceback.format_exc()}")
            raise HTTPException(status_code=500, detail=f"ç”¨æˆ·ç”»åƒæå–å¤±è´¥: {str(e)}")
        
        # Step 3: Conduct dynamic multi-scenario evaluation
        try:
            # â­ Memory check before evaluation
            memory_usage = check_memory_usage()
            if memory_usage > config.MEMORY_CRITICAL_THRESHOLD:
                raise HTTPException(status_code=507, detail=f"å†…å­˜ä¸è¶³ ({memory_usage:.1f}%)")
            
            logger.info("ğŸ¯ Starting dynamic conversation evaluation...")
            print("ğŸ¯ å¼€å§‹åŠ¨æ€å¤šè½®å¯¹è¯è¯„ä¼°...")
            evaluation_results = await conduct_dynamic_multi_scenario_evaluation(
                api_config, user_persona_info, requirement_context, use_raw_messages
            )
            
            if not evaluation_results:
                raise HTTPException(status_code=500, detail="åŠ¨æ€å¯¹è¯è¯„ä¼°å¤±è´¥ï¼Œè¯·æ£€æŸ¥AI Agenté…ç½®")
                
            logger.info(f"âœ… Evaluation completed with {len(evaluation_results)} scenarios")
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"âŒ Evaluation failed: {str(e)}")
            logger.error(f"Full traceback: {traceback.format_exc()}")
            raise HTTPException(status_code=500, detail=f"åŠ¨æ€å¯¹è¯è¯„ä¼°å¤±è´¥: {str(e)}")
        
        # Step 4: Generate comprehensive final report
        try:
            logger.info("ğŸ“Š Generating comprehensive report...")
            print("ğŸ“Š ç”Ÿæˆç»¼åˆè¯„ä¼°æŠ¥å‘Š...")
            comprehensive_report = await generate_final_comprehensive_report(
                evaluation_results, user_persona_info, requirement_context
            )
            logger.info("âœ… Report generated successfully")
        except Exception as e:
            logger.error(f"âŒ Report generation failed: {str(e)}")
            logger.error(f"Full traceback: {traceback.format_exc()}")
            # Use fallback report generation
            comprehensive_report = {
                "improvement_recommendations": ["ç³»ç»Ÿå»ºè®®ï¼šåŠ å¼ºå¯¹è¯ç†è§£èƒ½åŠ›", "ç³»ç»Ÿå»ºè®®ï¼šæé«˜å›ç­”å‡†ç¡®æ€§"],
                "extracted_persona_summary": user_persona_info,
                "persona_alignment_analysis": "åŸºäºç³»ç»Ÿåˆ†æç”Ÿæˆ",
                "business_goal_achievement": "è¯„ä¼°å®Œæˆ"
            }
        
        # Calculate overall summary
        try:
            # Calculate from scenario scores (which are now in 5-point scale)
            overall_score_5 = sum(r.get('scenario_score', 0) for r in evaluation_results) / len(evaluation_results) if evaluation_results else 0
            overall_score_100 = sum(r.get('scenario_score_100', 0) for r in evaluation_results) / len(evaluation_results) if evaluation_results else 0
            total_conversations = sum(len(r.get('conversation_history', [])) for r in evaluation_results)
            
            # Generate comprehensive evaluation summary  
            evaluation_summary = generate_evaluation_summary(evaluation_results, requirement_context)
            
            response_data = {
                "evaluation_summary": {
                    "overall_score": round(overall_score_5, 2),  # Keep for compatibility
                    "overall_score_100": round(overall_score_100, 2),  # Primary 100-point scale
                    "total_scenarios": len(evaluation_results),
                    "total_conversations": total_conversations,
                    "framework": "åŠ¨æ€å¤šè½®å¯¹è¯è¯„ä¼° (100åˆ†åˆ¶)",
                    "dimension_scores_100": evaluation_summary.get("dimensions_100", {}),
                    "dimension_scores": evaluation_summary.get("dimensions", {}),  # Keep for compatibility
                    "comprehensive_analysis": comprehensive_report,
                    "extracted_persona_display": {
                        "user_role": user_persona_info.get('user_persona', {}).get('role', 'ä¸“ä¸šç”¨æˆ·'),
                        "business_domain": user_persona_info.get('usage_context', {}).get('business_domain', 'ä¸“ä¸šæœåŠ¡'),
                        "experience_level": user_persona_info.get('user_persona', {}).get('experience_level', 'ä¸­ç­‰ç»éªŒ'),
                        "communication_style": user_persona_info.get('user_persona', {}).get('communication_style', 'ä¸“ä¸šæ²Ÿé€š'),
                        "work_environment": user_persona_info.get('user_persona', {}).get('work_environment', 'ä¸“ä¸šå·¥ä½œç¯å¢ƒ'),
                        "primary_scenarios": user_persona_info.get('usage_context', {}).get('primary_scenarios', ['ä¸“ä¸šå’¨è¯¢']),
                        "pain_points": user_persona_info.get('usage_context', {}).get('pain_points', ['ä¿¡æ¯è·å–']),
                        "core_functions": user_persona_info.get('extracted_requirements', {}).get('core_functions', ['ä¿¡æ¯æŸ¥è¯¢']),
                        "quality_expectations": user_persona_info.get('extracted_requirements', {}).get('quality_expectations', ['å‡†ç¡®æ€§']),
                        "extraction_method": "DeepSeekæ™ºèƒ½æå–åˆ†æ",
                        "document_length": len(requirement_context) if requirement_context else 0
                    },
                    "scoring_system": {
                        "scale": "0-100åˆ†åˆ¶",
                        "grade_levels": {
                            "90-100": "ä¼˜ç§€ (Excellent)",
                            "80-89": "è‰¯å¥½ (Good)", 
                            "70-79": "ä¸­ç­‰ (Average)",
                            "60-69": "åŠæ ¼ (Pass)",
                            "50-59": "ä¸åŠæ ¼ (Below Pass)",
                            "0-49": "éœ€è¦æ”¹è¿› (Needs Improvement)"
                        }
                    }
                },
                "conversation_records": evaluation_results,
                "recommendations": comprehensive_report.get('improvement_recommendations', []),
                "extracted_persona_full": comprehensive_report.get('extracted_persona_summary', {}),
                "persona_alignment_analysis": comprehensive_report.get('persona_alignment_analysis', ''),
                "business_goal_achievement": comprehensive_report.get('business_goal_achievement', ''),
                "detailed_context_display": {
                    "requirement_document_summary": {
                        "content_length": len(requirement_context) if requirement_context else 0,
                        "content_preview": requirement_context[:500] + "..." if requirement_context and len(requirement_context) > 500 else requirement_context,
                        "analysis_basis": "åŸºäºä¸Šä¼ çš„éœ€æ±‚æ–‡æ¡£è¿›è¡ŒAIæ™ºèƒ½åˆ†æ"
                    },
                    "evaluation_methodology": {
                        "conversation_generation": "DeepSeekåŠ¨æ€ç”Ÿæˆå¯¹è¯åœºæ™¯",
                        "response_evaluation": "å¤šç»´åº¦100åˆ†åˆ¶è¯„ä¼°",
                        "persona_matching": "åŸºäºæ–‡æ¡£æå–çš„ç”¨æˆ·ç”»åƒè¿›è¡Œä¸ªæ€§åŒ–æµ‹è¯•"
                    },
                    "technical_details": {
                        "api_type": "Dify API" if "/v1/chat-messages" in api_config.url else "Coze API" if "coze" in api_config.url.lower() else "è‡ªå®šä¹‰API",
                        "conversation_turns": total_conversations,
                        "evaluation_dimensions": len(evaluation_results[0].get('evaluation_scores', {})) if evaluation_results else 3
                    }
                },
                "evaluation_mode": "dynamic",
                "user_persona_info": user_persona_info,
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"ğŸ¯ Dynamic evaluation completed successfully! Score: {overall_score_100:.2f}/100.0")
            print(f"ğŸ¯ åŠ¨æ€è¯„ä¼°å®Œæˆï¼ç»¼åˆå¾—åˆ†: {overall_score_100:.2f}/100.0")
            print(f"ğŸ“Š è¯„ä¼°åœºæ™¯: {len(evaluation_results)} ä¸ª")
            print(f"ğŸ’¬ å¯¹è¯è½®æ¬¡: {total_conversations} è½®")
            print(f"ğŸ­ ç”¨æˆ·ç”»åƒ: {user_persona_info.get('user_persona', {}).get('role', 'æœªçŸ¥è§’è‰²')}")
            
            # Monitor response size and optimize if needed
            import json
            import sys
            response_json = json.dumps(response_data, ensure_ascii=False, default=str)
            response_size_mb = sys.getsizeof(response_json) / (1024 * 1024)
            
            logger.info(f"ğŸ“Š Response size: {response_size_mb:.2f} MB")
            print(f"ğŸ“Š Response size: {response_size_mb:.2f} MB")
            
            # If response is too large (>50MB), optimize it
            if response_size_mb > 50:
                logger.warning(f"âš ï¸ Large response detected ({response_size_mb:.2f} MB), optimizing...")
                print(f"âš ï¸ Large response detected ({response_size_mb:.2f} MB), optimizing...")
                
                # Reduce conversation history verbosity for large responses
                for record in response_data.get("conversation_records", []):
                    for turn in record.get("conversation_history", []):
                        # Truncate very long AI responses
                        if len(turn.get("ai_response", "")) > 5000:
                            turn["ai_response"] = turn["ai_response"][:5000] + "\n...[å“åº”å·²æˆªæ–­ï¼Œå®Œæ•´å†…å®¹è¯·æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š]"
                        
                        # Truncate very long evaluation explanations
                        for key, value in record.get("evaluation_scores_with_explanations", {}).items():
                            if isinstance(value, dict) and len(str(value.get("detailed_analysis", ""))) > 2000:
                                value["detailed_analysis"] = str(value["detailed_analysis"])[:2000] + "...[è¯¦ç»†åˆ†æå·²æˆªæ–­]"
            
            # Store the response before attempting database save
            final_response = response_data.copy()
            
            # Auto-save to database if enabled (non-blocking)
            if config.ENABLE_AUTO_SAVE:
                try:
                    # Use asyncio.create_task to make database save non-blocking
                    async def save_to_db():
                        try:
                            session_id = await save_evaluation_to_database(response_data, requirement_context)
                            if session_id:
                                print(f"ğŸ’¾ è¯„ä¼°ç»“æœå·²è‡ªåŠ¨ä¿å­˜åˆ°æ•°æ®åº“ï¼Œä¼šè¯ID: {session_id}")
                            else:
                                print("âš ï¸ æ•°æ®åº“è‡ªåŠ¨ä¿å­˜å¤±è´¥ï¼Œä½†è¯„ä¼°ç»“æœä»ç„¶å¯ç”¨")
                        except Exception as e:
                            print(f"âš ï¸ æ•°æ®åº“ä¿å­˜å¼‚å¸¸ï¼Œä½†ä¸å½±å“è¯„ä¼°ç»“æœ: {str(e)}")
                    
                    # Create background task for database save
                    asyncio.create_task(save_to_db())
                    
                    # Attempt quick database save with timeout
                    try:
                        session_id = await asyncio.wait_for(
                            save_evaluation_to_database(response_data, requirement_context),
                            timeout=5.0  # 5 second timeout for database save
                        )
                        if session_id:
                            final_response["database_session_id"] = session_id
                            print(f"ğŸ’¾ è¯„ä¼°ç»“æœå·²è‡ªåŠ¨ä¿å­˜åˆ°æ•°æ®åº“ï¼Œä¼šè¯ID: {session_id}")
                    except asyncio.TimeoutError:
                        print("âš ï¸ æ•°æ®åº“ä¿å­˜è¶…æ—¶ï¼Œå·²åˆ›å»ºåå°ä»»åŠ¡ç»§ç»­ä¿å­˜")
                    except Exception as e:
                        print(f"âš ï¸ æ•°æ®åº“ä¿å­˜å¼‚å¸¸ï¼Œä½†ä¸å½±å“è¯„ä¼°ç»“æœ: {str(e)}")
                        
                except Exception as e:
                    print(f"âš ï¸ æ•°æ®åº“ä¿å­˜æ¨¡å—å¼‚å¸¸: {str(e)}")
            
            # Final response validation and optimization
            try:
                # Ensure the response can be JSON serialized
                test_json = json.dumps(final_response, ensure_ascii=False, default=str)
                final_size_mb = sys.getsizeof(test_json) / (1024 * 1024)
                logger.info(f"âœ… Final response ready: {final_size_mb:.2f} MB")
                print(f"âœ… Final response ready: {final_size_mb:.2f} MB")
                
                # Add response metadata
                final_response["response_metadata"] = {
                    "size_mb": round(final_size_mb, 2),
                    "generation_time": datetime.now().isoformat(),
                    "optimized": response_size_mb > 50,
                    "version": "4.0"
                }
                
                return final_response
                
            except Exception as json_error:
                logger.error(f"âŒ Response serialization failed: {str(json_error)}")
                print(f"âŒ Response serialization failed: {str(json_error)}")
                
                # Return a minimal response if serialization fails
                return {
                    "evaluation_summary": {
                        "overall_score_100": round(overall_score_100, 2),
                        "total_scenarios": len(evaluation_results),
                        "error": "Full response too large, providing summary only"
                    },
                    "conversation_records": [],
                    "recommendations": ["ç³»ç»Ÿå»ºè®®ï¼šå“åº”è¿‡å¤§ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š"],
                    "timestamp": datetime.now().isoformat(),
                    "error_info": "Response optimization failed"
                }
            
        except Exception as e:
            logger.error(f"âŒ Response data assembly failed: {str(e)}")
            logger.error(f"Full traceback: {traceback.format_exc()}")
            raise HTTPException(status_code=500, detail=f"å“åº”æ•°æ®ç»„è£…å¤±è´¥: {str(e)}")
        
    except HTTPException:
        # Re-raise HTTP exceptions as-is
        raise
    except Exception as e:
        # Catch any other unexpected exceptions
        logger.error(f"âŒ Unexpected error in dynamic evaluation: {str(e)}")
        logger.error(f"Full traceback: {traceback.format_exc()}")
        raise HTTPException(
            status_code=500, 
            detail=f"åŠ¨æ€è¯„ä¼°è¿‡ç¨‹å‡ºç°æ„å¤–é”™è¯¯: {str(e)}. è¯·æ£€æŸ¥æœåŠ¡å™¨æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚"
        )

def enhance_scenario_with_persona(scenario: Dict, user_persona_info: Dict) -> Dict:
    """
    Enhance conversation scenario with extracted user persona information
    """
    enhanced_scenario = scenario.copy()
    
    persona = user_persona_info.get('user_persona', {})
    context = user_persona_info.get('usage_context', {})
    ai_role = user_persona_info.get('ai_role_simulation', {})
    
    # Enhance user profile
    if not scenario.get('user_profile') or scenario.get('user_profile') == '':
        enhanced_scenario['user_profile'] = f"{persona.get('role', 'ä¸“ä¸šç”¨æˆ·')}ï¼Œ{persona.get('experience_level', 'æœ‰ç»éªŒ')}"
    
    # Enhance context if not provided
    if not scenario.get('context') or scenario.get('context') == '':
        work_env = persona.get('work_environment', '')
        business_domain = context.get('business_domain', '')
        enhanced_scenario['context'] = f"{work_env} - {business_domain}" if work_env and business_domain else work_env or business_domain or "ä¸“ä¸šå·¥ä½œç¯å¢ƒ"
    
    # Add persona-aware conversation approach
    enhanced_scenario['conversation_approach'] = ai_role.get('conversation_approach', 'ç›´æ¥ä¸“ä¸šæé—®')
    enhanced_scenario['language_style'] = ai_role.get('language_characteristics', 'ä¸“ä¸šæœ¯è¯­ä¸é€šä¿—è§£é‡Šç»“åˆ')
    
    return enhanced_scenario

async def evaluate_single_conversation_scenario(
    api_config: APIConfig,
    scenario: Dict,
    requirement_context: str = "",
    evaluation_mode: str = "manual",
    user_persona_info: Dict = None
) -> Optional[Dict]:
    """
    Enhanced single scenario evaluation with persona awareness
    """
    try:
        print(f"ğŸ—£ï¸ å¼€å§‹å¯¹è¯åœºæ™¯: {scenario.get('title', 'æœªå‘½ååœºæ™¯')}")
        
        conversation_history = []
        turns = scenario.get('turns', [])
        
        if not turns:
            print("âš ï¸ åœºæ™¯æ²¡æœ‰é…ç½®å¯¹è¯è½®æ¬¡")
            return None
            
        # Enhanced conversation simulation with persona context
        for turn_num, user_message in enumerate(turns, 1):
            if not user_message.strip():
                continue
                
            print(f"ğŸ’¬ ç¬¬ {turn_num} è½®å¯¹è¯: {user_message[:50]}...")
            
            # Add persona context to the message if in auto mode
            enhanced_message = user_message
            if evaluation_mode == "auto" and user_persona_info:
                persona_context = f"[ä½œä¸º{user_persona_info['user_persona']['role']}ï¼Œ{user_persona_info['user_persona']['communication_style']}] {user_message}"
                enhanced_message = persona_context
            
            try:
                ai_response = await call_ai_agent_api(api_config, enhanced_message)
                
                if ai_response:
                    conversation_history.append({
                        "turn": turn_num,
                        "user_message": user_message,  # Store original message for display
                        "enhanced_message": enhanced_message if evaluation_mode == "auto" else user_message,
                        "ai_response": ai_response
                    })
                    print(f"âœ… AIå“åº”: {ai_response[:100]}...")
                else:
                    print(f"âŒ ç¬¬ {turn_num} è½®AIæ— å“åº”")
                    
            except Exception as e:
                print(f"âŒ ç¬¬ {turn_num} è½®å¯¹è¯å¤±è´¥: {str(e)}")
                continue
        
        if not conversation_history:
            print("âŒ åœºæ™¯å¯¹è¯å®Œå…¨å¤±è´¥")
            return None
        
        # Enhanced evaluation with persona awareness
        evaluation_scores, explanations = await evaluate_conversation_with_deepseek(
            conversation_history, scenario, requirement_context, user_persona_info
        )
        
        scenario_score = sum(evaluation_scores.values()) / len(evaluation_scores) if evaluation_scores else 0
        print(f"ğŸ¯ åœºæ™¯å¾—åˆ†: {scenario_score:.2f}/5.0")
        
        return {
            "scenario": {
                "title": scenario.get('title', 'æœªå‘½ååœºæ™¯'),
                "context": f"{user_persona_info.get('usage_context', {}).get('business_domain', 'ä¸“ä¸šæœåŠ¡') if user_persona_info else scenario.get('context', 'ä¸“ä¸šå·¥ä½œç¯å¢ƒ')} - {scenario.get('context', 'ä¸“ä¸šå·¥ä½œç¯å¢ƒ')}",
                "user_profile": f"{user_persona_info.get('user_persona', {}).get('role', 'ç”¨æˆ·') if user_persona_info else scenario.get('user_profile', 'ç”¨æˆ·')}ï¼Œ{user_persona_info.get('user_persona', {}).get('experience_level', 'ä¸­ç­‰ç»éªŒ') if user_persona_info else 'ä¸­ç­‰ç»éªŒ'}ï¼Œ{user_persona_info.get('user_persona', {}).get('communication_style', 'ä¸“ä¸šæ²Ÿé€š') if user_persona_info else 'ä¸“ä¸šæ²Ÿé€š'}"
            },
            "conversation_history": conversation_history,
            "evaluation_scores": evaluation_scores,
            "evaluation_scores_with_explanations": explanations,  # Add detailed explanations
            "explanations": explanations,
            "scenario_score": scenario_score,
            "evaluation_mode": evaluation_mode,
            "persona_enhanced": evaluation_mode == "auto" and user_persona_info is not None,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"âŒ åœºæ™¯è¯„ä¼°å¼‚å¸¸: {str(e)}")
        return None

async def perform_deepseek_evaluations(evaluation_prompts: Dict, base_context: str, requirement_context: str) -> tuple:
    """
    Perform DeepSeek evaluations for all dimensions
    """
    try:
        # Standard evaluation prompts 
        if not evaluation_prompts:  # If prompts not provided, create them
            evaluation_prompts = {
                "fuzzy_understanding": f"""
{base_context}

è¯·è¯„ä¼°AIåœ¨æ¨¡ç³Šç†è§£ä¸è¿½é—®èƒ½åŠ›æ–¹é¢çš„è¡¨ç°ã€‚

è¯„åˆ†æ ‡å‡† (1-5åˆ†):
1åˆ†: å®Œå…¨æ— æ³•ç†è§£æ¨¡ç³Šè¡¨è¾¾ï¼Œç›´æ¥ç»™å‡ºé”™è¯¯æˆ–æ— å…³å›ç­”
2åˆ†: ç†è§£é”™è¯¯ä¸”æœªä¸»åŠ¨è¿½é—®ï¼Œå¯èƒ½è¯¯å¯¼ç”¨æˆ·
3åˆ†: éƒ¨åˆ†ç†è§£ä½†å¼•å¯¼ä¸è¶³ï¼Œä»…ç»™å‡ºéƒ¨åˆ†æœ‰ç”¨ä¿¡æ¯
4åˆ†: åŸºæœ¬ç†è§£æ¨¡ç³Šè¡¨è¾¾ä¸”æœ‰ä¸€å®šå¼•å¯¼ï¼Œä½†è¿½é—®ä¸å¤Ÿæ·±å…¥
5åˆ†: å‡†ç¡®ç†è§£æ¨¡ç³Šè¡¨è¾¾å¹¶æœ‰æ•ˆå¼•å¯¼ç”¨æˆ·æ¾„æ¸…éœ€æ±‚

è¯·ç»™å‡ºå…·ä½“è¯„åˆ†å’Œè¯¦ç»†ç†ç”±ã€‚
""",
                "answer_correctness": f"""
{base_context}

è¯·è¯„ä¼°AIå›ç­”çš„å‡†ç¡®æ€§ä¸ä¸“ä¸šæ€§ã€‚

è¯„åˆ†æ ‡å‡† (1-5åˆ†):
1åˆ†: å›ç­”é”™è¯¯ï¼ŒåŒ…å«å±é™©ä¿¡æ¯æˆ–ä¸¥é‡è¯¯å¯¼
2åˆ†: è¡¨é¢çœ‹èµ·æ¥åˆç†ä½†æ ¸å¿ƒå†…å®¹é”™è¯¯
3åˆ†: å¤§éƒ¨åˆ†æ­£ç¡®ä½†æœ‰æ˜æ˜¾ç¼ºæ¼æˆ–ä¸å¤Ÿå‡†ç¡®
4åˆ†: åŸºæœ¬å‡†ç¡®ä¸“ä¸šä½†ç¼ºå°‘è§„èŒƒå¼•ç”¨æˆ–ç»†èŠ‚
5åˆ†: å®Œå…¨å‡†ç¡®ä¸”ä¸“ä¸šï¼Œæœ‰è§„èŒƒä¾æ®å’Œå®ç”¨æŒ‡å¯¼

è¯·ç»™å‡ºå…·ä½“è¯„åˆ†å’Œè¯¦ç»†ç†ç”±ã€‚
""",
                "persona_alignment": f"""
{base_context}

è¯·è¯„ä¼°AIä¸ç”¨æˆ·ç”»åƒçš„åŒ¹é…åº¦ã€‚

è¯„åˆ†æ ‡å‡† (1-5åˆ†):
1åˆ†: æ²Ÿé€šé£æ ¼å®Œå…¨ä¸ç¬¦åˆç”¨æˆ·èƒŒæ™¯
2åˆ†: ç”¨è¯è¿‡äºä¸“ä¸šæˆ–è¿‡äºç®€å•ï¼Œç”¨æˆ·éš¾ä»¥ç†è§£
3åˆ†: åŸºæœ¬å¯ä»¥ç†è§£ä½†å­˜åœ¨æœ¯è¯­ä½¿ç”¨ä¸å½“
4åˆ†: æ²Ÿé€šé£æ ¼åŸºæœ¬åˆé€‚ï¼Œå¶æœ‰ä¸åŒ¹é…
5åˆ†: å®Œå…¨è´´åˆç”¨æˆ·è§’è‰²å’Œæ²Ÿé€šåå¥½

è¯·ç»™å‡ºå…·ä½“è¯„åˆ†å’Œè¯¦ç»†ç†ç”±ã€‚
"""
            }
            
            # Add goal alignment if requirement context exists
            if requirement_context.strip():
                evaluation_prompts["goal_alignment"] = f"""
{base_context}

åŸºäºæä¾›çš„éœ€æ±‚æ–‡æ¡£ï¼Œè¯·è¯„ä¼°AIæ˜¯å¦è¾¾æˆäº†é¢„æœŸçš„ç›®æ ‡å¯¹é½åº¦ã€‚

è¯„åˆ†æ ‡å‡† (1-5åˆ†):
1åˆ†: å®Œå…¨åç¦»éœ€æ±‚ç›®æ ‡ï¼Œæœªè§£å†³ä»»ä½•å…³é”®é—®é¢˜
2åˆ†: éƒ¨åˆ†ç›¸å…³ä½†æœªè¾¾æˆä¸»è¦ç›®æ ‡
3åˆ†: åŸºæœ¬ç¬¦åˆéœ€æ±‚ä½†æœ‰é‡è¦é—æ¼
4åˆ†: å¾ˆå¥½åœ°æ»¡è¶³äº†å¤§éƒ¨åˆ†éœ€æ±‚ç›®æ ‡
5åˆ†: å®Œç¾å¯¹é½æ‰€æœ‰éœ€æ±‚ç›®æ ‡ï¼Œè¶…å‡ºé¢„æœŸ

è¯·ç»™å‡ºå…·ä½“è¯„åˆ†å’Œè¯¦ç»†ç†ç”±ã€‚
"""
        
        # Execute evaluations concurrently for better performance
        evaluation_results = {}
        explanations = {}
        
        for dimension, prompt in evaluation_prompts.items():
            try:
                print(f"  ğŸ“Š Evaluating {dimension}...")
                response = await call_deepseek_api(prompt)
                score = extract_score_from_response(response)
                
                evaluation_results[dimension] = score
                explanations[dimension] = response
                
                print(f"  âœ… {dimension}: {score}/5")
                
            except Exception as e:
                print(f"  âŒ Failed to evaluate {dimension}: {str(e)}")
                evaluation_results[dimension] = 3.0  # Default score
                explanations[dimension] = f"è¯„ä¼°å¤±è´¥: {str(e)}"
        
        return evaluation_results, explanations
        
    except Exception as e:
        print(f"âŒ Evaluation process failed: {str(e)}")
        return {}, {}

def generate_evaluation_summary(evaluation_results: List[Dict], requirement_context: str = "") -> Dict:
    """
    Generate evaluation summary from results - 100-point scale normalized
    """
    if not evaluation_results:
        return {
            "overall_score_100": 0.0,
            "overall_score": 0.0,  # Keep for compatibility
            "total_scenarios": 0,
            "total_conversations": 0,
            "framework": "AI Agent 4ç»´åº¦è¯„ä¼°æ¡†æ¶ (100åˆ†åˆ¶)",
            "dimensions_100": {},
            "dimensions": {}  # Keep for compatibility
        }
        
    # Calculate dimension averages from 100-point scores
    all_scores_100 = {}
    total_conversations = 0
    
    for result in evaluation_results:
        # Use scenario_score_100 if available, fallback to converted scores
        scenario_score_100 = result.get("scenario_score_100", 0)
        if scenario_score_100 == 0:
            # Convert from 5-point scale if needed
            scenario_score_5 = result.get("scenario_score", 0)
            scenario_score_100 = scenario_score_5 * 20 if scenario_score_5 <= 5 else scenario_score_5
        
        scores = result.get("evaluation_scores", {})
        conversation_history = result.get("conversation_history", [])
        total_conversations += len(conversation_history)
        
        for dimension, score in scores.items():
            if dimension not in all_scores_100:
                all_scores_100[dimension] = []
            # Ensure score is in 100-point scale
            normalized_score = score * 20 if score <= 5 else score
            all_scores_100[dimension].append(normalized_score)
    
    # Calculate averages in 100-point scale
    dimension_averages_100 = {}
    dimension_averages_5 = {}  # For compatibility
    for dimension, scores in all_scores_100.items():
        avg_100 = sum(scores) / len(scores) if scores else 0
        dimension_averages_100[dimension] = round(avg_100, 2)
        dimension_averages_5[dimension] = round(avg_100 / 20, 2)  # For compatibility
    
    overall_score_100 = sum(dimension_averages_100.values()) / len(dimension_averages_100) if dimension_averages_100 else 0
    overall_score_5 = overall_score_100 / 20  # For compatibility
    
    return {
        "overall_score_100": round(overall_score_100, 2),
        "overall_score": round(overall_score_5, 2),  # Keep for compatibility
        "total_scenarios": len(evaluation_results),
        "total_conversations": total_conversations,
        "framework": "AI Agent 4ç»´åº¦è¯„ä¼°æ¡†æ¶ (100åˆ†åˆ¶)",
        "dimensions_100": dimension_averages_100,
        "dimensions": dimension_averages_5  # Keep for compatibility
    }

def extract_recommendations_from_response(response: str) -> List[str]:
    """Extract improvement recommendations from DeepSeek response"""
    try:
        # Look for numbered or bulleted recommendations
        recommendations = []
        lines = response.split('\n')
        
        for line in lines:
            line = line.strip()
            if any(marker in line for marker in ['1.', '2.', '3.', '4.', '5.', '-', 'â€¢', 'â‘ ', 'â‘¡', 'â‘¢']):
                # Clean the line and extract recommendation
                clean_rec = re.sub(r'^[\d\.\-\â€¢â‘ â‘¡â‘¢â‘£â‘¤]\s*', '', line).strip()
                if clean_rec and len(clean_rec) > 10:
                    recommendations.append(clean_rec)
        
        # If no structured recommendations found, try to extract from content
        if not recommendations and response:
            # Split into sentences and look for actionable suggestions
            sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.]', response)
            for sentence in sentences:
                if any(keyword in sentence for keyword in ['å»ºè®®', 'åº”è¯¥', 'éœ€è¦', 'å¯ä»¥', 'æ”¹è¿›', 'æå‡', 'ä¼˜åŒ–']):
                    if len(sentence.strip()) > 15:
                        recommendations.append(sentence.strip())
        
        return recommendations[:5] if recommendations else [
            "å¢å¼ºå¯¹è¯ç†è§£èƒ½åŠ›",
            "æé«˜å›ç­”å‡†ç¡®æ€§",
            "ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ",
            "åŠ å¼ºä¸“ä¸šçŸ¥è¯†æ·±åº¦"
        ]
        
    except Exception:
        return [
            "å¢å¼ºå¯¹è¯ç†è§£èƒ½åŠ›",
            "æé«˜å›ç­”å‡†ç¡®æ€§", 
            "ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ",
            "åŠ å¼ºä¸“ä¸šçŸ¥è¯†æ·±åº¦"
        ]

@app.post("/api/validate-config")
async def validate_agent_config(agent_api_config: str = Form(...)):
    """
    Validate AI Agent configuration before evaluation
    """
    try:
        # Parse configuration
        api_config_dict = json.loads(agent_api_config)
        api_config = APIConfig(**api_config_dict)
        
        validation_results = {
            "is_valid": True,
            "warnings": [],
            "errors": [],
            "suggestions": []
        }
        
        # Basic validation
        if not api_config.url:
            validation_results["errors"].append("API URLä¸èƒ½ä¸ºç©º")
            validation_results["is_valid"] = False
        
        if not api_config.headers:
            validation_results["warnings"].append("æœªè®¾ç½®è¯·æ±‚å¤´ï¼Œå¯èƒ½å¯¼è‡´è®¤è¯å¤±è´¥")
        
        # Coze-specific validation
        if api_config.type == "coze-agent":
            if not api_config.agentId:
                validation_results["errors"].append("Coze Agent IDä¸èƒ½ä¸ºç©º")
                validation_results["is_valid"] = False
            
            auth_header = api_config.headers.get("Authorization", "")
            if not auth_header or not auth_header.startswith("Bearer "):
                validation_results["errors"].append("Coze Agentéœ€è¦æœ‰æ•ˆçš„Bearer Token")
                validation_results["is_valid"] = False
            
            if api_config.region not in ["global", "china"]:
                validation_results["warnings"].append("å»ºè®®ä½¿ç”¨ 'global' æˆ– 'china' ä½œä¸ºregion")
        
        elif api_config.type == "coze-bot":
            if not api_config.botId:
                validation_results["errors"].append("Coze Bot IDä¸èƒ½ä¸ºç©º")
                validation_results["is_valid"] = False
        
        # Test connectivity (optional quick test)
        if validation_results["is_valid"]:
            try:
                # Quick connectivity test with timeout
                async with httpx.AsyncClient(timeout=httpx.Timeout(5.0)) as client:
                    if api_config.type == "coze-agent":
                        # Test Coze Agent endpoint
                        test_url = f"https://api.coze.{'cn' if api_config.region == 'china' else 'com'}/v3/chat"
                        response = await client.post(
                            test_url,
                            headers=api_config.headers,
                            json={
                                "bot_id": api_config.agentId,
                                "user_id": "test_validation",
                                "stream": False,
                                "auto_save_history": False,
                                "additional_messages": [
                                    {"role": "user", "content": "test", "content_type": "text"}
                                ]
                            }
                        )
                        
                        if response.status_code == 401:
                            validation_results["errors"].append("è®¤è¯å¤±è´¥ï¼šè¯·æ£€æŸ¥Access Tokenæ˜¯å¦æœ‰æ•ˆ")
                            validation_results["is_valid"] = False
                        elif response.status_code == 403:
                            validation_results["errors"].append("æƒé™ä¸è¶³ï¼šè¯·æ£€æŸ¥Tokenæƒé™æˆ–Agent ID")
                            validation_results["is_valid"] = False
                        elif response.status_code in [200, 400]:  # 400 might be expected for test message
                            validation_results["suggestions"].append("âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸ")
                        else:
                            validation_results["warnings"].append(f"APIè¿”å›çŠ¶æ€ç : {response.status_code}")
                    
                    else:
                        # Test custom API endpoint
                        response = await client.post(
                            api_config.url,
                            headers=api_config.headers,
                            json={"message": "test"}
                        )
                        
                        if response.status_code in [200, 400, 401]:
                            validation_results["suggestions"].append("âœ… APIç«¯ç‚¹å¯è®¿é—®")
                        else:
                            validation_results["warnings"].append(f"APIè¿”å›çŠ¶æ€ç : {response.status_code}")
                            
            except httpx.TimeoutException:
                validation_results["warnings"].append("APIè¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–URL")
            except Exception as e:
                validation_results["warnings"].append(f"è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)[:50]}...")
        
        # Add helpful suggestions
        if validation_results["is_valid"]:
            validation_results["suggestions"].extend([
                "ğŸ’¡ å»ºè®®å…ˆç”¨ç®€å•é—®é¢˜æµ‹è¯•AI Agentå“åº”",
                "ğŸ“ ç¡®ä¿Agentå·²å‘å¸ƒä¸”å¤„äºæ´»è·ƒçŠ¶æ€",
                "ğŸ”„ å¦‚é‡åˆ°é—®é¢˜ï¼Œå¯å°è¯•é‡æ–°ç”ŸæˆAccess Token"
            ])
        
        return {
            "validation_result": validation_results,
            "config_summary": {
                "type": api_config.type,
                "url": api_config.url,
                "has_auth": bool(api_config.headers.get("Authorization")),
                "timeout": api_config.timeout
            }
        }
        
    except json.JSONDecodeError:
        return {
            "validation_result": {
                "is_valid": False,
                "errors": ["é…ç½®æ ¼å¼é”™è¯¯ï¼šè¯·æ£€æŸ¥JSONæ ¼å¼"],
                "warnings": [],
                "suggestions": ["è¯·ç¡®ä¿é…ç½®ä¿¡æ¯ä¸ºæœ‰æ•ˆçš„JSONæ ¼å¼"]
            }
        }
    except Exception as e:
        return {
            "validation_result": {
                "is_valid": False,
                "errors": [f"é…ç½®éªŒè¯å¤±è´¥: {str(e)}"],
                "warnings": [],
                "suggestions": ["è¯·æ£€æŸ¥é…ç½®ä¿¡æ¯æ˜¯å¦å®Œæ•´"]
            }
        }

async def call_deepseek_api_with_fallback(prompt: str, max_retries: int = 2) -> str:
    """
    Enhanced DeepSeek API call with config-based settings and proper error handling
    """
    headers = {
        "Authorization": f"Bearer {config.DEEPSEEK_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": "deepseek-chat",
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 800,
        "temperature": config.ENHANCED_TEMPERATURE
    }
    
    for attempt in range(max_retries):
        try:
            timeout = httpx.Timeout(config.DEEPSEEK_TIMEOUT, connect=10.0)
            async with httpx.AsyncClient(timeout=timeout) as client:
                response = await client.post(config.DEEPSEEK_API_URL, headers=headers, json=payload)
                
                if response.status_code == 200:
                    result = response.json()
                    if "choices" in result and len(result["choices"]) > 0:
                        content = result["choices"][0]["message"]["content"].strip()
                        if content and len(content) > 10:
                            return content
                        else:
                            raise Exception("DeepSeek returned empty or too short response")
                    else:
                        raise Exception("No valid choices in DeepSeek response")
                elif response.status_code == 401:
                    raise Exception("API authentication failed - check API key")
                elif response.status_code == 429:
                    if attempt < max_retries - 1:
                        await asyncio.sleep(2 ** attempt)
                        continue
                    raise Exception("API rate limited")
                else:
                    error_text = response.text if hasattr(response, 'text') else 'Unknown error'
                    raise Exception(f"API error {response.status_code}: {error_text}")
                    
        except (asyncio.TimeoutError, httpx.TimeoutException):
            if attempt < max_retries - 1:
                await asyncio.sleep(1)
                continue
            raise Exception(f"API timeout after {config.DEEPSEEK_TIMEOUT}s")
        except httpx.RequestError as e:
            if attempt < max_retries - 1:
                await asyncio.sleep(1)
                continue
            raise Exception(f"Network error: {str(e)}")
        except Exception as e:
            if "empty" in str(e) or "short" in str(e):
                if attempt < max_retries - 1:
                    await asyncio.sleep(1)
                    continue
            raise e
            
    raise Exception("All API attempts failed")

# Create alias function to redirect to new implementation
async def conduct_dynamic_conversation(api_config: APIConfig, scenario_info: Dict, user_persona_info: Dict) -> List[Dict]:
    """Redirect to true dynamic conversation implementation"""
    return await conduct_true_dynamic_conversation(api_config, scenario_info, user_persona_info)

async def conduct_true_dynamic_conversation(api_config: APIConfig, scenario_info: Dict, user_persona_info: Dict, use_raw_messages: bool = False) -> List[Dict]:
    """
    TRUE dynamic conversation: Correct flow implementation
    
    Flow: 
    1. DeepSeek generates user message based on persona â†’ 
    2. Send RAW message to Coze (no enhancement) â†’ 
    3. Extract Coze's actual response â†’ 
    4. Pass Coze response to DeepSeek for next message generation
    
    Args:
        use_raw_messages: Legacy parameter (always uses raw messages now)
    """
    print(f"ğŸ—£ï¸ å¼€å§‹çœŸæ­£åŠ¨æ€å¯¹è¯: {scenario_info.get('title', 'æœªå‘½ååœºæ™¯')}")
    print("ğŸ”„ æ­£ç¡®æµç¨‹: DeepSeek(åŸºäºç”»åƒç”Ÿæˆæ¶ˆæ¯) â†’ åŸå§‹æ¶ˆæ¯ â†’ Coze â†’ å“åº” â†’ DeepSeek(åˆ†æå“åº”ç”Ÿæˆä¸‹è½®)")
    
    conversation_history = []
    persona = user_persona_info.get('user_persona', {})
    context = user_persona_info.get('usage_context', {})
    
    # Initialize conversation manager for continuity
    conversation_manager = ConversationManager(api_config)
    conversation_manager.start_new_conversation()
    
    # Step 1: Generate ONLY the initial message based on persona and scenario
    try:
        initial_message = await generate_single_initial_message(scenario_info, user_persona_info)
        if not initial_message:
            raise Exception("Failed to generate initial message")
    except Exception as e:
        print(f"âŒ åˆå§‹æ¶ˆæ¯ç”Ÿæˆå¤±è´¥: {str(e)}")
        raise Exception(f"Dynamic conversation initialization failed: {str(e)}")
    
    current_user_message = initial_message
    failed_turns = 0  # Track failed turns
    
    # Step 2: Conduct true turn-by-turn conversation (optimized to 2-3 turns max)
    for turn_num in range(1, 4):  # Maximum 3 turns
        try:
            # ğŸ› Debug log for message processing - ALWAYS use raw messages in dynamic conversation
            print(f"ğŸ” [TURN {turn_num}] DeepSeekç”Ÿæˆçš„åŸå§‹ç”¨æˆ·æ¶ˆæ¯: {current_user_message}")
            
            # ALWAYS send raw user message to Coze (no persona enhancement in dynamic mode)
            # This is the correct flow: DeepSeek(persona) â†’ raw message â†’ Coze â†’ response â†’ DeepSeek(analyze)
            message_to_send = current_user_message
            print(f"ğŸ” [RAW MESSAGE] å‘é€åŸå§‹æ¶ˆæ¯åˆ°Coze: {message_to_send}")
            
            # Get AI response with timeout and conversation continuity
            ai_response = await call_coze_with_strict_timeout(api_config, message_to_send, conversation_manager, True)
            
            if not ai_response or len(ai_response.strip()) < 5:
                print(f"âš ï¸ ç¬¬{turn_num}è½®AIå“åº”ä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œå¯èƒ½æ˜¯APIé—®é¢˜")
                failed_turns += 1
                if failed_turns >= 2:  # Stop if too many failed turns
                    print("âŒ è¿ç»­å¤šè½®APIå“åº”å¤±è´¥ï¼Œå¯èƒ½æ˜¯APIé…ç½®æˆ–è´¦æˆ·é—®é¢˜ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥å’Œè´¦æˆ·ä½™é¢")
                    break
                continue
            
            # Clean the AI response to extract meaningful content
            cleaned_response = clean_ai_response(ai_response)
            
            # If cleaned response is empty (system message), try to generate a fallback response
            if not cleaned_response:
                try:
                    fallback_prompt = f"""
ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„{user_persona_info.get('user_persona', {}).get('role', 'åŠ©æ‰‹')}ï¼Œè¯·å¯¹ä»¥ä¸‹é—®é¢˜ç»™å‡ºç®€çŸ­ä½†æœ‰ç”¨çš„å›å¤ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{current_user_message}
å›å¤è¦æ±‚ï¼š
1. ç›´æ¥å›ç­”é—®é¢˜ï¼Œä¸è¦è¯´"æˆ‘ä¸çŸ¥é“"
2. ä¿æŒä¸“ä¸šä½†å‹å¥½çš„è¯­è°ƒ
3. å¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯ï¼Œå¯ä»¥ç®€å•è¯¢é—®
4. å›å¤æ§åˆ¶åœ¨50å­—ä»¥å†…

è¯·ç›´æ¥ç»™å‡ºå›å¤ï¼š
"""
                    
                    fallback_response = await call_deepseek_api_enhanced(fallback_prompt, temperature=0.3, max_tokens=100)
                    if fallback_response and len(fallback_response.strip()) > 5:
                        cleaned_response = fallback_response.strip()
                        failed_turns = 0  # Reset since we got a response
                    else:
                        failed_turns += 1
                        if failed_turns >= 2:
                            break
                        continue
                except Exception as e:
                    failed_turns += 1
                    if failed_turns >= 2:
                        break
                    continue
            
            # Reset failed turn counter on successful turn
            failed_turns = 0
            
            # Record this turn
            conversation_history.append({
                "turn": turn_num,
                "user_message": current_user_message,  # Raw message generated by DeepSeek
                "message_sent_to_ai": message_to_send,  # Same as user_message (always raw)
                "ai_response": cleaned_response,        # Actual Coze response
                "response_length": len(cleaned_response),
                "conversation_id": conversation_manager.get_conversation_id(),
                "flow_type": "deepseek_to_raw_to_coze",  # Indicate the correct flow
                "timestamp": datetime.now().isoformat()
            })
            
            print(f"âœ… ç¬¬ {turn_num} è½®å¯¹è¯å®Œæˆ")
            
            # Generate next message based on AI's actual response (only if not the last turn)
            if turn_num < 3:  # Don't generate after last turn
                try:
                    next_message = await generate_next_message_based_on_response(
                        scenario_info, user_persona_info, conversation_history, cleaned_response
                    )
                    
                    if not next_message or next_message.upper() in ["END", "FINISH", "DONE"]:
                        print(f"ğŸ”š å¯¹è¯è‡ªç„¶ç»“æŸäºç¬¬ {turn_num} è½®")
                        break
                        
                    current_user_message = next_message
                    
                except Exception as e:
                    print(f"âŒ ç¬¬{turn_num + 1}è½®æ¶ˆæ¯ç”Ÿæˆå¤±è´¥: {str(e)}")
                    break  # End conversation if next message generation fails
            
        except Exception as e:
            print(f"âŒ ç¬¬ {turn_num} è½®å¯¹è¯å¼‚å¸¸: {str(e)}")
            failed_turns += 1
            if failed_turns >= 2:
                break
            continue
    
    if not conversation_history:
        raise Exception("Dynamic conversation completely failed - no successful turns")
    
    print(f"ğŸ“Š çœŸå®åŠ¨æ€å¯¹è¯å®Œæˆï¼Œå…± {len(conversation_history)} è½®")
    print(f"âœ… å®ç°æµç¨‹: DeepSeek(ç”»åƒç”Ÿæˆ) â†’ åŸå§‹æ¶ˆæ¯ â†’ Coze â†’ å®é™…å›å¤ â†’ DeepSeek(åˆ†æå›å¤)")
    return conversation_history

# DeepSeek Configuration

async def call_deepseek_api_enhanced(prompt: str, max_tokens: int = 500, temperature: float = 0.1, max_retries: int = 2) -> str:
    """
    Enhanced DeepSeek API call with better configuration and error handling
    """
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {config.DEEPSEEK_API_KEY}"
    }
    
    payload = {
        "model": "deepseek-chat",
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": max_tokens,
        "temperature": temperature,
        "top_p": 0.9,
        "frequency_penalty": 0.1,
        "presence_penalty": 0.1
    }
    
    # Single attempt - fail fast if there are issues
    try:
        # Increased timeout and added better error handling
        timeout = httpx.Timeout(config.DEEPSEEK_TIMEOUT, connect=10.0)
        async with httpx.AsyncClient(timeout=timeout) as client:
            response = await client.post(config.DEEPSEEK_API_URL, json=payload, headers=headers)
            
            if response.status_code == 200:
                result = response.json()
                if "choices" in result and len(result["choices"]) > 0:
                    content = result["choices"][0]["message"]["content"]
                    return content.strip()
                else:
                    raise Exception("No valid response choices in API response")
            elif response.status_code == 429:
                raise Exception(f"API rate limited (429)")
            elif response.status_code == 401:
                raise Exception(f"API authentication failed (401) - check API key")
            else:
                error_text = response.text if hasattr(response, 'text') else 'Unknown error'
                raise Exception(f"API error {response.status_code}: {error_text}")
                
    except asyncio.TimeoutError:
        raise Exception(f"API request timeout after {config.DEEPSEEK_TIMEOUT}s - try increasing timeout in config.py")
    except httpx.TimeoutException:
        raise Exception(f"API request timeout after {config.DEEPSEEK_TIMEOUT}s - try increasing timeout in config.py")
    except httpx.RequestError as e:
        raise Exception(f"Network error: {str(e)} - check internet connection")
    except Exception as e:
        # Re-raise without fallback
        raise e

# Add after the health check endpoint
@app.post("/api/download-report")
async def download_evaluation_report(
    request: Request,
    evaluation_data: str = Form(...),
    format: str = Form("json"),  # json, txt, docx
    include_transcript: bool = Form(False)
):
    """
    Generate and download evaluation report in specified format
    """
    try:
        # Parse evaluation data
        eval_results = json.loads(evaluation_data)
        
        # ğŸ†• è‡ªåŠ¨ä¿å­˜è¯„ä¼°ç»“æœåˆ°æ•°æ®åº“ï¼ˆå¦‚æœå°šæœªä¿å­˜ï¼‰
        session_id = None
        if PYMYSQL_AVAILABLE and config.ENABLE_AUTO_SAVE:
            try:
                # æ£€æŸ¥è¯„ä¼°æ•°æ®ä¸­æ˜¯å¦å·²æœ‰session_id
                session_id = eval_results.get('session_id')
                if not session_id:
                    # å¦‚æœæ²¡æœ‰session_idï¼Œä¿å­˜è¯„ä¼°ç»“æœåˆ°æ•°æ®åº“
                    requirement_context = eval_results.get('requirement_document', '')
                    session_id = await save_evaluation_to_database(eval_results, requirement_context)
                    print(f"âœ… è¯„ä¼°ç»“æœå·²è‡ªåŠ¨ä¿å­˜åˆ°æ•°æ®åº“ï¼Œä¼šè¯ID: {session_id}")
                
                # è®°å½•ä¸‹è½½æ´»åŠ¨
                if session_id:
                    file_size = len(evaluation_data)  # ä¼°ç®—æ–‡ä»¶å¤§å°
                    await save_download_record(session_id, format, include_transcript, file_size, request)
                    print(f"ğŸ“¥ ä¸‹è½½è®°å½•å·²ä¿å­˜: {format} æ ¼å¼ï¼ŒåŒ…å«å¯¹è¯è®°å½•: {include_transcript}")
                    
            except Exception as db_error:
                print(f"âš ï¸ æ•°æ®åº“ä¿å­˜å¤±è´¥ï¼Œä½†æŠ¥å‘Šç”Ÿæˆå°†ç»§ç»­: {db_error}")
        
        # ç”Ÿæˆå¹¶è¿”å›æŠ¥å‘Š
        if format == "json":
            return generate_json_report(eval_results, include_transcript)
        elif format == "txt":
            return generate_txt_report(eval_results, include_transcript)
        elif format == "docx":
            return generate_docx_report(eval_results, include_transcript)
        else:
            raise HTTPException(status_code=400, detail="Unsupported format")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Report generation failed: {str(e)}")

def generate_json_report(eval_results: Dict, include_transcript: bool = False) -> JSONResponse:
    """Generate JSON format report with complete evaluation information"""
    report_data = {
        "evaluation_summary": eval_results.get("evaluation_summary", {}),
        "overall_score": eval_results.get("overall_score", 0),
        "dimension_scores": eval_results.get("dimension_scores", {}),
        "detailed_analysis": eval_results.get("detailed_analysis", {}),
        "recommendations": eval_results.get("recommendations", []),
        "user_persona_info": eval_results.get("user_persona_info", {}),
        "detailed_context_display": eval_results.get("detailed_context_display", {}),
        "persona_alignment_analysis": eval_results.get("persona_alignment_analysis", ""),
        "business_goal_achievement": eval_results.get("business_goal_achievement", ""),
        "evaluation_mode": eval_results.get("evaluation_mode", "unknown"),
        "timestamp": eval_results.get("timestamp", datetime.now().isoformat())
    }
    
    if include_transcript:
        report_data["conversation_records"] = eval_results.get("conversation_records", [])
    
    return JSONResponse(
        content=report_data,
        headers={"Content-Disposition": "attachment; filename=evaluation_report.json"}
    )

def generate_txt_report(eval_results: Dict, include_transcript: bool = False) -> FileResponse:
    """Generate TXT format report"""
    import tempfile
    
    # Extract scoring information with proper 100-point scale
    overall_score = eval_results.get('evaluation_summary', {}).get('overall_score', eval_results.get('overall_score', 0))
    
    report_content = f"""
AI Agent Evaluation Report
=========================
Generated: {eval_results.get('timestamp', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))}
Evaluation Mode: {eval_results.get('evaluation_mode', 'Unknown')}

OVERALL PERFORMANCE
------------------
Overall Score: {overall_score}/100.0

DIMENSION SCORES
---------------
"""
    
    # Use conversation_records to extract dimension scores
    conversation_records = eval_results.get('conversation_records', [])
    if conversation_records:
        for i, record in enumerate(conversation_records, 1):
            scenario_title = record.get('scenario', {}).get('title', f'Scenario {i}')
            report_content += f"\n{scenario_title}:\n"
            scores = record.get('evaluation_scores_with_explanations', record.get('evaluation_scores', {}))
            for dimension, score_data in scores.items():
                score = score_data.get('score', score_data) if isinstance(score_data, dict) else score_data
                dimension_name = dimension.replace('_', ' ').title()
                report_content += f"  {dimension_name}: {score}/100.0\n"
    
    report_content += f"\nDETAILED ANALYSIS\n{'-' * 16}\n"
    
    detailed_analysis = eval_results.get('detailed_analysis', {})
    for dimension, analysis in detailed_analysis.items():
        report_content += f"\n{dimension.upper()}:\n"
        if isinstance(analysis, dict):
            report_content += f"Score: {analysis.get('score', 'N/A')}\n"
            report_content += f"Analysis: {analysis.get('detailed_analysis', 'No details available')}\n"
        else:
            report_content += f"{analysis}\n"
    
    report_content += f"\nRECOMMENDations\n{'-' * 15}\n"
    recommendations = eval_results.get('recommendations', [])
    for i, rec in enumerate(recommendations, 1):
        report_content += f"{i}. {rec}\n"
    
    if include_transcript:
        report_content += f"\nCONVERSATION TRANSCRIPT\n{'-' * 22}\n"
        conversation_records = eval_results.get('conversation_records', [])
        for record in conversation_records:
            for turn in record.get('conversation', []):
                report_content += f"Turn {turn.get('turn', 'N/A')}: {turn.get('user_message', '')}\n"
                report_content += f"AI Response: {turn.get('ai_response', '')}\n\n"
    
    # Create temporary file
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as tmp_file:
        tmp_file.write(report_content)
        tmp_file_path = tmp_file.name
    
    return FileResponse(
        path=tmp_file_path,
        filename="evaluation_report.txt",
        media_type="text/plain"
    )

def generate_docx_report(eval_results: Dict, include_transcript: bool = False) -> FileResponse:
    """Generate DOCX format report (if docx library is available)"""
    if not DOCUMENT_PROCESSING_AVAILABLE:
        raise HTTPException(status_code=500, detail="DOCX generation not available. Install python-docx.")
    
    import tempfile
    from docx import Document
    from docx.shared import Inches
    
    # Create document
    doc = Document()
    
    # Title
    title = doc.add_heading('AI Agent Evaluation Report', 0)
    
    # Summary section
    doc.add_heading('Executive Summary', level=1)
    overall_score = eval_results.get('overall_score', 'N/A')
    doc.add_paragraph(f'Overall Performance Score: {overall_score}/5.0')
    doc.add_paragraph(f'Generated: {eval_results.get("timestamp", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))}')
    
    # Dimension scores
    doc.add_heading('Performance Dimensions', level=1)
    dimension_scores = eval_results.get('dimension_scores', {})
    table = doc.add_table(rows=1, cols=2)
    table.style = 'Table Grid'
    hdr_cells = table.rows[0].cells
    hdr_cells[0].text = 'Dimension'
    hdr_cells[1].text = 'Score'
    
    for dimension, score in dimension_scores.items():
        row_cells = table.add_row().cells
        row_cells[0].text = dimension.replace('_', ' ').title()
        row_cells[1].text = f'{score}/5.0'
    
    # Detailed analysis
    doc.add_heading('Detailed Analysis', level=1)
    detailed_analysis = eval_results.get('detailed_analysis', {})
    for dimension, analysis in detailed_analysis.items():
        doc.add_heading(dimension.replace('_', ' ').title(), level=2)
        if isinstance(analysis, dict):
            doc.add_paragraph(f"Score: {analysis.get('score', 'N/A')}")
            doc.add_paragraph(analysis.get('detailed_analysis', 'No details available'))
        else:
            doc.add_paragraph(str(analysis))
    
    # Recommendations
    doc.add_heading('Recommendations', level=1)
    recommendations = eval_results.get('recommendations', [])
    for i, rec in enumerate(recommendations, 1):
        doc.add_paragraph(f'{i}. {rec}')
    
    # Conversation transcript (if requested)
    if include_transcript:
        doc.add_heading('Conversation Transcript', level=1)
        conversation_records = eval_results.get('conversation_records', [])
        for record in conversation_records:
            scenario_title = record.get('scenario', {}).get('title', 'Unknown Scenario')
            doc.add_heading(f'Scenario: {scenario_title}', level=2)
            for turn in record.get('conversation', []):
                doc.add_paragraph(f"Turn {turn.get('turn', 'N/A')}: {turn.get('user_message', '')}")
                doc.add_paragraph(f"AI Response: {turn.get('ai_response', '')}")
                doc.add_paragraph("")  # Empty line for spacing
    
    # Save to temporary file
    with tempfile.NamedTemporaryFile(suffix='.docx', delete=False) as tmp_file:
        tmp_file_path = tmp_file.name
    
    doc.save(tmp_file_path)
    
    return FileResponse(
        path=tmp_file_path,
        filename="evaluation_report.docx",
        media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    )

async def call_coze_with_strict_timeout(api_config: APIConfig, message: str, conversation_manager: ConversationManager = None, use_raw_message: bool = False) -> str:
    """
    Call AI Agent API with strict timeout for dynamic conversations and proper logging
    """
    try:
        # Add memory check before API call to prevent crashes
        memory_usage = check_memory_usage()
        if memory_usage > config.MEMORY_CRITICAL_THRESHOLD:
            raise Exception(f"Memory usage critical: {memory_usage:.1f}%. Please restart server.")
        
        # Use timeout wrapper for individual API calls
        response = await asyncio.wait_for(
            call_ai_agent_api(api_config, message, conversation_manager, use_raw_message),
            timeout=config.DEFAULT_REQUEST_TIMEOUT  # 2 minutes for individual calls
        )
        
        # Determine API type for proper logging (reduced verbosity)
        if "/v1/chat-messages" in api_config.url or "dify" in api_config.url.lower():
            print(f"âœ… Dify APIå“åº” ({len(response)} chars)")
        elif "coze" in api_config.url.lower():
            print(f"âœ… Coze APIå“åº” ({len(response)} chars)")
        else:
            print(f"âœ… è‡ªå®šä¹‰APIå“åº” ({len(response)} chars)")
            
        return response
        
    except asyncio.TimeoutError:
        print(f"â° APIè°ƒç”¨è¶…æ—¶ ({config.DEFAULT_REQUEST_TIMEOUT}ç§’)")
        return ""
    except Exception as e:
        print(f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}")
        return ""

async def generate_single_initial_message(scenario_info: Dict, user_persona_info: Dict) -> str:
    """
    Generate a single initial message based on scenario and user persona
    """
    try:
        persona = user_persona_info.get('user_persona', {})
        usage_context = user_persona_info.get('usage_context', {})
        ai_role = user_persona_info.get('ai_role_simulation', {})
        
        # Get fuzzy expressions and opening patterns for this role
        fuzzy_expressions = ai_role.get('fuzzy_expressions', [])
        opening_patterns = ai_role.get('opening_patterns', [])
        
        generation_prompt = f"""
ä½ æ˜¯ä¸€ä¸ª{persona.get('role', 'ä¸“ä¸šç”¨æˆ·')}ï¼Œå·¥ä½œç¯å¢ƒæ˜¯{persona.get('work_environment', 'ä¸“ä¸šç¯å¢ƒ')}ã€‚
ä½ çš„æ²Ÿé€šé£æ ¼ï¼š{persona.get('communication_style', 'ä¸“ä¸šæ²Ÿé€š')}
å½“å‰åœºæ™¯ï¼š{scenario_info.get('title', 'ä¸“ä¸šå’¨è¯¢')}
åœºæ™¯èƒŒæ™¯ï¼š{scenario_info.get('context', 'å·¥ä½œåœºæ™¯')}

è¯·ç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„åˆå§‹é—®é¢˜æˆ–éœ€æ±‚æè¿°ï¼Œè¦æ±‚ï¼š
1. ä½“ç°{persona.get('role', 'ç”¨æˆ·')}çš„èº«ä»½å’ŒèƒŒæ™¯
2. è¡¨è¾¾æ–¹å¼è¦{persona.get('communication_style', 'ä¸“ä¸š')}
3. å¯ä»¥ç¨å¾®æ¨¡ç³Šæˆ–ä¸å®Œæ•´ï¼Œéœ€è¦AIè¿½é—®æ¾„æ¸…
4. é•¿åº¦æ§åˆ¶åœ¨10-30ä¸ªå­—
5. ä¸è¦ä½¿ç”¨å¼•å·æˆ–ç‰¹æ®Šç¬¦å·

ç¤ºä¾‹é£æ ¼å‚è€ƒï¼ˆä»…å‚è€ƒé£æ ¼ï¼Œä¸è¦ç…§æ¬ï¼‰ï¼š
{', '.join(fuzzy_expressions[:3]) if fuzzy_expressions else 'æœ‰ä¸ªé—®é¢˜éœ€è¦å’¨è¯¢'}

ç›´æ¥è¾“å‡ºé—®é¢˜å†…å®¹ï¼Œä¸è¦ä»»ä½•è§£é‡Šï¼š
"""
        
        response = await call_deepseek_api_enhanced(generation_prompt, temperature=0.6, max_tokens=100)
        
        # Clean the response
        message = response.strip().strip('"').strip("'").strip('ã€‚').strip('ï¼Ÿ').strip('!')
        
        if message and len(message) > 3:
            print(f"âœ… ç”Ÿæˆåˆå§‹æ¶ˆæ¯: {message}")
            return message
        else:
            # Fallback to predefined patterns
            if opening_patterns:
                import random
                fallback = random.choice(opening_patterns)
                print(f"ğŸ”„ ä½¿ç”¨å¤‡ç”¨å¼€åœº: {fallback}")
                return fallback
            else:
                return "æœ‰ä¸ªé—®é¢˜éœ€è¦å’¨è¯¢"
                
    except Exception as e:
        print(f"âŒ åˆå§‹æ¶ˆæ¯ç”Ÿæˆå¤±è´¥: {str(e)}")
        # Ultimate fallback
        return "è¯·å¸®å¿™è§£å†³ä¸€ä¸ªé—®é¢˜"

async def generate_next_message_based_on_response(
    scenario_info: Dict, 
    user_persona_info: Dict, 
    conversation_history: List[Dict], 
    coze_response: str
) -> str:
    """
    Generate next user message based on Coze's response and conversation context
    """
    try:
        persona = user_persona_info.get('user_persona', {})
        
        # Analyze the conversation so far
        turn_count = len(conversation_history)
        last_user_message = conversation_history[-1]['user_message'] if conversation_history else ""
        
        generation_prompt = f"""
ä½ æ˜¯ä¸€ä¸ª{persona.get('role', 'ä¸“ä¸šç”¨æˆ·')}ï¼Œæ­£åœ¨ä¸AIåŠ©æ‰‹å¯¹è¯ã€‚
æ²Ÿé€šé£æ ¼ï¼š{persona.get('communication_style', 'ä¸“ä¸šæ²Ÿé€š')}
åœºæ™¯ï¼š{scenario_info.get('title', 'ä¸“ä¸šå’¨è¯¢')}

å¯¹è¯å†å²ï¼š
{chr(10).join([f"ç¬¬{turn['turn']}è½® - æˆ‘: {turn['user_message']}" for turn in conversation_history[-2:]])}
AIåˆšæ‰å›å¤: {coze_response[:200]}

ç°åœ¨æ˜¯ç¬¬{turn_count + 1}è½®å¯¹è¯ã€‚åŸºäºAIçš„å›å¤ï¼Œè¯·ç”Ÿæˆä½ çš„ä¸‹ä¸€ä¸ªé—®é¢˜æˆ–å›åº”ï¼š

è¦æ±‚ï¼š
1. è‡ªç„¶åœ°åŸºäºAIçš„å›å¤å†…å®¹ç»§ç»­å¯¹è¯
2. å¯ä»¥è¿½é—®ç»†èŠ‚ã€è¦æ±‚æ¾„æ¸…ã€æˆ–æå‡ºæ–°çš„ç›¸å…³é—®é¢˜  
3. ä¿æŒ{persona.get('role', 'ç”¨æˆ·')}çš„èº«ä»½å’Œ{persona.get('communication_style', 'æ²Ÿé€šé£æ ¼')}
4. é•¿åº¦10-40ä¸ªå­—
5. å¦‚æœAIå·²ç»å……åˆ†å›ç­”äº†é—®é¢˜ï¼Œå¯ä»¥å›å¤"END"ç»“æŸå¯¹è¯

ç›´æ¥è¾“å‡ºä¸‹ä¸€å¥è¯ï¼Œä¸è¦è§£é‡Šï¼š
"""
        
        print(f"ğŸ¤– DeepSeekåˆ†æCozeå›å¤å†…å®¹: {coze_response[:50]}...")
        response = await call_deepseek_api_enhanced(generation_prompt, temperature=0.7, max_tokens=150)
        
        # Clean the response
        message = response.strip().strip('"').strip("'").strip('ã€‚').strip('ï¼Ÿ').strip('!')
        
        if message and len(message) > 2:
            # Check if it's an end signal
            if message.upper() in ["END", "FINISH", "DONE", "ç»“æŸ", "å®Œæˆ"]:
                print("ğŸ”š DeepSeekåˆ¤æ–­å¯¹è¯åº”è¯¥ç»“æŸ")
                return "END"
            
            print(f"âœ… DeepSeekåŸºäºCozeå›å¤ç”Ÿæˆä¸‹è½®æ¶ˆæ¯: {message}")
            return message
        else:
            # If generation fails, end the conversation
            print("âŒ DeepSeekç”Ÿæˆä¸‹è½®æ¶ˆæ¯å¤±è´¥ï¼Œç»“æŸå¯¹è¯")
            return "END"
            
    except Exception as e:
        print(f"âŒ ä¸‹è½®æ¶ˆæ¯ç”Ÿæˆå¤±è´¥: {str(e)}")
        return "END"

async def evaluate_conversation_with_deepseek(
    conversation_history: List[Dict], 
    scenario_info: Dict, 
    requirement_context: str = "", 
    user_persona_info: Dict = None
) -> tuple:
    """
    Enhanced conversation evaluation with detailed explanations and 100-point scoring
    """
    try:
        print("ğŸ§  å¼€å§‹DeepSeekæ™ºèƒ½è¯„ä¼°...")
        
        # Build conversation context - ensure it uses the complete actual conversation
        conversation_text = "å®Œæ•´å¯¹è¯è®°å½•:\n"
        for turn in conversation_history:
            conversation_text += f"ç¬¬{turn['turn']}è½®:\n"
            conversation_text += f"ç”¨æˆ·: {turn['user_message']}\n"
            conversation_text += f"AIå›ç­”: {turn['ai_response']}\n\n"
        
        # Build evaluation context
        context_section = f"""
ä¸šåŠ¡åœºæ™¯: {scenario_info.get('context', 'é€šç”¨AIåŠ©æ‰‹åœºæ™¯')}
å¯¹è¯ä¸»é¢˜: {scenario_info.get('title', '')}
"""
        
        # Add persona information if available
        if user_persona_info:
            persona = user_persona_info.get('user_persona', {})
            context_section += f"""
ç”¨æˆ·è§’è‰²: {persona.get('role', '')}
ç»éªŒæ°´å¹³: {persona.get('experience_level', '')}
æ²Ÿé€šé£æ ¼: {persona.get('communication_style', '')}
å·¥ä½œç¯å¢ƒ: {persona.get('work_environment', '')}
"""
        
        if requirement_context:
            context_section += f"\néœ€æ±‚æ–‡æ¡£ä¸Šä¸‹æ–‡:\n{requirement_context[:800]}"
        
        # Enhanced evaluation with detailed explanations
        evaluation_scores = {}
        detailed_explanations = {}
        
        # Define evaluation dimensions
        dimensions = {
            "fuzzy_understanding": "æ¨¡ç³Šç†è§£ä¸è¿½é—®èƒ½åŠ›",
            "answer_correctness": "å›ç­”å‡†ç¡®æ€§ä¸ä¸“ä¸šæ€§",
            "persona_alignment": "ç”¨æˆ·åŒ¹é…åº¦"
        }
        
        if requirement_context:
            dimensions["goal_alignment"] = "ç›®æ ‡å¯¹é½åº¦"
        
        # Evaluate each dimension with optimized prompts (shorter but focused)
        for dimension, dimension_name in dimensions.items():
            eval_prompt = f"""
{context_section}

{conversation_text}

è¯·è¯„ä¼°AIåœ¨"{dimension_name}"æ–¹é¢çš„è¡¨ç°ã€‚

è¯„åˆ†æ ‡å‡† (1-100åˆ†åˆ¶):
90-100åˆ†: ä¼˜ç§€è¡¨ç°ï¼Œå®Œå…¨ç¬¦åˆè¦æ±‚ï¼Œè¶…å‡ºé¢„æœŸ
80-89åˆ†: è‰¯å¥½è¡¨ç°ï¼ŒåŸºæœ¬ç¬¦åˆæœŸæœ›ï¼Œæœ‰å°å¹…æå‡ç©ºé—´
70-79åˆ†: ä¸­ç­‰è¡¨ç°ï¼Œæ»¡è¶³åŸºæœ¬è¦æ±‚ï¼Œä½†æœ‰æ˜æ˜¾æ”¹è¿›ç©ºé—´
60-69åˆ†: åŠæ ¼è¡¨ç°ï¼Œå­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œéœ€è¦æ”¹è¿›
50-59åˆ†: ä¸åŠæ ¼è¡¨ç°ï¼Œæœ‰é‡è¦ç¼ºé™·
1-49åˆ†: å·®åŠ²è¡¨ç°ï¼Œå­˜åœ¨æ˜æ˜¾é—®é¢˜

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼ç®€æ´è¾“å‡ºï¼š

è¯„åˆ†ï¼šXXåˆ†

è¯¦ç»†åˆ†æï¼š
[åˆ†æAIçš„å…·ä½“è¡¨ç°ï¼ŒæŒ‡å‡ºä¼˜åŠ¿å’Œä¸è¶³]

æ”¹è¿›å»ºè®®ï¼š
[2-3æ¡å…·ä½“æ”¹è¿›å»ºè®®]
"""
            
            try:
                response = await call_deepseek_api_enhanced(eval_prompt, temperature=0.2, max_tokens=500)
                
                # Extract score (now on 100-point scale)
                score = extract_score_from_response(response)
                evaluation_scores[dimension] = score
                
                # Parse structured response with enhanced detail
                parsed_analysis = parse_evaluation_response_enhanced(response, score)
                
                # Store detailed explanation with enhanced structure
                detailed_explanations[dimension] = {
                    "score": score,
                    "score_out_of": 100,  # Make it clear this is out of 100
                    "detailed_analysis": parsed_analysis.get("detailed_analysis", response),
                    "specific_quotes": parsed_analysis.get("specific_quotes", ""),
                    "improvement_suggestions": parsed_analysis.get("improvement_suggestions", ""),
                    "comprehensive_evaluation": parsed_analysis.get("comprehensive_evaluation", ""),
                    "dimension_name": dimension_name,
                    "full_response": response,
                    "score_grade": get_score_grade(score)  # Add grade label
                }
                
                print(f"  âœ… {dimension_name}: {score}/100 ({get_score_grade(score)})")
                
            except Exception as e:
                print(f"  âŒ {dimension_name}è¯„ä¼°å¤±è´¥: {str(e)}")
                evaluation_scores[dimension] = 60.0
                detailed_explanations[dimension] = {
                    "score": 60.0,
                    "score_out_of": 100,
                    "detailed_analysis": f"è¯„ä¼°å¤±è´¥: {str(e)}ï¼Œè¯·é‡æ–°å°è¯•è¯„ä¼°",
                    "specific_quotes": "ç”±äºæŠ€æœ¯åŸå› ï¼Œæ— æ³•æä¾›å…·ä½“å¯¹è¯å¼•ç”¨",
                    "improvement_suggestions": "å»ºè®®æ£€æŸ¥AI Agenté…ç½®åé‡æ–°è¯„ä¼°",
                    "comprehensive_evaluation": "æŠ€æœ¯é—®é¢˜å¯¼è‡´è¯„ä¼°ä¸­æ–­",
                    "dimension_name": dimension_name,
                    "full_response": f"è¯„ä¼°å¼‚å¸¸: {str(e)}",
                    "score_grade": "åŠæ ¼"
                }
        
        # Calculate overall score (now average of 100-point scores)
        scenario_score = sum(evaluation_scores.values()) / len(evaluation_scores) if evaluation_scores else 60.0
        
        print(f"âœ… è¯„ä¼°å®Œæˆï¼Œåœºæ™¯å¾—åˆ†: {scenario_score:.1f}/100")
        return evaluation_scores, detailed_explanations, scenario_score
        
    except Exception as e:
        print(f"âŒ DeepSeekè¯„ä¼°å¤±è´¥: {str(e)}")
        # Return fallback scores with proper 100-point structure
        fallback_scores = {
            "fuzzy_understanding": 60.0,
            "answer_correctness": 60.0,
            "persona_alignment": 60.0
        }
        fallback_explanations = {
            dim: {
                "score": 60.0, 
                "score_out_of": 100,
                "detailed_analysis": f"ç”±äºæŠ€æœ¯åŸå› å¯¼è‡´è¯„ä¼°å¤±è´¥: {str(e)}ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…ç½®åé‡è¯•ã€‚",
                "specific_quotes": "æ— æ³•è·å–å…·ä½“å¯¹è¯å¼•ç”¨ï¼Œå»ºè®®é‡æ–°è¿›è¡Œè¯„ä¼°",
                "improvement_suggestions": "å»ºè®®æ£€æŸ¥AI Agenté…ç½®å’Œç½‘ç»œè¿æ¥çŠ¶å†µ",
                "comprehensive_evaluation": "æŠ€æœ¯æ•…éšœå¯¼è‡´æ— æ³•å®Œæˆè¯„ä¼°",
                "dimension_name": dim,
                "full_response": f"è¯„ä¼°ç³»ç»Ÿå¼‚å¸¸: {str(e)}",
                "score_grade": "åŠæ ¼"
            }
            for dim in fallback_scores.keys()
        }
        return fallback_scores, fallback_explanations, 60.0

def get_score_grade(score: float) -> str:
    """Convert numerical score to grade label"""
    if score >= 90:
        return "ä¼˜ç§€"
    elif score >= 80:
        return "è‰¯å¥½"
    elif score >= 70:
        return "ä¸­ç­‰"
    elif score >= 60:
        return "åŠæ ¼"
    else:
        return "ä¸åŠæ ¼"

def parse_evaluation_response_enhanced(response: str, score: float) -> Dict[str, str]:
    """
    Parse enhanced evaluation response to extract different sections with better structure
    """
    try:
        # Initialize result
        result = {
            "detailed_analysis": "",
            "specific_quotes": "",
            "improvement_suggestions": "",
            "comprehensive_evaluation": ""
        }
        
        # Split response into lines
        lines = response.strip().split('\n')
        current_section = "detailed_analysis"
        
        for line in lines:
            line = line.strip()
            
            # Identify section headers
            if "è¯¦ç»†åˆ†æ" in line or "åˆ†æ" in line:
                current_section = "detailed_analysis"
                continue
            elif "å…·ä½“å¼•ç”¨" in line or "å¼•ç”¨" in line or "å¯¹è¯" in line:
                current_section = "specific_quotes"
                continue
            elif "æ”¹è¿›å»ºè®®" in line or "å»ºè®®" in line:
                current_section = "improvement_suggestions"
                continue
            elif "ç»¼åˆè¯„ä»·" in line or "è¯„ä»·" in line:
                current_section = "comprehensive_evaluation"
                continue
            elif "è¯„åˆ†" in line:
                continue  # Skip score lines
            
            # Add content to current section
            if line and not line.startswith("è¯„åˆ†"):
                if result[current_section]:
                    result[current_section] += "\n" + line
                else:
                    result[current_section] = line
        
        # Ensure all sections have content with enhanced detail
        if not result["detailed_analysis"]:
            result["detailed_analysis"] = f"è¯„åˆ† {score} åˆ†ï¼ˆ{get_score_grade(score)}ï¼‰ã€‚" + (response[:300] if response else "æœªæä¾›è¯¦ç»†åˆ†æ")
            
        if not result["specific_quotes"]:
            result["specific_quotes"] = "å…·ä½“å¯¹è¯å¼•ç”¨ï¼šç”±äºå“åº”æ ¼å¼é™åˆ¶ï¼Œæœªèƒ½æå–å…·ä½“å¼•ç”¨å†…å®¹ã€‚å»ºè®®äººå·¥æŸ¥çœ‹å¯¹è¯è®°å½•è¿›è¡Œåˆ†æã€‚"
            
        if not result["improvement_suggestions"]:
            result["improvement_suggestions"] = "å»ºè®®ç»§ç»­ä¼˜åŒ–AIå›ç­”è´¨é‡ï¼Œæå‡ç”¨æˆ·æ»¡æ„åº¦ã€‚å…·ä½“æ”¹è¿›æªæ–½éœ€è¦æ ¹æ®å¯¹è¯å†…å®¹è¿›ä¸€æ­¥åˆ†æã€‚"
            
        if not result["comprehensive_evaluation"]:
            result["comprehensive_evaluation"] = f"è¯¥ç»´åº¦å¾—åˆ†{score}åˆ†ï¼Œå±äº{get_score_grade(score)}æ°´å¹³ã€‚"
        
        return result
        
    except Exception as e:
        print(f"âš ï¸ è§£æè¯„ä¼°å“åº”å¤±è´¥: {str(e)}")
        return {
            "detailed_analysis": f"è¯„åˆ† {score} åˆ†ï¼ˆ{get_score_grade(score)}ï¼‰ã€‚" + (response[:300] if response else "è§£æå¤±è´¥ï¼Œæœªæä¾›è¯¦ç»†åˆ†æ"),
            "specific_quotes": "ç”±äºè§£æå¼‚å¸¸ï¼Œæ— æ³•æä¾›å…·ä½“å¯¹è¯å¼•ç”¨",
            "improvement_suggestions": "å»ºè®®é‡æ–°è¿›è¡Œè¯„ä¼°ä»¥è·å–è¯¦ç»†å»ºè®®",
            "comprehensive_evaluation": f"è¯¥ç»´åº¦å¾—åˆ†{score}åˆ†ï¼Œä½†ç”±äºè§£æé—®é¢˜ï¼Œæ— æ³•æä¾›å®Œæ•´è¯„ä»·ã€‚"
        }

async def generate_final_comprehensive_report(
    evaluation_results: List[Dict], 
    user_persona_info: Dict, 
    requirement_context: str
) -> Dict:
    """
    Generate comprehensive final report with enhanced analysis
    """
    try:
        print("ğŸ“Š ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š...")
        
        # Extract key information
        total_scenarios = len(evaluation_results)
        overall_scores = [r.get('scenario_score', 0) for r in evaluation_results]
        avg_score = sum(overall_scores) / len(overall_scores) if overall_scores else 0
        
        persona = user_persona_info.get('user_persona', {})
        context = user_persona_info.get('usage_context', {})
        
        # Generate improvement recommendations
        recommendations = []
        
        if avg_score < 3.0:
            recommendations.extend([
                f"ğŸ”´ é’ˆå¯¹{persona.get('role', 'ç”¨æˆ·')}çš„æ•´ä½“æœåŠ¡èƒ½åŠ›éœ€è¦æ˜¾è‘—æ”¹è¿›",
                f"ğŸ“š åŠ å¼º{context.get('business_domain', 'ä¸“ä¸š')}é¢†åŸŸçš„çŸ¥è¯†åº“å»ºè®¾",
                "ğŸ’¡ æå‡å¯¹æ¨¡ç³Šéœ€æ±‚çš„ç†è§£å’Œè¿½é—®èƒ½åŠ›"
            ])
        elif avg_score < 4.0:
            recommendations.extend([
                f"ğŸŸ¡ å¯¹{persona.get('role', 'ç”¨æˆ·')}çš„æœåŠ¡åŸºæœ¬æ»¡è¶³éœ€æ±‚ï¼Œæœ‰ä¼˜åŒ–ç©ºé—´",
                "ğŸ¯ é’ˆå¯¹ç”¨æˆ·æ²Ÿé€šé£æ ¼è¿›è¡Œä¸ªæ€§åŒ–ä¼˜åŒ–",
                "ğŸ“ˆ ç»§ç»­æå‡ä¸“ä¸šçŸ¥è¯†çš„å‡†ç¡®æ€§"
            ])
        else:
            recommendations.extend([
                f"ğŸŸ¢ å¯¹{persona.get('role', 'ç”¨æˆ·')}çš„æœåŠ¡è¡¨ç°ä¼˜ç§€",
                "âœ¨ ä¿æŒå½“å‰ä¼˜åŠ¿ï¼ŒæŒç»­ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ",
                "ğŸš€ å¯ä»¥è€ƒè™‘æ‰©å±•æ›´å¤šä¸“ä¸šåœºæ™¯æ”¯æŒ"
            ])
        
        return {
            "improvement_recommendations": recommendations,
            "extracted_persona_summary": user_persona_info,
            "persona_alignment_analysis": f"åŸºäº{total_scenarios}ä¸ªåœºæ™¯çš„è¯„ä¼°ï¼ŒAIå¯¹{persona.get('role', 'ç”¨æˆ·')}çš„é€‚é…ç¨‹åº¦ä¸º{avg_score:.2f}/5.0",
            "business_goal_achievement": f"åœ¨{context.get('business_domain', 'ä¸“ä¸šæœåŠ¡')}é¢†åŸŸçš„ç›®æ ‡è¾¾æˆåº¦è‰¯å¥½ï¼Œå¹³å‡å¾—åˆ†{avg_score:.2f}åˆ†"
        }
        
    except Exception as e:
        print(f"âŒ ç»¼åˆæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
        return {
            "improvement_recommendations": ["ç³»ç»Ÿå»ºè®®ï¼šåŠ å¼ºå¯¹è¯ç†è§£èƒ½åŠ›", "ç³»ç»Ÿå»ºè®®ï¼šæé«˜å›ç­”å‡†ç¡®æ€§"],
            "extracted_persona_summary": user_persona_info,
            "persona_alignment_analysis": "åŸºäºç³»ç»Ÿåˆ†æç”Ÿæˆ",
            "business_goal_achievement": "è¯„ä¼°å®Œæˆ"
        }

def find_available_port(start_port: int = 8000, max_port: int = 8010) -> int:
    """Find an available port starting from start_port"""
    for port in range(start_port, max_port + 1):
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            result = sock.connect_ex(('localhost', port))
            sock.close()
            if result != 0:
                return port
        except:
            continue
    return start_port

async def extract_user_persona_with_deepseek(requirement_content: str) -> Dict[str, Any]:
    """
    Use DeepSeek to extract user persona, context, and role information from requirement document
    Enhanced with better document analysis and content matching
    """
    
    # Debug: Log the document content for troubleshooting
    logger.info(f"ğŸ­ å¼€å§‹ç”¨æˆ·ç”»åƒæå–ï¼Œæ–‡æ¡£é•¿åº¦: {len(requirement_content)}")
    logger.debug(f"ğŸ“ æ–‡æ¡£å†…å®¹å‰1000å­—ç¬¦: {requirement_content[:1000]}")
    print(f"ğŸ­ å¼€å§‹ç”¨æˆ·ç”»åƒæå–ï¼Œæ–‡æ¡£é•¿åº¦: {len(requirement_content)}")
    print(f"ğŸ“ æ–‡æ¡£å†…å®¹å‰500å­—ç¬¦: {requirement_content[:500]}")
    
    # Pre-analysis: Check for construction/civil engineering keywords
    construction_keywords = ['å»ºç­‘', 'æ–½å·¥', 'å·¥ç¨‹', 'ç›‘ç†', 'ç°åœº', 'è´¨é‡æ£€æŸ¥', 'å®‰å…¨è§„èŒƒ', 'å»ºç­‘æ–½å·¥', 'åœŸå»º', 'é’¢ç­‹', 'æ··å‡åœŸ', 'åŸºç¡€å·¥ç¨‹', 'ç»“æ„å·¥ç¨‹', 'å®‰è£…å·¥ç¨‹', 'è£…ä¿®å·¥ç¨‹']
    civil_keywords = ['æ°‘ç”¨å»ºç­‘', 'å·¥ä¸šå»ºç­‘', 'åŸºç¡€è®¾æ–½', 'é“è·¯å·¥ç¨‹', 'æ¡¥æ¢å·¥ç¨‹', 'æ°´ç”µå·¥ç¨‹', 'æš–é€šå·¥ç¨‹', 'æ¶ˆé˜²å·¥ç¨‹', 'å›­æ—å·¥ç¨‹', 'å¸‚æ”¿å·¥ç¨‹']
    
    found_construction = [kw for kw in construction_keywords if kw in requirement_content]
    found_civil = [kw for kw in civil_keywords if kw in requirement_content]
    
    logger.info(f"ğŸ” æ£€æµ‹åˆ°å»ºç­‘å…³é”®è¯: {found_construction}")
    logger.info(f"ğŸ” æ£€æµ‹åˆ°åœŸå»ºå…³é”®è¯: {found_civil}")
    print(f"ğŸ” æ£€æµ‹åˆ°å»ºç­‘å…³é”®è¯: {found_construction}")
    print(f"ğŸ” æ£€æµ‹åˆ°åœŸå»ºå…³é”®è¯: {found_civil}")
    
    # First, perform content analysis to identify key domain indicators
    content_analysis_prompt = f"""
è¯·ä»”ç»†åˆ†æä»¥ä¸‹éœ€æ±‚æ–‡æ¡£çš„å†…å®¹ï¼Œå¹¶è¯†åˆ«å…³é”®ä¿¡æ¯ï¼š

æ–‡æ¡£å†…å®¹ï¼š
{requirement_content[:1500]}

è¯·è¯†åˆ«ï¼š
1. æ–‡æ¡£ä¸»è¦æ¶‰åŠçš„è¡Œä¸š/é¢†åŸŸï¼ˆå¦‚ï¼šå»ºç­‘å·¥ç¨‹ã€åœŸæœ¨å·¥ç¨‹ã€é“¶è¡Œé‡‘èã€å®¢æœå’¨è¯¢ã€æŠ€æœ¯æ”¯æŒç­‰ï¼‰
2. ä¸»è¦ä¸šåŠ¡ç±»å‹ï¼ˆå¦‚ï¼šæ–½å·¥ç°åœºç›‘ç†ã€å·¥ç¨‹è´¨é‡æ£€æŸ¥ã€è§„èŒƒæŸ¥è¯¢ã€å®¢æˆ·æœåŠ¡ã€æ•…éšœæ’é™¤ç­‰ï¼‰
3. ç”¨æˆ·å¯èƒ½çš„å·¥ä½œè§’è‰²ï¼ˆå¦‚ï¼šåœŸå»ºå·¥ç¨‹å¸ˆã€å»ºç­‘ç›‘ç†ã€é“¶è¡Œå®¢æœã€æŠ€æœ¯å·¥ç¨‹å¸ˆç­‰ï¼‰
4. ä½¿ç”¨åœºæ™¯ç‰¹å¾ï¼ˆå¦‚ï¼šå»ºç­‘ç°åœºä½œä¸šã€æ–½å·¥ç›‘ç†ã€åŠå…¬å®¤å·¥ä½œã€ç§»åŠ¨åŠå…¬ç­‰ï¼‰

**ç‰¹åˆ«æ³¨æ„**ï¼šå¦‚æœæ–‡æ¡£æ¶‰åŠå»ºç­‘ã€æ–½å·¥ã€å·¥ç¨‹ç›‘ç†ç­‰å†…å®¹ï¼Œè¯·å‡†ç¡®è¯†åˆ«ä¸ºå»ºç­‘å·¥ç¨‹é¢†åŸŸã€‚

åªè¾“å‡ºå…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¸è¦è§£é‡Šï¼š
è¡Œä¸šé¢†åŸŸï¼š
ä¸šåŠ¡ç±»å‹ï¼š
ç”¨æˆ·è§’è‰²ï¼š
ä½¿ç”¨åœºæ™¯ï¼š
"""
    
    try:
        # Step 1: Analyze document content
        logger.info("ğŸ” å¼€å§‹æ–‡æ¡£å†…å®¹åˆ†æ...")
        print("ğŸ” å¼€å§‹æ–‡æ¡£å†…å®¹åˆ†æ...")
        
        content_analysis = await call_deepseek_api_enhanced(content_analysis_prompt, temperature=0.2, max_tokens=200)
        logger.info(f"ğŸ“‹ å†…å®¹åˆ†æç»“æœ: {content_analysis}")
        print(f"ğŸ“‹ å†…å®¹åˆ†æç»“æœ: {content_analysis}")
        
        # Parse analysis results
        analysis_lines = content_analysis.strip().split('\n')
        domain_hints = {}
        
        for line in analysis_lines:
            if 'ï¼š' in line:
                key, value = line.split('ï¼š', 1)
                domain_hints[key.strip()] = value.strip()
        
        logger.info(f"ğŸ” è§£æå¾—åˆ°çš„é¢†åŸŸæç¤º: {domain_hints}")
        print(f"ğŸ” è§£æå¾—åˆ°çš„é¢†åŸŸæç¤º: {domain_hints}")
        
        # Step 2: Enhanced extraction with domain-specific guidance
        extraction_prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„éœ€æ±‚åˆ†æå¸ˆï¼Œè¯·æ ¹æ®ä»¥ä¸‹éœ€æ±‚æ–‡æ¡£è¿›è¡Œç”¨æˆ·ç”»åƒåˆ†æã€‚

**åˆ†æåŸåˆ™ï¼š** 
- åŸºäºæ–‡æ¡£å®é™…å†…å®¹è¿›è¡Œå®¢è§‚åˆ†æ
- è¯†åˆ«æ–‡æ¡£ä¸­æè¿°çš„ä¸»è¦ç”¨æˆ·ç¾¤ä½“å’Œä½¿ç”¨åœºæ™¯
- é‡ç‚¹å…³æ³¨æœ€ç»ˆç”¨æˆ·çš„è§’è‰²å’Œéœ€æ±‚ï¼Œè€Œéç³»ç»Ÿå¼€å‘è€…

**æ–‡æ¡£å†…å®¹åˆ†æï¼š**
è¡Œä¸šé¢†åŸŸï¼š{domain_hints.get('è¡Œä¸šé¢†åŸŸ', 'æœªè¯†åˆ«')}
ä¸šåŠ¡ç±»å‹ï¼š{domain_hints.get('ä¸šåŠ¡ç±»å‹', 'æœªè¯†åˆ«')}  
ç”¨æˆ·è§’è‰²ï¼š{domain_hints.get('ç”¨æˆ·è§’è‰²', 'æœªè¯†åˆ«')}
ä½¿ç”¨åœºæ™¯ï¼š{domain_hints.get('ä½¿ç”¨åœºæ™¯', 'æœªè¯†åˆ«')}

**éœ€æ±‚æ–‡æ¡£åŸæ–‡ï¼š**
{requirement_content}

**åˆ†æè¦æ±‚ï¼š**
1. å‡†ç¡®è¯†åˆ«æ–‡æ¡£ä¸­æè¿°çš„ç”¨æˆ·è§’è‰²å’Œå·¥ä½œåœºæ™¯
2. åˆ†æç”¨æˆ·çš„ä¸“ä¸šèƒŒæ™¯å’Œå·¥ä½œç¯å¢ƒç‰¹ç‚¹
3. æå–å…¸å‹çš„å¯¹è¯åœºæ™¯å’Œäº¤äº’éœ€æ±‚
4. å…³æ³¨ç”¨æˆ·çš„æ²Ÿé€šé£æ ¼å’Œè¡¨è¾¾ä¹ æƒ¯

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºï¼š

{{
    "user_persona": {{
        "role": "åŸºäºæ–‡æ¡£å†…å®¹çš„å…·ä½“ç”¨æˆ·è§’è‰²ï¼ˆå¿…é¡»ä¸{domain_hints.get('è¡Œä¸šé¢†åŸŸ', 'æ–‡æ¡£é¢†åŸŸ')}é«˜åº¦åŒ¹é…ï¼‰",
        "experience_level": "åŸºäºæ–‡æ¡£æ¨æ–­çš„ç»éªŒæ°´å¹³è¯¦ç»†æè¿°", 
        "expertise_areas": ["ä¸æ–‡æ¡£ä¸»é¢˜ç›´æ¥ç›¸å…³çš„ä¸“ä¸šé¢†åŸŸ1", "ç›¸å…³ä¸“ä¸šé¢†åŸŸ2"],
        "communication_style": "ç¬¦åˆè¯¥è¡Œä¸šç‰¹ç‚¹çš„æ²Ÿé€šé£æ ¼ï¼ˆåŒ…æ‹¬æ¨¡ç³Šè¡¨è¾¾ç‰¹å¾ï¼‰",
        "work_environment": "ä¸æ–‡æ¡£ä¸šåŠ¡åœºæ™¯åŒ¹é…çš„å·¥ä½œç¯å¢ƒè¯¦ç»†æè¿°",
        "work_pressure": "è¯¥è§’è‰²å…¸å‹çš„å·¥ä½œå‹åŠ›å’Œæ—¶é—´çº¦æŸ"
    }},
    "usage_context": {{
        "primary_scenarios": ["åŸºäºæ–‡æ¡£çš„ä¸»è¦ä½¿ç”¨åœºæ™¯1", "ç›¸å…³ä½¿ç”¨åœºæ™¯2"],
        "business_domain": "ä¸æ–‡æ¡£å†…å®¹ä¸¥æ ¼å¯¹åº”çš„å…·ä½“ä¸šåŠ¡é¢†åŸŸ",
        "interaction_goals": ["ä¸æ–‡æ¡£éœ€æ±‚ç›´æ¥ç›¸å…³çš„äº¤äº’ç›®æ ‡1", "ç›¸å…³ç›®æ ‡2"],
        "pain_points": ["æ–‡æ¡£ä¸­ä½“ç°çš„ç—›ç‚¹é—®é¢˜1", "ç›¸å…³ç—›ç‚¹2"],
        "usage_timing": ["ç¬¦åˆè¯¥ä¸šåŠ¡ç‰¹ç‚¹çš„ä½¿ç”¨æ—¶æœº1", "ç›¸å…³æ—¶æœº2"]
    }},
    "ai_role_simulation": {{
        "simulated_user_type": "åŸºäºæ–‡æ¡£å†…å®¹çš„ç”¨æˆ·ç±»å‹è¯¦ç»†æè¿°",
        "conversation_approach": "ç¬¦åˆè¯¥è¡Œä¸šçš„å¯¹è¯æ–¹å¼åå¥½", 
        "language_characteristics": "è¯¥è¡Œä¸šç”¨æˆ·çš„è¯­è¨€ç‰¹ç‚¹ï¼ˆåŒ…æ‹¬ä¸“ä¸šæœ¯è¯­ã€è¡¨è¾¾ä¹ æƒ¯ï¼‰",
        "typical_questions": ["è¯¥è§’è‰²åœ¨æ­¤ä¸šåŠ¡åœºæ™¯ä¸‹çš„å…¸å‹é—®é¢˜1", "å…¸å‹é—®é¢˜2", "å…¸å‹é—®é¢˜3"],
        "fuzzy_expressions": ["è¯¥è¡Œä¸šå¸¸è§çš„æ¨¡ç³Šè¡¨è¾¾1", "æ¨¡ç³Šè¡¨è¾¾2", "æ¨¡ç³Šè¡¨è¾¾3"],
        "opening_patterns": ["è¯¥è§’è‰²å¸¸ç”¨çš„å¼€åœºæ–¹å¼1", "å¼€åœºæ–¹å¼2"],
        "situational_variations": "è¯¥è§’è‰²åœ¨ä¸åŒå·¥ä½œæƒ…å†µä¸‹çš„è¡¨è¾¾å·®å¼‚"
    }},
    "extracted_requirements": {{
        "core_functions": ["æ–‡æ¡£ä¸­æ˜ç¡®æåˆ°çš„æ ¸å¿ƒåŠŸèƒ½éœ€æ±‚1", "æ ¸å¿ƒéœ€æ±‚2"],
        "quality_expectations": ["æ–‡æ¡£ä¸­ä½“ç°çš„è´¨é‡æœŸæœ›1", "è´¨é‡æœŸæœ›2"],
        "interaction_preferences": ["åŸºäºä¸šåŠ¡ç‰¹ç‚¹çš„äº¤äº’åå¥½1", "åå¥½2"]
    }}
}}"""

        print("ğŸ§  å¼€å§‹å¢å¼ºçš„ç”¨æˆ·ç”»åƒæå–...")
        
        # Call API with enhanced error handling
        response = await call_deepseek_api_enhanced(extraction_prompt, temperature=0.3, max_tokens=1000)
        print(f"ğŸ“ DeepSeek extraction response: {response[:300]}...")
        
        # Clean and parse response
        cleaned_response = response.strip()
        
        # Remove markdown code blocks if present
        if cleaned_response.startswith('```'):
            lines = cleaned_response.split('\n')
            start_line = 1
            end_line = len(lines) - 1
            
            # Find actual JSON start and end
            for i, line in enumerate(lines):
                if line.strip().startswith('{'):
                    start_line = i
                    break
            
            for i in range(len(lines) - 1, -1, -1):
                if lines[i].strip().endswith('}'):
                    end_line = i
                    break
                    
            cleaned_response = '\n'.join(lines[start_line:end_line + 1])
        
        # Find JSON boundaries
        start_idx = cleaned_response.find('{')
        end_idx = cleaned_response.rfind('}')
        
        if start_idx == -1 or end_idx == -1 or end_idx <= start_idx:
            raise Exception("DeepSeek response does not contain valid JSON structure")
        
        json_str = cleaned_response[start_idx:end_idx+1]
        
        try:
            extraction_result = json.loads(json_str)
            print("âœ… Successfully parsed enhanced extraction result from DeepSeek")
            
            # Validate the structure
            required_keys = ['user_persona', 'usage_context', 'ai_role_simulation', 'extracted_requirements']
            if not all(key in extraction_result for key in required_keys):
                raise Exception(f"JSON structure incomplete, missing keys: {[k for k in required_keys if k not in extraction_result]}")
            
            # Post-processing validation: ensure role matches domain
            user_role = extraction_result.get('user_persona', {}).get('role', '')
            business_domain = extraction_result.get('usage_context', {}).get('business_domain', '')
            
            # Domain consistency check
            domain_mapping = {
                'å»ºç­‘': ['å·¥ç¨‹', 'ç›‘ç†', 'æ–½å·¥', 'å»ºç­‘'],
                'å·¥ç¨‹': ['å·¥ç¨‹å¸ˆ', 'ç›‘ç†', 'æŠ€æœ¯', 'ç°åœº'],  
                'é“¶è¡Œ': ['å®¢æœ', 'é‡‘è', 'é“¶è¡Œ', 'ç†è´¢'],
                'é‡‘è': ['å®¢æœ', 'é‡‘è', 'é“¶è¡Œ', 'ç†è´¢'],
                'å®¢æœ': ['å®¢æœ', 'æœåŠ¡', 'å’¨è¯¢', 'æ¥å¾…'],
                'æŠ€æœ¯': ['æŠ€æœ¯', 'å·¥ç¨‹å¸ˆ', 'å¼€å‘', 'è¿ç»´']
            }
            
            # Check if role matches domain
            domain_keywords = domain_hints.get('è¡Œä¸šé¢†åŸŸ', '').lower()
            role_keywords = user_role.lower()
            
            consistency_check = False
            for domain_key, valid_roles in domain_mapping.items():
                if domain_key in domain_keywords:
                    if any(role_word in role_keywords for role_word in valid_roles):
                        consistency_check = True
                        break
            
            if not consistency_check and domain_keywords:
                print(f"âš ï¸ è§’è‰²ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥ï¼Œé‡æ–°è°ƒæ•´è§’è‰²åŒ¹é…")
                # Adjust role to match domain
                extraction_result = adjust_role_for_domain_consistency(extraction_result, domain_hints)
            
            print(f"âœ… æœ€ç»ˆæå–è§’è‰²: {extraction_result.get('user_persona', {}).get('role', 'æœªçŸ¥')}")
            print(f"âœ… ä¸šåŠ¡é¢†åŸŸ: {extraction_result.get('usage_context', {}).get('business_domain', 'æœªçŸ¥')}")
            
            return extraction_result
            
        except json.JSONDecodeError as e:
            raise Exception(f"Failed to parse DeepSeek response as JSON: {str(e)}")
            
    except Exception as e:
        print(f"âš ï¸ Enhanced persona extraction failed: {str(e)}")
        print("ğŸ”„ Using domain-aware fallback persona generation...")
        
        # Return domain-aware fallback result
        fallback_result = create_domain_aware_fallback_result(requirement_content, domain_hints if 'domain_hints' in locals() else {})
        print("âœ… Domain-aware fallback persona generated successfully")
        return fallback_result

def adjust_role_for_domain_consistency(extraction_result: Dict, domain_hints: Dict) -> Dict:
    """
    Perform light adjustment for domain consistency while preserving DeepSeek's analysis
    """
    domain = domain_hints.get('è¡Œä¸šé¢†åŸŸ', '').lower()
    current_role = extraction_result.get('user_persona', {}).get('role', '')
    
    print(f"ğŸ” é¢†åŸŸä¸€è‡´æ€§æ£€æŸ¥: åŸŸ={domain}, è§’è‰²={current_role}")
    
    # Only perform light validation without forcing changes
    if domain and current_role:
        # Log the extracted role and domain for debugging
        print(f"âœ… æå–çš„è§’è‰²ä¸é¢†åŸŸ: {current_role} in {domain}")
        
        # Basic domain-role matching suggestions (not enforced)
        suggested_domains = {
            'å»ºç­‘': 'å»ºç­‘å·¥ç¨‹',
            'å·¥ç¨‹': 'å·¥ç¨‹æŠ€æœ¯', 
            'é“¶è¡Œ': 'é“¶è¡ŒæœåŠ¡',
            'é‡‘è': 'é‡‘èæœåŠ¡',
            'å®¢æœ': 'å®¢æˆ·æœåŠ¡',
            'åŒ»ç–—': 'åŒ»ç–—å¥åº·',
            'æ•™è‚²': 'æ•™è‚²åŸ¹è®­'
        }
        
        # Suggest business domain if not specific enough
        current_domain = extraction_result.get('usage_context', {}).get('business_domain', '')
        if not current_domain or current_domain in ['ä¸“ä¸šæœåŠ¡', 'æœªçŸ¥']:
            for keyword, suggested_domain in suggested_domains.items():
                if keyword in domain:
                    extraction_result['usage_context']['business_domain'] = suggested_domain
                    print(f"ğŸ’¡ å»ºè®®ä¸šåŠ¡é¢†åŸŸ: {suggested_domain}")
                    break
    
    return extraction_result

def create_domain_aware_fallback_result(requirement_content: str, domain_hints: Dict) -> Dict[str, Any]:
    """
    Create a domain-aware fallback result when parsing fails
    Enhanced with better construction/civil engineering detection
    """
    logger.info("ğŸ”„ åˆ›å»ºé¢†åŸŸæ„ŸçŸ¥çš„å›é€€ç»“æœ...")
    print("ğŸ”„ åˆ›å»ºé¢†åŸŸæ„ŸçŸ¥çš„å›é€€ç»“æœ...")
    
    # Extract domain information with enhanced construction detection
    domain = domain_hints.get('è¡Œä¸šé¢†åŸŸ', extract_business_domain_from_content(requirement_content))
    role = domain_hints.get('ç”¨æˆ·è§’è‰²', extract_role_from_content(requirement_content))
    
    logger.info(f"ğŸ¢ æ£€æµ‹åˆ°é¢†åŸŸ: {domain}")
    logger.info(f"ğŸ‘¤ æ£€æµ‹åˆ°è§’è‰²: {role}")
    print(f"ğŸ¢ æ£€æµ‹åˆ°é¢†åŸŸ: {domain}")
    print(f"ğŸ‘¤ æ£€æµ‹åˆ°è§’è‰²: {role}")
    
    # Enhanced construction/civil engineering detection
    construction_indicators = ['å»ºç­‘', 'æ–½å·¥', 'å·¥ç¨‹', 'ç›‘ç†', 'ç°åœº', 'è´¨é‡', 'å®‰å…¨', 'è§„èŒƒ', 'å»ºè®¾', 'åœŸå»º', 'ç»“æ„', 'åŸºç¡€']
    if any(indicator in requirement_content for indicator in construction_indicators):
        logger.info("ğŸ—ï¸ å¼ºåˆ¶è®¾ç½®ä¸ºå»ºç­‘å·¥ç¨‹é¢†åŸŸ")
        print("ğŸ—ï¸ å¼ºåˆ¶è®¾ç½®ä¸ºå»ºç­‘å·¥ç¨‹é¢†åŸŸ")
        domain = 'å»ºç­‘å·¥ç¨‹'
        role = 'åœŸå»ºå·¥ç¨‹å¸ˆ' if not role or 'æŠ€æœ¯' in role else role
    
    # Ensure role matches domain with enhanced construction handling
    if 'å»ºç­‘' in domain.lower() or 'å·¥ç¨‹' in domain.lower() or 'æ–½å·¥' in domain.lower():
        # More accurate civil engineering role detection
        if 'ç›‘ç†' in requirement_content:
            role = 'å»ºç­‘å·¥ç¨‹ç›‘ç†'
        elif 'æ–½å·¥' in requirement_content:
            role = 'æ–½å·¥å·¥ç¨‹å¸ˆ'
        elif 'è®¾è®¡' in requirement_content:
            role = 'å»ºç­‘è®¾è®¡å¸ˆ'
        elif 'è´¨é‡' in requirement_content:
            role = 'è´¨é‡å·¥ç¨‹å¸ˆ'
        else:
            role = 'åœŸå»ºå·¥ç¨‹å¸ˆ'  # Default for construction
        
        business_domain = 'å»ºç­‘å·¥ç¨‹'
        typical_questions = ["è¿™ä¸ªè§„èŒƒè¦æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ", "æ–½å·¥æ ‡å‡†ç¬¦åˆå—ï¼Ÿ", "è´¨é‡æ£€æŸ¥æ€ä¹ˆåšï¼Ÿ", "å®‰å…¨æªæ–½åˆ°ä½å—ï¼Ÿ", "è¿™ä¸ªææ–™ç¬¦åˆæ ‡å‡†å—ï¼Ÿ"]
        fuzzy_expressions = ["è¿™ä¸ªåœ°æ–¹æœ‰é—®é¢˜", "æ ‡å‡†ä¸å¤ªå¯¹", "éœ€è¦æ£€æŸ¥ä¸€ä¸‹", "è´¨é‡æœ‰ç‚¹é—®é¢˜", "ä¸å¤ªç¬¦åˆè§„èŒƒ"]
    elif 'é“¶è¡Œ' in domain.lower() or 'é‡‘è' in domain.lower():
        role = role if 'å®¢æœ' in role or 'é“¶è¡Œ' in role else 'é“¶è¡Œå®¢æœä»£è¡¨'
        business_domain = 'é“¶è¡Œé‡‘èæœåŠ¡'
        typical_questions = ["å®¢æˆ·é—®è¿™ä¸ªæ€ä¹ˆåŠï¼Ÿ", "è¿™ä¸ªä¸šåŠ¡æ€ä¹ˆå¤„ç†ï¼Ÿ", "æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿ"]
        fuzzy_expressions = ["å®¢æˆ·ä¸æ»¡æ„", "åˆæ˜¯é‚£ä¸ªé—®é¢˜", "æ€ä¹ˆè§£é‡Šå‘¢"]
    elif 'å®¢æœ' in domain.lower():
        role = role if 'å®¢æœ' in role else 'å®¢æœä¸“å‘˜'
        business_domain = 'å®¢æˆ·æœåŠ¡'
        typical_questions = ["å®¢æˆ·æŠ•è¯‰æ€ä¹ˆå¤„ç†ï¼Ÿ", "è¿™ä¸ªé—®é¢˜æ€ä¹ˆè§£å†³ï¼Ÿ", "æœåŠ¡æ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿ"]
        fuzzy_expressions = ["å®¢æˆ·åˆæŠ•è¯‰äº†", "è€é—®é¢˜äº†", "ä¸çŸ¥é“æ€ä¹ˆè¯´"]
    else:
        role = role or 'ä¸“ä¸šç”¨æˆ·'
        business_domain = domain or 'ä¸“ä¸šæœåŠ¡'
        typical_questions = ["è¿™ä¸ªæ€ä¹ˆå¤„ç†ï¼Ÿ", "è§„èŒƒè¦æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ", "è¿˜æœ‰å…¶ä»–æ–¹æ¡ˆå—ï¼Ÿ"]
        fuzzy_expressions = ["æœ‰ç‚¹é—®é¢˜", "ä¸å¤ªå¯¹", "æ€ä¹ˆå¤„ç†ï¼Ÿ"]

    return {
        "user_persona": {
            "role": role,
            "experience_level": "ä¸­ç­‰ç»éªŒä¸“ä¸šç”¨æˆ·",
            "expertise_areas": [business_domain, "ç›¸å…³ä¸“ä¸šçŸ¥è¯†"],
            "communication_style": "ä¸“ä¸šä½†æœ‰æ—¶è¡¨è¾¾ä¸å®Œæ•´ï¼Œè´´åˆè¡Œä¸šç‰¹ç‚¹",
            "work_environment": f"{business_domain}å·¥ä½œç¯å¢ƒ",
            "work_pressure": "æ­£å¸¸å·¥ä½œå‹åŠ›ï¼Œæ³¨é‡æ•ˆç‡å’Œå‡†ç¡®æ€§"
        },
        "usage_context": {
            "primary_scenarios": [f"{business_domain}å’¨è¯¢", "å·¥ä½œæ”¯æŒ"],
            "business_domain": business_domain,
            "interaction_goals": ["è·å–å‡†ç¡®ä¿¡æ¯", "è§£å†³å·¥ä½œé—®é¢˜"],
            "pain_points": ["ä¿¡æ¯ä¸å¤Ÿå…·ä½“", "å›ç­”æ—¶é—´è¾ƒé•¿"],
            "usage_timing": ["å·¥ä½œæ—¶é—´", "é‡åˆ°é—®é¢˜æ—¶", "éœ€è¦ç¡®è®¤æ—¶"]
        },
        "ai_role_simulation": {
            "simulated_user_type": f"åŸºäº{business_domain}çš„{role}",
            "conversation_approach": "ç›´æ¥æé—®ï¼Œæœ‰æ—¶è¡¨è¾¾æ¨¡ç³Š",
            "language_characteristics": f"{business_domain}ä¸“ä¸šæœ¯è¯­ä¸æ—¥å¸¸è¡¨è¾¾æ··åˆ",
            "typical_questions": typical_questions,
            "fuzzy_expressions": fuzzy_expressions,
            "opening_patterns": ["å…³äºè¿™ä¸ª...", "éœ€è¦å’¨è¯¢...", "æœ‰ä¸ªé—®é¢˜...", "æƒ³äº†è§£..."],
            "situational_variations": "å·¥ä½œç¹å¿™æ—¶è¡¨è¾¾ç®€çŸ­ï¼Œæ­£å¸¸æƒ…å†µä¸‹ä¼šè¯¦ç»†æè¿°"
        },
        "extracted_requirements": {
            "core_functions": ["å‡†ç¡®ä¿¡æ¯æŸ¥è¯¢", "ä¸“ä¸šé—®é¢˜è§£ç­”"],
            "quality_expectations": ["å›ç­”å‡†ç¡®", "å“åº”åŠæ—¶", "ä¸“ä¸šæ€§å¼º"],
            "interaction_preferences": ["ç®€æ´æ˜äº†", "åŒ…å«å…·ä½“ç¤ºä¾‹", "æä¾›æ“ä½œæŒ‡å¯¼"]
        }
    }

def extract_role_from_content(content: str) -> Optional[str]:
    """Extract user role from content"""
    if "å®¢æœ" in content:
        return "å®¢æœä»£è¡¨"
    elif "ç›‘ç†" in content:
        return "ç°åœºç›‘ç†å·¥ç¨‹å¸ˆ"
    elif "å·¥ç¨‹å¸ˆ" in content:
        return "å·¥ç¨‹å¸ˆ"
    elif "æŠ€æœ¯" in content:
        return "æŠ€æœ¯äººå‘˜"
    return None

def extract_business_domain_from_content(content: str) -> str:
    """Extract business domain from content with enhanced construction detection"""
    logger.debug(f"ğŸ” åˆ†æä¸šåŠ¡é¢†åŸŸï¼Œå†…å®¹å‰200å­—ç¬¦: {content[:200]}")
    
    # Enhanced construction/civil engineering detection
    construction_keywords = ['å»ºç­‘', 'æ–½å·¥', 'å·¥ç¨‹', 'ç›‘ç†', 'ç°åœº', 'è´¨é‡æ£€æŸ¥', 'å®‰å…¨è§„èŒƒ', 'å»ºç­‘æ–½å·¥', 'åœŸå»º', 'é’¢ç­‹', 'æ··å‡åœŸ', 'åŸºç¡€å·¥ç¨‹', 'ç»“æ„å·¥ç¨‹']
    civil_keywords = ['æ°‘ç”¨å»ºç­‘', 'å·¥ä¸šå»ºç­‘', 'åŸºç¡€è®¾æ–½', 'é“è·¯å·¥ç¨‹', 'æ¡¥æ¢å·¥ç¨‹', 'æ°´ç”µå·¥ç¨‹', 'æš–é€šå·¥ç¨‹', 'æ¶ˆé˜²å·¥ç¨‹']
    
    construction_count = sum(1 for kw in construction_keywords if kw in content)
    civil_count = sum(1 for kw in civil_keywords if kw in content)
    
    logger.debug(f"ğŸ—ï¸ å»ºç­‘å…³é”®è¯åŒ¹é…æ•°: {construction_count}")
    logger.debug(f"ğŸ—ï¸ åœŸå»ºå…³é”®è¯åŒ¹é…æ•°: {civil_count}")
    
    if construction_count > 0 or civil_count > 0:
        logger.info("âœ… è¯†åˆ«ä¸ºå»ºç­‘å·¥ç¨‹é¢†åŸŸ")
        return "å»ºç­‘å·¥ç¨‹"
    elif "é“¶è¡Œ" in content or "é‡‘è" in content:
        return "é“¶è¡Œé‡‘èæœåŠ¡"
    elif "å®¢æœ" in content:
        return "å®¢æˆ·æœåŠ¡"
    elif "æŠ€æœ¯" in content and "å·¥ç¨‹" not in content:  # Avoid misclassifying engineering as tech support
        return "æŠ€æœ¯æ”¯æŒ"
    else:
        return "ä¸“ä¸šæœåŠ¡"

async def conduct_dynamic_multi_scenario_evaluation(
    api_config: APIConfig,
    user_persona_info: Dict,
    requirement_context: str,
    use_raw_messages: bool = False
) -> List[Dict]:
    """
    Conduct dynamic multi-scenario evaluation based on extracted user persona
    """
    try:
        print("ğŸ¯ å¼€å§‹åŠ¨æ€å¤šåœºæ™¯è¯„ä¼°...")
        
        # Generate 2 dynamic scenarios based on user persona
        scenarios = await generate_dynamic_scenarios_from_persona(user_persona_info)
        
        if not scenarios:
            print("âš ï¸ æ— æ³•ç”ŸæˆåŠ¨æ€åœºæ™¯ï¼Œä½¿ç”¨é»˜è®¤åœºæ™¯")
            scenarios = [
                {
                    "title": "åŸºç¡€å’¨è¯¢åœºæ™¯",
                    "context": f"{user_persona_info.get('usage_context', {}).get('business_domain', 'ä¸“ä¸šæœåŠ¡')}å’¨è¯¢",
                    "user_profile": user_persona_info.get('user_persona', {}).get('role', 'ä¸“ä¸šç”¨æˆ·')
                },
                {
                    "title": "é—®é¢˜è§£å†³åœºæ™¯", 
                    "context": f"{user_persona_info.get('usage_context', {}).get('business_domain', 'ä¸“ä¸šæœåŠ¡')}é—®é¢˜å¤„ç†",
                    "user_profile": user_persona_info.get('user_persona', {}).get('role', 'ä¸“ä¸šç”¨æˆ·')
                }
            ]
        
        evaluation_results = []
        
        for i, scenario_info in enumerate(scenarios, 1):
            print(f"ğŸ“‹ åœºæ™¯ {i}/{len(scenarios)}: {scenario_info.get('title', 'æœªå‘½ååœºæ™¯')}")
            
            try:
                # Conduct true dynamic conversation for this scenario
                conversation_history = await conduct_true_dynamic_conversation(
                    api_config, scenario_info, user_persona_info, use_raw_messages
                )
                
                if not conversation_history:
                    print(f"âš ï¸ åœºæ™¯ {i} å¯¹è¯å¤±è´¥ï¼Œè·³è¿‡")
                    continue
                
                # Evaluate the conversation
                evaluation_scores, detailed_explanations, scenario_score = await evaluate_conversation_with_deepseek(
                    conversation_history, scenario_info, requirement_context, user_persona_info
                )
                
                # Convert scenario score to 5-point scale for consistency
                scenario_score_5 = scenario_score / 20.0 if scenario_score > 5 else scenario_score
                
                # Create evaluation result
                evaluation_result = {
                    "scenario": {
                        "title": scenario_info.get('title', f'åœºæ™¯ {i}'),
                        "context": scenario_info.get('context', 'åŠ¨æ€ç”Ÿæˆåœºæ™¯'),
                        "user_profile": scenario_info.get('user_profile', user_persona_info.get('user_persona', {}).get('role', 'ä¸“ä¸šç”¨æˆ·'))
                    },
                    "conversation_history": conversation_history,
                    "evaluation_scores": evaluation_scores,
                    "detailed_explanations": detailed_explanations,
                    "scenario_score": round(scenario_score_5, 2),  # Use 5-point scale
                    "scenario_score_100": round(scenario_score, 2),  # Also provide 100-point scale
                    "evaluation_mode": "dynamic",
                    "timestamp": datetime.now().isoformat()
                }
                
                evaluation_results.append(evaluation_result)
                print(f"âœ… åœºæ™¯ {i} è¯„ä¼°å®Œæˆï¼Œå¾—åˆ†: {scenario_score_5:.2f}/5.0")
                
            except Exception as e:
                print(f"âŒ åœºæ™¯ {i} è¯„ä¼°å¤±è´¥: {str(e)}")
                continue
        
        if not evaluation_results:
            raise Exception("æ‰€æœ‰åœºæ™¯è¯„ä¼°å‡å¤±è´¥")
        
        print(f"ğŸ¯ åŠ¨æ€å¤šåœºæ™¯è¯„ä¼°å®Œæˆï¼Œå…±å®Œæˆ {len(evaluation_results)} ä¸ªåœºæ™¯")
        return evaluation_results
        
    except Exception as e:
        print(f"âŒ åŠ¨æ€å¤šåœºæ™¯è¯„ä¼°å¤±è´¥: {str(e)}")
        raise e

async def generate_dynamic_scenarios_from_persona(user_persona_info: Dict) -> List[Dict]:
    """
    Generate dynamic scenarios based on extracted user persona
    """
    try:
        persona = user_persona_info.get('user_persona', {})
        context = user_persona_info.get('usage_context', {})
        
        # Generate scenarios based on primary scenarios from persona
        primary_scenarios = context.get('primary_scenarios', ['ä¸“ä¸šå’¨è¯¢', 'å·¥ä½œæ”¯æŒ'])
        business_domain = context.get('business_domain', 'ä¸“ä¸šæœåŠ¡')
        role = persona.get('role', 'ä¸“ä¸šç”¨æˆ·')
        
        scenarios = []
        
        # Generate first scenario based on primary use case
        if len(primary_scenarios) >= 1:
            scenarios.append({
                "title": f"{primary_scenarios[0]}åœºæ™¯",
                "context": f"{business_domain} - {primary_scenarios[0]}",
                "user_profile": f"{role}ï¼Œ{persona.get('experience_level', 'ä¸­ç­‰ç»éªŒ')}"
            })
        
        # Generate second scenario based on secondary use case or pain points
        if len(primary_scenarios) >= 2:
            scenarios.append({
                "title": f"{primary_scenarios[1]}åœºæ™¯",
                "context": f"{business_domain} - {primary_scenarios[1]}",
                "user_profile": f"{role}ï¼Œ{persona.get('experience_level', 'ä¸­ç­‰ç»éªŒ')}"
            })
        elif context.get('pain_points'):
            # Create scenario based on pain points
            pain_point = context['pain_points'][0] if context['pain_points'] else 'æ•ˆç‡æå‡'
            scenarios.append({
                "title": f"{pain_point}è§£å†³åœºæ™¯",
                "context": f"{business_domain} - è§£å†³{pain_point}é—®é¢˜",
                "user_profile": f"{role}ï¼Œ{persona.get('experience_level', 'ä¸­ç­‰ç»éªŒ')}"
            })
        
        return scenarios[:2]  # Return maximum 2 scenarios
        
    except Exception as e:
        print(f"âŒ åŠ¨æ€åœºæ™¯ç”Ÿæˆå¤±è´¥: {str(e)}")
        return []

@app.post("/api/test-with-raw-coze-conversation")
async def test_with_raw_coze_conversation(
    agent_api_config: str = Form(...),
    coze_conversation_json: str = Form(...),
    use_raw_message: bool = Form(True)
):
    """
    Test AI Agent with raw Coze conversation JSON - extracts user message and sends it directly
    """
    try:
        print("ğŸ§ª å¼€å§‹åŸå§‹Cozeå¯¹è¯æµ‹è¯•...")
        
        # Parse API configuration
        api_config_dict = json.loads(agent_api_config)
        api_config = APIConfig(**api_config_dict)
        
        # Parse Coze conversation JSON
        coze_data = json.loads(coze_conversation_json)
        
        # Extract raw user message
        raw_user_message = extract_user_message_from_coze_json(coze_data)
        
        if not raw_user_message:
            raise HTTPException(status_code=400, detail="æ— æ³•ä»Cozeå¯¹è¯JSONä¸­æå–ç”¨æˆ·æ¶ˆæ¯")
        
        print(f"âœ… æå–åˆ°åŸå§‹ç”¨æˆ·æ¶ˆæ¯: {raw_user_message}")
        
        # Call AI Agent with raw message
        ai_response = await call_ai_agent_api(api_config, raw_user_message, use_raw_message=use_raw_message)
        
        return {
            "status": "success",
            "raw_user_message": raw_user_message,
            "ai_response": ai_response,
            "use_raw_message": use_raw_message,
            "message_processing_mode": "RAW" if use_raw_message else "ENHANCED",
            "timestamp": datetime.now().isoformat()
        }
        
    except json.JSONDecodeError as e:
        raise HTTPException(status_code=400, detail=f"JSONè§£æå¤±è´¥: {str(e)}")
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Raw Coze conversation test failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æµ‹è¯•å¤±è´¥: {str(e)}")

@app.post("/api/extract-user-persona")
async def extract_user_persona(
    requirement_file: UploadFile = File(None),
    requirement_text: str = Form(None)
):
    """
    Extract user persona from requirement document
    """
    try:
        logger.info("ğŸ­ å¼€å§‹ç”¨æˆ·ç”»åƒæå–...")
        print("ğŸ­ å¼€å§‹ç”¨æˆ·ç”»åƒæå–...")
        
        # Handle requirement document
        requirement_context = ""
        
        if requirement_file and requirement_file.filename:
            logger.info(f"ğŸ“„ Processing uploaded file: {requirement_file.filename}")
            print(f"ğŸ“„ Processing uploaded file: {requirement_file.filename}")
            requirement_context = await process_uploaded_document_improved(requirement_file)
        elif requirement_text:
            logger.info("ğŸ“ Using provided text content")
            print("ğŸ“ Using provided text content")
            requirement_context = requirement_text
        
        if not requirement_context:
            raise HTTPException(status_code=400, detail="è¯·æä¾›éœ€æ±‚æ–‡æ¡£æˆ–æ–‡æœ¬å†…å®¹")
            
        logger.info(f"âœ… Document processed, length: {len(requirement_context)} characters")
        print(f"âœ… Document processed, length: {len(requirement_context)} characters")
        
        # Extract user persona using enhanced algorithm
        user_persona_info = await extract_user_persona_with_deepseek(requirement_context)
        
        if not user_persona_info:
            raise HTTPException(status_code=400, detail="æ— æ³•ä»éœ€æ±‚æ–‡æ¡£ä¸­æå–æœ‰æ•ˆçš„ç”¨æˆ·ç”»åƒä¿¡æ¯")
        
        return {
            "status": "success",
            "extraction_result": user_persona_info,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Persona extraction failed: {str(e)}")
        logger.error(f"ğŸ“‹ Traceback: {traceback.format_exc()}")
        print(f"âŒ Persona extraction failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç”¨æˆ·ç”»åƒæå–å¤±è´¥: {str(e)}")

@app.post("/api/debug-document-processing")
async def debug_document_processing(
    requirement_file: UploadFile = File(None),
    requirement_text: str = Form(None)
):
    """
    Debug endpoint to test document processing and persona extraction separately
    This helps identify where the issue occurs in cloud deployment
    """
    try:
        result = {
            "document_processing": {},
            "persona_extraction": {},
            "domain_analysis": {},
            "errors": []
        }
        
        # Step 1: Document Processing
        requirement_context = ""
        
        if requirement_file and requirement_file.filename:
            logger.info(f"ğŸ§ª Debug: Processing file {requirement_file.filename}")
            try:
                requirement_context = await process_uploaded_document_improved(requirement_file)
                result["document_processing"] = {
                    "status": "success",
                    "filename": requirement_file.filename,
                    "content_length": len(requirement_context),
                    "content_preview": requirement_context[:300] + "..." if len(requirement_context) > 300 else requirement_context,
                    "file_type": getattr(requirement_file, 'content_type', 'unknown')
                }
            except Exception as e:
                error_msg = f"Document processing failed: {str(e)}"
                result["document_processing"] = {
                    "status": "error",
                    "error": error_msg,
                    "traceback": traceback.format_exc()
                }
                result["errors"].append(error_msg)
                
        elif requirement_text:
            requirement_context = requirement_text
            result["document_processing"] = {
                "status": "success",
                "source": "text_input",
                "content_length": len(requirement_context),
                "content_preview": requirement_context[:300] + "..." if len(requirement_context) > 300 else requirement_context
            }
        
        if not requirement_context:
            result["errors"].append("No document content available")
            return result
        
        # Step 2: Domain Analysis
        try:
            domain = extract_business_domain_from_content(requirement_context)
            role = extract_role_from_content(requirement_context)
            
            # Construction keywords analysis
            construction_keywords = ['å»ºç­‘', 'æ–½å·¥', 'å·¥ç¨‹', 'ç›‘ç†', 'ç°åœº', 'è´¨é‡æ£€æŸ¥', 'å®‰å…¨è§„èŒƒ', 'å»ºç­‘æ–½å·¥', 'åœŸå»º', 'é’¢ç­‹', 'æ··å‡åœŸ', 'åŸºç¡€å·¥ç¨‹', 'ç»“æ„å·¥ç¨‹']
            found_keywords = [kw for kw in construction_keywords if kw in requirement_context]
            
            result["domain_analysis"] = {
                "status": "success",
                "detected_domain": domain,
                "detected_role": role,
                "construction_keywords_found": found_keywords,
                "total_construction_keywords": len(found_keywords),
                "is_construction_content": len(found_keywords) > 0
            }
        except Exception as e:
            error_msg = f"Domain analysis failed: {str(e)}"
            result["domain_analysis"] = {
                "status": "error",
                "error": error_msg
            }
            result["errors"].append(error_msg)
        
        # Step 3: Persona Extraction
        try:
            user_persona_info = await extract_user_persona_with_deepseek(requirement_context)
            result["persona_extraction"] = {
                "status": "success",
                "extracted_role": user_persona_info.get('user_persona', {}).get('role', 'N/A'),
                "business_domain": user_persona_info.get('usage_context', {}).get('business_domain', 'N/A'),
                "extraction_method": "deepseek_api",
                "full_result": user_persona_info
            }
        except Exception as e:
            error_msg = f"Persona extraction failed: {str(e)}"
            result["persona_extraction"] = {
                "status": "error",
                "error": error_msg,
                "traceback": traceback.format_exc()
            }
            result["errors"].append(error_msg)
            
            # Try fallback method
            try:
                fallback_result = create_domain_aware_fallback_result(requirement_context, {})
                result["persona_extraction"]["fallback_result"] = {
                    "role": fallback_result.get('user_persona', {}).get('role', 'N/A'),
                    "business_domain": fallback_result.get('usage_context', {}).get('business_domain', 'N/A'),
                    "method": "fallback"
                }
            except Exception as fallback_error:
                result["persona_extraction"]["fallback_error"] = str(fallback_error)
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ Debug endpoint failed: {str(e)}")
        return {
            "status": "error",
            "error": str(e),
            "traceback": traceback.format_exc()
        }

# Database related functions
def get_database_connection():
    """
    Create database connection
    """
    if not PYMYSQL_AVAILABLE or not config.ENABLE_DATABASE_SAVE:
        return None
    
    try:
        connection = pymysql.connect(**config.DATABASE_CONFIG)
        return connection
    except Exception as e:
        print(f"âŒ Database connection failed: {str(e)}")
        return None

def generate_session_id() -> str:
    """
    Generate unique session ID for evaluation
    """
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    random_suffix = uuid.uuid4().hex[:8]
    return f"EVAL_{timestamp}_{random_suffix}"

async def save_evaluation_to_database(evaluation_data: Dict, requirement_context: str = "") -> str:
    """
    Save evaluation results to database
    Returns session_id if successful, None if failed
    """
    if not PYMYSQL_AVAILABLE or not config.ENABLE_DATABASE_SAVE:
        print("ğŸ“ Database save disabled or PyMySQL not available")
        return None
    
    connection = get_database_connection()
    if not connection:
        print("âŒ Cannot connect to database")
        return None
    
    session_id = generate_session_id()
    
    try:
        with connection.cursor() as cursor:
            # Insert main evaluation session
            insert_session_sql = """
                INSERT INTO ai_evaluation_sessions (
                    session_id, overall_score, total_scenarios, total_conversations,
                    evaluation_mode, evaluation_framework, requirement_document,
                    ai_agent_config, user_persona_info, evaluation_summary, recommendations
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """
            
            evaluation_summary = evaluation_data.get('evaluation_summary', {})
            
            # Convert 100-point scale to 5-point scale for database storage
            overall_score = evaluation_summary.get('overall_score_100', evaluation_summary.get('overall_score', 0))
            if overall_score > 5:  # If it's 100-point scale, convert to 5-point scale
                overall_score_5_point = overall_score / 20.0  # Convert 100-point to 5-point
            else:
                overall_score_5_point = overall_score
            
            cursor.execute(insert_session_sql, (
                session_id,
                round(overall_score_5_point, 2),  # Store as 5-point scale
                evaluation_summary.get('total_scenarios', 0),
                evaluation_summary.get('total_conversations', 0),
                evaluation_data.get('evaluation_mode', 'manual'),
                evaluation_summary.get('framework', 'AI Agent 3ç»´åº¦è¯„ä¼°æ¡†æ¶'),
                requirement_context[:5000] if requirement_context else None,  # Limit length
                json.dumps(evaluation_data.get('ai_agent_config', {})),
                json.dumps(evaluation_data.get('user_persona_info', {})),
                json.dumps(evaluation_summary),
                json.dumps(evaluation_data.get('recommendations', []))
            ))
            
            # Insert conversation scenarios and records
            conversation_records = evaluation_data.get('conversation_records', [])
            
            for scenario_index, record in enumerate(conversation_records):
                scenario = record.get('scenario', {})
                conversation_history = record.get('conversation_history', [])
                evaluation_scores = record.get('evaluation_scores_with_explanations', {})
                
                # Insert scenario
                insert_scenario_sql = """
                    INSERT INTO ai_conversation_scenarios (
                        session_id, scenario_index, scenario_title, scenario_context,
                        user_profile, scenario_score, conversation_turns
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s)
                """
                
                # Convert scenario score to 5-point scale for database storage
                scenario_score = record.get('scenario_score_100', record.get('scenario_score', 0))
                if scenario_score > 5:  # If it's 100-point scale, convert to 5-point scale
                    scenario_score_5_point = scenario_score / 20.0
                else:
                    scenario_score_5_point = scenario_score
                
                cursor.execute(insert_scenario_sql, (
                    session_id,
                    scenario_index,
                    scenario.get('title', f'åœºæ™¯ {scenario_index + 1}'),
                    scenario.get('context', ''),
                    scenario.get('user_profile', ''),
                    round(scenario_score_5_point, 2),  # Store as 5-point scale
                    len(conversation_history)
                ))
                
                scenario_id = cursor.lastrowid
                
                # Insert conversation turns
                for turn in conversation_history:
                    insert_turn_sql = """
                        INSERT INTO ai_conversation_turns (
                            session_id, scenario_id, turn_number, user_message,
                            enhanced_message, ai_response, response_length
                        ) VALUES (%s, %s, %s, %s, %s, %s, %s)
                    """
                    
                    cursor.execute(insert_turn_sql, (
                        session_id,
                        scenario_id,
                        turn.get('turn', 0),
                        turn.get('user_message', ''),
                        turn.get('enhanced_message', ''),
                        turn.get('ai_response', ''),
                        len(turn.get('ai_response', ''))
                    ))
                
                # Insert evaluation scores
                for dimension_name, score_data in evaluation_scores.items():
                    if isinstance(score_data, dict):
                        insert_score_sql = """
                            INSERT INTO ai_evaluation_scores (
                                session_id, scenario_id, dimension_name, dimension_label,
                                score, detailed_analysis, specific_quotes,
                                improvement_suggestions, full_response
                            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                        """
                        
                        dimension_labels = {
                            'fuzzy_understanding': 'æ¨¡ç³Šç†è§£ä¸è¿½é—®èƒ½åŠ›',
                            'answer_correctness': 'å›ç­”å‡†ç¡®æ€§ä¸ä¸“ä¸šæ€§',
                            'persona_alignment': 'ç”¨æˆ·åŒ¹é…åº¦',
                            'goal_alignment': 'ç›®æ ‡å¯¹é½åº¦'
                        }
                        
                        # Convert dimension score to 5-point scale for database storage
                        dimension_score = score_data.get('score', 0)
                        if dimension_score > 5:  # If it's 100-point scale, convert to 5-point scale
                            dimension_score_5_point = dimension_score / 20.0
                        else:
                            dimension_score_5_point = dimension_score
                        
                        cursor.execute(insert_score_sql, (
                            session_id,
                            scenario_id,
                            dimension_name,
                            dimension_labels.get(dimension_name, dimension_name),
                            round(dimension_score_5_point, 2),  # Store as 5-point scale
                            score_data.get('detailed_analysis', ''),
                            score_data.get('specific_quotes', ''),
                            score_data.get('improvement_suggestions', ''),
                            score_data.get('full_response', '')
                        ))
        
        connection.commit()
        print(f"âœ… Evaluation data saved to database with session_id: {session_id}")
        return session_id
        
    except Exception as e:
        connection.rollback()
        print(f"âŒ Failed to save evaluation to database: {str(e)}")
        print(f"Full traceback: {traceback.format_exc()}")
        return None
    finally:
        connection.close()

async def save_download_record(session_id: str, download_format: str, include_transcript: bool, 
                             file_size: int = None, request: Request = None) -> bool:
    """
    Record download activity
    """
    if not PYMYSQL_AVAILABLE or not config.ENABLE_DATABASE_SAVE:
        return False
    
    connection = get_database_connection()
    if not connection:
        return False
    
    try:
        with connection.cursor() as cursor:
            client_ip = request.client.host if request else None
            user_agent = request.headers.get("user-agent") if request else None
            
            insert_sql = """
                INSERT INTO ai_report_downloads (
                    session_id, download_format, include_transcript,
                    file_size, download_ip, user_agent
                ) VALUES (%s, %s, %s, %s, %s, %s)
            """
            
            cursor.execute(insert_sql, (
                session_id, download_format, include_transcript,
                file_size, client_ip, user_agent
            ))
        
        connection.commit()
        return True
        
    except Exception as e:
        print(f"âŒ Failed to save download record: {str(e)}")
        return False
    finally:
        connection.close()

def extract_user_message_from_coze_json(coze_conversation_json: Dict) -> str:
    """
    Extract raw user message from Coze conversation JSON structure
    
    Expected Coze JSON structure:
    {
        "additional_messages": [
            {
                "content_type": "text",
                "type": "question",
                "role": "user", 
                "content": "SBSå·ææ­æ¥å¤„çƒ­ç†”è´¨é‡æ£€æŸ¥æƒ…å†µï¼ŸèŠ‚ç‚¹éƒ¨ä½é™„åŠ å±‚è¦åšé—­æ°´è¯•éªŒ"
            }
        ]
    }
    """
    try:
        # ğŸ› Debug log for Coze JSON parsing
        print(f"ğŸ” [COZE JSON] Extracting user message from: {json.dumps(coze_conversation_json, ensure_ascii=False)[:200]}...")
        
        # Try to extract from additional_messages (most common)
        if "additional_messages" in coze_conversation_json:
            additional_messages = coze_conversation_json["additional_messages"]
            if isinstance(additional_messages, list) and len(additional_messages) > 0:
                first_message = additional_messages[0]
                if isinstance(first_message, dict) and "content" in first_message:
                    raw_content = first_message["content"].strip()
                    print(f"ğŸ” [EXTRACTED] Raw user message: {raw_content}")
                    return raw_content
        
        # Try to extract from messages array
        if "messages" in coze_conversation_json:
            messages = coze_conversation_json["messages"]
            if isinstance(messages, list):
                for message in messages:
                    if (isinstance(message, dict) and 
                        message.get("role") == "user" and 
                        "content" in message):
                        raw_content = message["content"].strip()
                        print(f"ğŸ” [EXTRACTED] Raw user message from messages: {raw_content}")
                        return raw_content
        
        # Try direct content field
        if "content" in coze_conversation_json:
            raw_content = coze_conversation_json["content"].strip()
            print(f"ğŸ” [EXTRACTED] Raw user message from content: {raw_content}")
            return raw_content
        
        # Fallback - look for any text content
        for key, value in coze_conversation_json.items():
            if isinstance(value, str) and len(value.strip()) > 5:
                print(f"ğŸ” [FALLBACK] Using field '{key}': {value.strip()}")
                return value.strip()
        
        print("âŒ [EXTRACTION FAILED] No user message found in Coze JSON")
        return ""
        
    except Exception as e:
        print(f"âŒ [EXTRACTION ERROR] Failed to extract user message: {str(e)}")
        return ""

def clean_ai_response(response: str) -> str:
    """
    Clean AI response to extract meaningful content and filter out system messages
    Enhanced to properly handle plugin tool outputs
    """
    try:
        original_response = response
        print(f"ğŸ§¹ Cleaning AI response: {response[:100]}...")
        
        # ğŸ”§ NEW: First check if this is a plugin tool output that we want to preserve
        if response and not response.strip().startswith('{"name":"'):
            # This might be actual tool output content, preserve it
            pass
        elif (response.strip().startswith('{"name":"') and 
            '"arguments":' in response and
            '"plugin_id":' in response):
            # This is a plugin invocation JSON - try to extract tool output
            try:
                plugin_data = json.loads(response)
                tool_output_fields = ['tool_output_content', 'output', 'result', 'content', 'answer']
                
                for field in tool_output_fields:
                    if field in plugin_data and plugin_data[field]:
                        tool_output = str(plugin_data[field])
                        if len(tool_output.strip()) > 10:
                            print(f"ğŸ”§ Extracted {field} from plugin JSON: {tool_output[:80]}...")
                            return clean_ai_response(tool_output)  # Recursive clean
                
                # Check nested arguments
                if 'arguments' in plugin_data and isinstance(plugin_data['arguments'], dict):
                    args = plugin_data['arguments']
                    for field in tool_output_fields:
                        if field in args and args[field]:
                            tool_output = str(args[field])
                            if len(tool_output.strip()) > 10:
                                print(f"ğŸ”§ Extracted args.{field} from plugin JSON: {tool_output[:80]}...")
                                return clean_ai_response(tool_output)  # Recursive clean
                
                print("ğŸš« No useful tool output found in plugin JSON, filtering out")
                return ""  # Return empty if no tool output found
                
            except json.JSONDecodeError:
                print("ğŸš« Backup filter: Detected malformed plugin JSON, filtering out")
                return ""
        
        # Check for pure system messages (skip only if entire response is system content)
        system_only_indicators = [
            '"msg_type":"time_capsule_recall"',
            '"msg_type":"conversation_summary"', 
            '"msg_type":"system_message"'
        ]
        
        # If the response is ONLY a system message, skip it
        if (response.strip().startswith('{"msg_type"') and 
            any(indicator in response for indicator in system_only_indicators) and
            len(response.strip()) < 2000):  # Short responses that are likely pure system messages
            print("ğŸš« Detected pure system message, skipping this response")
            return ""  # Return empty to trigger conversation end
        
        # If response looks like JSON, try to extract the actual answer
        if response.strip().startswith('{'):
            try:
                # Handle multiple JSON objects in response (streaming format)
                json_objects = []
                lines = response.strip().split('\n')
                
                for line in lines:
                    line = line.strip()
                    if line.startswith('data: '):
                        line = line[6:]  # Remove 'data: ' prefix
                    
                    if line and line.startswith('{') and line.endswith('}'):
                        try:
                            json_obj = json.loads(line)
                            json_objects.append(json_obj)
                        except json.JSONDecodeError:
                            continue
                
                # If no JSON objects found, try parsing the entire response
                if not json_objects:
                    try:
                        json_objects = [json.loads(response)]
                    except json.JSONDecodeError:
                        pass
                
                # Extract meaningful content from JSON objects
                meaningful_content = ""
                
                for json_obj in json_objects:
                    # Skip system messages
                    if json_obj.get('msg_type') in ['time_capsule_recall', 'conversation_summary', 'system_message']:
                        continue
                    
                    # Extract content from various possible fields
                    content_fields = [
                        'tool_output_content',
                        'content', 
                        'answer',
                        'message',
                        'text',
                        'response'
                    ]
                    
                    for field in content_fields:
                        if field in json_obj and json_obj[field]:
                            content = str(json_obj[field])
                            
                            # Clean up escape characters
                            content = content.replace('\\n', '\n').replace('\\"', '"').replace('\\t', '\t')
                            
                            # Filter out evaluation-related content
                            evaluation_keywords = [
                                'ç”¨æˆ·ç¼–å†™çš„ä¿¡æ¯',
                                'ç”¨æˆ·ç”»åƒä¿¡æ¯', 
                                'ç”¨æˆ·è®°å¿†ç‚¹ä¿¡æ¯',
                                'é¿å…ä½¿ç”¨éšç§å’Œæ•æ„Ÿä¿¡æ¯',
                                'ä»¥ä¸‹ä¿¡æ¯æ¥æºäºç”¨æˆ·ä¸ä½ å¯¹è¯',
                                'wraped_text',
                                'origin_search_results'
                            ]
                            
                            if not any(keyword in content for keyword in evaluation_keywords):
                                # Look for "ç­”æ¡ˆï¼š" pattern and extract content after it
                                if "ç­”æ¡ˆï¼š" in content:
                                    answer_part = content.split("ç­”æ¡ˆï¼š", 1)[1]
                                    answer_part = answer_part.replace("å‚è€ƒä¾æ®ï¼š", "").replace("ä¾æ®æ¥æºï¼š", "")
                                    meaningful_content = answer_part.strip()
                                    break
                                elif len(content.strip()) > 10:  # Substantial content
                                    meaningful_content = content.strip()
                                    break
                
                if meaningful_content:
                    print(f"âœ… Extracted from JSON: {meaningful_content[:80]}...")
                    return meaningful_content
                    
            except Exception as e:
                print(f"âš ï¸ JSON parsing failed: {str(e)}")
        
        # Handle streaming format patterns - enhanced for stream_plugin_finish
        if '"msg_type":"stream_plugin_finish"' in response:
            try:
                import re
                # Try multiple patterns to extract content
                patterns = [
                    r'"tool_output_content":"([^"]+)"',
                    r'"content":"([^"]+)"',
                    r'"answer":"([^"]+)"',
                    r'"text":"([^"]+)"'
                ]
                
                for pattern in patterns:
                    match = re.search(pattern, response)
                    if match:
                        content = match.group(1)
                        content = content.replace('\\n', '\n').replace('\\"', '"').replace('\\t', '\t')
                        
                        # Filter out evaluation content
                        if not any(keyword in content for keyword in [
                            'ç”¨æˆ·ç¼–å†™çš„ä¿¡æ¯', 'ç”¨æˆ·ç”»åƒä¿¡æ¯', 'ç”¨æˆ·è®°å¿†ç‚¹ä¿¡æ¯',
                            'wraped_text', 'origin_search_results'
                        ]):
                            if "ç­”æ¡ˆï¼š" in content:
                                answer_part = content.split("ç­”æ¡ˆï¼š", 1)[1]
                                answer_part = answer_part.replace("å‚è€ƒä¾æ®ï¼š", "").replace("ä¾æ®æ¥æºï¼š", "")
                                cleaned_answer = answer_part.strip()
                                if len(cleaned_answer) > 5:  # Ensure substantial content
                                    print(f"âœ… Extracted from stream_plugin_finish: {cleaned_answer[:80]}...")
                                    return cleaned_answer
                            elif len(content.strip()) > 5:  # Substantial content
                                print(f"âœ… Extracted from stream_plugin_finish: {content.strip()[:80]}...")
                                return content.strip()
                            
                # If no patterns matched, try to parse the JSON directly
                try:
                    json_data = json.loads(response)
                    data_field = json_data.get('data', {})
                    if isinstance(data_field, str):
                        # Sometimes data is a JSON string
                        try:
                            data_obj = json.loads(data_field)
                            tool_output = data_obj.get('tool_output_content', '')
                            if tool_output and len(tool_output.strip()) > 5:
                                print(f"âœ… Extracted from nested JSON: {tool_output[:80]}...")
                                return tool_output.strip()
                        except:
                            pass
                except:
                    pass
                    
            except Exception as e:
                print(f"âš ï¸ Stream plugin parsing failed: {str(e)}")
                pass
        
        # Handle plain text with "ç­”æ¡ˆï¼š" pattern
        if "ç­”æ¡ˆï¼š" in response and not any(keyword in response for keyword in [
            'ç”¨æˆ·ç¼–å†™çš„ä¿¡æ¯', 'ç”¨æˆ·ç”»åƒä¿¡æ¯', 'ç”¨æˆ·è®°å¿†ç‚¹ä¿¡æ¯'
        ]):
            answer_part = response.split("ç­”æ¡ˆï¼š", 1)[1]
            lines = answer_part.split('\n')
            for line in lines:
                line = line.strip()
                if line and not line.startswith('å‚è€ƒä¾æ®ï¼š') and not line.startswith('ä¾æ®æ¥æºï¼š'):
                    return line
        
        # Final fallback - return original if it's clean text
        cleaned = response.strip()
        
        # ğŸ”§ DEBUGGING: Check what content is being filtered
        print(f"ğŸ” CONTENT FILTER DEBUG: Original length: {len(cleaned)} chars")
        print(f"ğŸ” CONTENT FILTER DEBUG: First 200 chars: {cleaned[:200]}...")
        
        # Final filter check for system content (REDUCED STRICTNESS)
        high_priority_system_patterns = [
            '"msg_type":"time_capsule_recall"',
            '"msg_type":"conversation_summary"',
            '"msg_type":"system_message"'
        ]
        
        # Only filter if it's clearly a system message AND short
        if (any(pattern in cleaned for pattern in high_priority_system_patterns) and 
            len(cleaned.strip()) < 1000):  # Only filter short system messages
            print(f"ğŸš« Final filter caught system content pattern, returning empty")
            return ""
        
        # ğŸ”§ NEW: Allow evaluation-related content but warn
        evaluation_patterns = [
            'ç”¨æˆ·ç¼–å†™çš„ä¿¡æ¯', 'ç”¨æˆ·ç”»åƒä¿¡æ¯', 'ç”¨æˆ·è®°å¿†ç‚¹ä¿¡æ¯',
            'wraped_text', 'origin_search_results'
        ]
        
        if any(pattern in cleaned for pattern in evaluation_patterns):
            print(f"âš ï¸ WARNING: Content contains evaluation pattern but allowing it: {cleaned[:100]}...")
            # Don't return empty - let it through with warning
        
        print(f"âœ… Cleaned response: {cleaned[:80]}...")
        return cleaned
        
    except Exception as e:
        print(f"âŒ å“åº”æ¸…ç†å¼‚å¸¸: {str(e)}")
        return original_response.strip() if len(original_response.strip()) < 500 else ""

async def test_coze_plugin_extraction():
    """
    Test function to debug Coze API plugin content extraction
    """
    print("ğŸ§ª Testing Coze API plugin extraction...")
    
    # Test with a simple question that should trigger plugin
    test_message = "åœ°ä¸‹å®¤é˜²æ°´å·ææ­æ¥å®½åº¦ä¸å¤Ÿï¼ŒåŸºå±‚å¤„ç†å¥½åƒä¹Ÿæœ‰é—®é¢˜"
    test_bot_id = "7498244859505999924"  # Default test bot ID
    
    try:
        # Try the HTTP fallback method first
        print("1ï¸âƒ£ Testing HTTP fallback method...")
        result = await call_coze_api_fallback(test_message, test_bot_id)
        print(f"âœ… HTTP fallback result: {result[:200]}...")
        print(f"ğŸ“ Result length: {len(result)} characters")
        
        # Test if result contains substantial content
        if len(result) > 100:
            print("âœ… HTTP fallback appears to work correctly")
        else:
            print("âŒ HTTP fallback returned minimal content")
            
        return result
        
    except Exception as e:
        print(f"âŒ Test failed: {str(e)}")
        return None

# â­ Security and validation functions
def validate_filename(filename: str) -> bool:
    """Validate uploaded filename for security"""
    if not filename:
        return False
    
    # Check for path traversal attempts
    if '..' in filename or '/' in filename or '\\' in filename:
        return False
    
    # Check for dangerous extensions
    if any(filename.lower().endswith(ext) for ext in config.BLOCKED_EXTENSIONS):
        return False
    
    # Check for allowed extensions
    file_ext = os.path.splitext(filename)[1].lower()
    if file_ext not in config.ALLOWED_EXTENSIONS:
        return False
    
    # Check filename length
    if len(filename) > config.MAX_FILENAME_LENGTH:
        return False
    
    return True

def sanitize_user_input(text: str, max_length: int = None) -> str:
    """Sanitize user input to prevent injection attacks"""
    if not text:
        return ""
    
    if max_length is None:
        max_length = config.MAX_INPUT_LENGTH
    
    # Remove null bytes and control characters
    text = ''.join(char for char in text if ord(char) >= 32 or char in '\n\r\t')
    
    # Truncate to max length
    if len(text) > max_length:
        text = text[:max_length] + "...[å†…å®¹æˆªæ–­]"
    
    return text.strip()

def validate_api_url(url: str) -> bool:
    """Validate API URL for security"""
    if not url:
        return False
    
    # Check for valid HTTP/HTTPS URLs
    if not (url.startswith('http://') or url.startswith('https://')):
        return False
    
    # Prevent local network access
    blocked_hosts = ['localhost', '127.0.0.1', '0.0.0.0', '::1']
    blocked_patterns = [r'192\.168\.', r'10\.', r'172\.(1[6-9]|2\d|3[01])\.']
    
    for host in blocked_hosts:
        if host in url.lower():
            return False
    
    for pattern in blocked_patterns:
        if re.search(pattern, url):
            return False
    
    return True

@app.post("/api/convert-docx-to-text")
async def convert_docx_to_text(
    requirement_file: UploadFile = File(...),
):
    """
    Cloud-compatible DOCX to text conversion endpoint
    Provides detailed extraction methods and fallback options
    """
    try:
        if not requirement_file or not requirement_file.filename:
            raise HTTPException(status_code=400, detail="æœªæä¾›æ–‡ä»¶")
        
        if not requirement_file.filename.lower().endswith('.docx'):
            raise HTTPException(status_code=400, detail="ä»…æ”¯æŒDOCXæ ¼å¼æ–‡ä»¶")
        
        # Validate file
        if not validate_filename(requirement_file.filename):
            raise HTTPException(status_code=400, detail="ä¸å®‰å…¨çš„æ–‡ä»¶å")
        
        # Create temporary file
        with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp_file:
            try:
                content = await requirement_file.read()
                
                if len(content) > config.MAX_FILE_SIZE:
                    raise HTTPException(status_code=413, detail="æ–‡ä»¶è¿‡å¤§ï¼Œè¯·ä½¿ç”¨å°äº10MBçš„æ–‡ä»¶")
                
                tmp_file.write(content)
                tmp_file.flush()
                
                # Try all extraction methods and return best result
                extraction_results = {}
                
                # Method 1: python-docx
                try:
                    result1 = _extract_with_python_docx(tmp_file.name)
                    extraction_results['python_docx'] = {
                        'success': True,
                        'content': result1,
                        'length': len(result1),
                        'method': 'python-docx library'
                    }
                except Exception as e:
                    extraction_results['python_docx'] = {
                        'success': False,
                        'error': str(e),
                        'method': 'python-docx library'
                    }
                
                # Method 2: ZIP+XML Advanced
                try:
                    result2 = _extract_with_zip_xml_advanced(tmp_file.name)
                    extraction_results['zip_xml_advanced'] = {
                        'success': True,
                        'content': result2,
                        'length': len(result2),
                        'method': 'ZIP+XML with namespaces'
                    }
                except Exception as e:
                    extraction_results['zip_xml_advanced'] = {
                        'success': False,
                        'error': str(e),
                        'method': 'ZIP+XML with namespaces'
                    }
                
                # Method 3: ZIP+XML Simple
                try:
                    result3 = _extract_with_zip_xml_simple(tmp_file.name)
                    extraction_results['zip_xml_simple'] = {
                        'success': True,
                        'content': result3,
                        'length': len(result3),
                        'method': 'Simple ZIP+XML parsing'
                    }
                except Exception as e:
                    extraction_results['zip_xml_simple'] = {
                        'success': False,
                        'error': str(e),
                        'method': 'Simple ZIP+XML parsing'
                    }
                
                # Method 4: Raw text extraction
                try:
                    result4 = _extract_raw_text_from_docx(tmp_file.name)
                    extraction_results['raw_extraction'] = {
                        'success': True,
                        'content': result4,
                        'length': len(result4),
                        'method': 'Raw text extraction with regex'
                    }
                except Exception as e:
                    extraction_results['raw_extraction'] = {
                        'success': False,
                        'error': str(e),
                        'method': 'Raw text extraction with regex'
                    }
                
                # Find best result
                best_result = None
                best_method = None
                best_length = 0
                
                for method, result in extraction_results.items():
                    if result['success'] and result['length'] > best_length:
                        best_result = result['content']
                        best_method = method
                        best_length = result['length']
                
                return {
                    "success": best_result is not None,
                    "best_method": best_method,
                    "best_content": best_result,
                    "content_length": best_length,
                    "extraction_ratio": (best_length / len(content) * 100) if len(content) > 0 else 0,
                    "all_methods": extraction_results,
                    "recommendations": _generate_conversion_recommendations(extraction_results, len(content)),
                    "filename": requirement_file.filename,
                    "file_size": len(content)
                }
                
            finally:
                try:
                    if os.path.exists(tmp_file.name):
                        os.unlink(tmp_file.name)
                except:
                    pass
                    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ DOCXè½¬æ¢å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ–‡æ¡£è½¬æ¢å¤±è´¥: {str(e)}")

def _generate_conversion_recommendations(extraction_results: Dict, file_size: int) -> List[str]:
    """Generate recommendations based on extraction results"""
    recommendations = []
    
    successful_methods = [method for method, result in extraction_results.items() if result['success']]
    
    if not successful_methods:
        recommendations.extend([
            "ğŸš¨ æ‰€æœ‰æå–æ–¹æ³•å‡å¤±è´¥ï¼Œå»ºè®®:",
            "1. ä½¿ç”¨Microsoft Wordæ‰“å¼€æ–‡æ¡£ï¼Œå¦å­˜ä¸º.txtæ ¼å¼",
            "2. æ£€æŸ¥æ–‡æ¡£æ˜¯å¦åŒ…å«å¤æ‚çš„å›¾ç‰‡ã€è¡¨æ ¼æˆ–ç‰¹æ®Šæ ¼å¼",
            "3. å°è¯•å¤åˆ¶æ–‡æ¡£å†…å®¹ï¼Œç›´æ¥ç²˜è´´åˆ°è¯„ä¼°å¹³å°çš„æ–‡æœ¬æ¡†ä¸­",
            "4. æ£€æŸ¥æ–‡æ¡£æ˜¯å¦æŸåæˆ–ä½¿ç”¨äº†ä¸å…¼å®¹çš„æ ¼å¼"
        ])
    elif len(successful_methods) == 1:
        best_method = successful_methods[0]
        best_result = extraction_results[best_method]
        extraction_ratio = best_result['length'] / file_size * 100 if file_size > 0 else 0
        
        if extraction_ratio < 5:
            recommendations.extend([
                f"âš ï¸ æå–ç‡è¾ƒä½ ({extraction_ratio:.1f}%)ï¼Œå»ºè®®:",
                "1. æ–‡æ¡£å¯èƒ½åŒ…å«å¤§é‡å›¾ç‰‡æˆ–è¡¨æ ¼ï¼Œæå–çš„ä¸»è¦æ˜¯æ–‡æœ¬å†…å®¹",
                "2. ä½¿ç”¨Wordå¦å­˜ä¸º.txtæ ¼å¼å¯èƒ½è·å¾—æ›´å¥½æ•ˆæœ",
                "3. æ£€æŸ¥æå–çš„å†…å®¹æ˜¯å¦åŒ…å«ä¸»è¦ä¿¡æ¯"
            ])
        elif extraction_ratio < 15:
            recommendations.append("âœ… æå–æˆåŠŸï¼Œä½†å†…å®¹ç›¸å¯¹è¾ƒå°‘ï¼Œå»ºè®®æ£€æŸ¥æ˜¯å¦æå–äº†ä¸»è¦ä¿¡æ¯")
        else:
            recommendations.append("âœ… æå–æˆåŠŸï¼Œå†…å®¹ä¸°å¯Œï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨")
    else:
        recommendations.append("âœ… å¤šç§æ–¹æ³•æå–æˆåŠŸï¼Œæ–‡æ¡£å¤„ç†è‰¯å¥½")
    
    # Cloud deployment specific recommendations
    recommendations.extend([
        "",
        "ğŸ’¡ äº‘ç¯å¢ƒéƒ¨ç½²å»ºè®®:",
        "1. å¦‚æœåœ¨äº‘ç«¯é‡åˆ°é—®é¢˜ï¼Œä¼˜å…ˆä½¿ç”¨.txtæ ¼å¼",
        "2. ä¿æŒæ–‡æ¡£å†…å®¹ç®€æ´ï¼Œé¿å…è¿‡äºå¤æ‚çš„æ ¼å¼",
        "3. å®šæœŸéªŒè¯æ–‡æ¡£å¤„ç†åŠŸèƒ½æ˜¯å¦æ­£å¸¸"
    ])
    
    return recommendations

@app.post("/api/enhanced-document-processing")
async def enhanced_document_processing(
    requirement_file: UploadFile = File(None),
    requirement_text: str = Form(None)
):
    """
    Enhanced document processing with cloud compatibility diagnostics
    """
    try:
        result = {
            "document_processing": {},
            "cloud_compatibility": {},
            "performance_metrics": {},
            "recommendations": []
        }
        
        if requirement_file and requirement_file.filename:
            # Process file with enhanced diagnostics
            start_time = time.time()
            
            try:
                # Check system environment
                result["cloud_compatibility"] = {
                    "python_docx_available": True,
                    "zipfile_available": True,
                    "xml_parser_available": True,
                    "temp_file_access": True
                }
                
                # Test dependencies
                try:
                    from docx import Document
                    result["cloud_compatibility"]["python_docx_available"] = True
                except ImportError:
                    result["cloud_compatibility"]["python_docx_available"] = False
                
                try:
                    import zipfile
                    import xml.etree.ElementTree as ET
                    result["cloud_compatibility"]["zipfile_available"] = True
                    result["cloud_compatibility"]["xml_parser_available"] = True
                except ImportError:
                    result["cloud_compatibility"]["zipfile_available"] = False
                    result["cloud_compatibility"]["xml_parser_available"] = False
                
                # Test temp file access
                try:
                    with tempfile.NamedTemporaryFile(delete=True) as test_tmp:
                        test_tmp.write(b"test")
                        result["cloud_compatibility"]["temp_file_access"] = True
                except Exception:
                    result["cloud_compatibility"]["temp_file_access"] = False
                
                # Process document
                processed_content = await process_uploaded_document_improved(requirement_file)
                
                processing_time = time.time() - start_time
                
                result["document_processing"] = {
                    "status": "success" if not processed_content.startswith("é”™è¯¯") else "error",
                    "filename": requirement_file.filename,
                    "file_size": len(await requirement_file.read()),  # Read size for metrics
                    "content_length": len(processed_content),
                    "content_preview": processed_content[:300] + "..." if len(processed_content) > 300 else processed_content,
                    "processing_time": processing_time
                }
                
                # Reset file position after reading size
                await requirement_file.seek(0)
                
                result["performance_metrics"] = {
                    "processing_time_seconds": processing_time,
                    "extraction_rate": "fast" if processing_time < 2 else "normal" if processing_time < 5 else "slow",
                    "extraction_ratio": (len(processed_content) / result["document_processing"]["file_size"] * 100) if result["document_processing"]["file_size"] > 0 else 0
                }
                
                # Generate recommendations
                if result["document_processing"]["status"] == "error":
                    result["recommendations"].extend([
                        "ğŸš¨ æ–‡æ¡£å¤„ç†å¤±è´¥ï¼Œå»ºè®®:",
                        "1. è½¬æ¢ä¸º.txtæ ¼å¼é‡æ–°ä¸Šä¼ ",
                        "2. æ£€æŸ¥æ–‡æ¡£æ˜¯å¦æŸå",
                        "3. ä½¿ç”¨æ–‡æœ¬å†…å®¹ç›´æ¥ç²˜è´´æ–¹å¼"
                    ])
                elif result["performance_metrics"]["extraction_ratio"] < 5:
                    result["recommendations"].extend([
                        "âš ï¸ æå–ç‡è¾ƒä½ï¼Œå»ºè®®:",
                        "1. æ£€æŸ¥æ–‡æ¡£æ˜¯å¦ä¸»è¦åŒ…å«å›¾ç‰‡æˆ–è¡¨æ ¼",
                        "2. è€ƒè™‘ä½¿ç”¨Wordè½¬æ¢ä¸ºçº¯æ–‡æœ¬æ ¼å¼",
                        "3. éªŒè¯æå–çš„å†…å®¹æ˜¯å¦åŒ…å«å…³é”®ä¿¡æ¯"
                    ])
                else:
                    result["recommendations"].append("âœ… æ–‡æ¡£å¤„ç†æˆåŠŸï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨")
                
                # Cloud-specific recommendations
                if not all(result["cloud_compatibility"].values()):
                    result["recommendations"].extend([
                        "",
                        "ğŸŒ äº‘ç¯å¢ƒå…¼å®¹æ€§é—®é¢˜:",
                        "1. æŸäº›ä¾èµ–åº“å¯èƒ½ä¸å¯ç”¨",
                        "2. å»ºè®®ä½¿ç”¨.txtæ ¼å¼ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ",
                        "3. è”ç³»ç®¡ç†å‘˜æ£€æŸ¥æœåŠ¡å™¨é…ç½®"
                    ])
                
            except Exception as e:
                result["document_processing"] = {
                    "status": "error",
                    "error": str(e),
                    "traceback": traceback.format_exc()
                }
        
        elif requirement_text:
            result["document_processing"] = {
                "status": "success",
                "source": "text_input",
                "content_length": len(requirement_text),
                "content_preview": requirement_text[:300] + "..." if len(requirement_text) > 300 else requirement_text
            }
            
            result["recommendations"].append("âœ… æ–‡æœ¬å†…å®¹å¤„ç†æˆåŠŸ")
        
        else:
            result["document_processing"] = {
                "status": "error",
                "error": "æœªæä¾›æ–‡ä»¶æˆ–æ–‡æœ¬å†…å®¹"
            }
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ Enhanced document processing failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¢å¼ºæ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "test":
        # Run test mode
        import asyncio
        asyncio.run(test_coze_plugin_extraction())
    else:
        # Run normal server
        port = find_available_port(config.DEFAULT_PORT)
        print(f"ğŸš€ AI Agentè¯„ä¼°å¹³å°å¯åŠ¨åœ¨ç«¯å£ {port}")
        uvicorn.run(app, host=config.DEFAULT_HOST, port=port) 