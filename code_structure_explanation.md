# AI Evaluation Platform - Detailed Code Structure & Workflow

## Table of Contents
1. [System Architecture](#system-architecture)
2. [Backend Components](#backend-components)
3. [Frontend Components](#frontend-components)
4. [Data Flow](#data-flow)
5. [Key Features & Implementation](#key-features--implementation)
6. [Error Handling & Edge Cases](#error-handling--edge-cases)
7. [Prompts & Templates](#prompts--templates)

## System Architecture

### Overview
The AI Evaluation Platform is built using a FastAPI backend and a modern HTML/JavaScript frontend. The system evaluates AI agents through structured conversations and provides detailed analysis and recommendations.

### Core Components
- **Backend**: FastAPI application (`main.py`)
- **Frontend**: HTML templates with JavaScript (`templates/index.html`)
- **API Integration**: DeepSeek API for AI-powered analysis
- **Database**: SQL database for storing evaluation results

## Backend Components

### 1. API Configuration (`APIConfig` Class)
```python
class APIConfig(BaseModel):
    type: str = Field(default="http")
    url: str = Field(..., description="AI Agent API URL")
    method: str = Field(default="POST")
    headers: Dict[str, str] = Field(default={})
    timeout: int = Field(default=30)
    agentId: Optional[str] = None
    region: Optional[str] = "global"
    botId: Optional[str] = None
    botVersion: Optional[str] = None
```

### 2. Evaluation Request Structure
```python
class EvaluationRequest(BaseModel):
    agent_api: APIConfig
    requirement_doc: Optional[str] = ""
    conversation_scenarios: List[ConversationScenario]
    use_raw_messages: Optional[bool] = False
    coze_bot_id: Optional[str] = None
```

### 3. DeepSeek API Integration
```python
async def call_deepseek_api(prompt: str, max_retries: int = 2) -> str:
    """
    Core function for DeepSeek API interaction
    - Handles authentication
    - Manages retries
    - Processes responses
    """
    headers = {
        "Authorization": f"Bearer {config.DEEPSEEK_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": "deepseek-chat",
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 1000,
        "temperature": config.DEFAULT_TEMPERATURE
    }
```

### 4. AI Improvement Suggestions Generation
```python
async def generate_ai_improvement_suggestions_for_programmers(
    explanations: Dict, 
    evaluation_summary: Dict
) -> List[str]:
    """
    Generates AI-powered improvement suggestions
    - Analyzes evaluation results
    - Creates structured suggestions
    - Handles formatting and validation
    """
```

## Frontend Components

### 1. Report Generation Structure
```javascript
function generateFinalReport(data) {
    const summary = data.evaluation_summary || {};
    const persona = summary.persona || {};
    const usageContext = summary.usage_context || {};
    const goal = summary.goal || {};
    const recommendations = summary.recommendations || data.recommendations || [];
    
    return `
        <div class="final-report-container">
            ${generateOverallScoreCard(summary)}
            ${generateRecommendationsCard(recommendations)}
            ${generateUserPersonaCard(persona, usageContext, goal)}
            ${generateDimensionsCard(summary.dimension_scores_100)}
            ${generateConversationsCard(data.conversation_records || [])}
            ${generateTechDataCard(data)}
        </div>
    `;
}
```

### 2. Recommendations Display
```javascript
function generateRecommendationsCard(recommendations) {
    // Priority handling for different suggestion types
    const aiSuggestions = currentEvaluationData?.ai_improvement_suggestions || [];
    const displayRecommendations = aiSuggestions.length > 0 ? aiSuggestions : recommendations;
    
    // Formatting logic for each suggestion
    return recommendations.map(rec => {
        const lines = rec.split('\n');
        const formattedLines = lines.map(line => {
            if (line.startsWith('é—®é¢˜ï¼š')) {
                return `<h6 class="mb-2 text-primary">${line}</h6>`;
            } else if (line.startsWith('æ–¹æ¡ˆï¼š')) {
                return `<p class="mb-2">${line}</p>`;
            } else if (line.startsWith('é¢„æœŸï¼š')) {
                return `<p class="mb-3 text-info"><small>${line}</small></p>`;
            }
        }).join('');
    });
}
```

### 3. Styling and Layout
```css
/* Core styling for recommendations */
.recommendations-container {
    max-height: 500px;
    overflow-y: auto;
}

.recommendation-item {
    margin-bottom: 1rem;
    padding: 1rem;
    border: 1px solid #e2e8f0;
    border-radius: 8px;
    background: white;
    transition: all 0.3s ease;
}

.recommendation-item:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
}
```

## Data Flow

### 1. Evaluation Process
1. User submits evaluation request
2. Backend processes request and initiates evaluation
3. DeepSeek API generates analysis
4. Results are structured and stored
5. Frontend receives and displays data

### 2. Suggestion Generation Flow
```
User Request
    â†“
Evaluation Processing
    â†“
DeepSeek API Analysis
    â†“
Suggestion Generation
    â†“
Data Structuring
    â†“
Frontend Display
```

### 3. Data Structure
```json
{
    "conversation_records": [],
    "recommendations": [],
    "ai_improvement_suggestions": [],
    "evaluation_summary": {
        "overall_score_100": 85.5,
        "dimension_scores_100": {},
        "persona": {},
        "usage_context": {},
        "goal": {}
    },
    "user_persona_info": {}
}
```

## Key Features & Implementation

### 1. Multi-source Suggestion Handling
- Priority order for suggestions:
  1. AI-generated suggestions
  2. Regular recommendations
  3. Fallback suggestions

### 2. Structured Suggestion Format
- Problem identification
- Technical solution
- Expected outcome
- Priority indicators

### 3. Visual Hierarchy
- Color coding for different sections
- Clear typography hierarchy
- Interactive elements
- Responsive design

### 4. Performance Optimizations
- Lazy loading of content
- Efficient DOM updates
- Caching of evaluation data
- Optimized API calls

## Error Handling & Edge Cases

### 1. API Error Handling
```python
try:
    response = await client.post(config.DEEPSEEK_API_URL, 
                               headers=headers, 
                               json=payload)
    response.raise_for_status()
except httpx.HTTPError as e:
    print(f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}")
    if attempt < max_retries - 1:
        continue
    raise
```

### 2. Frontend Error States
```javascript
function generateRecommendationsCard(recommendations) {
    if (!recommendations || recommendations.length === 0) {
        return `
            <div class="card">
                <div class="card-body">
                    <h5 class="card-title">ä¼˜åŒ–å»ºè®®</h5>
                    <p class="text-muted">æš‚æ— å…·ä½“æ”¹è¿›å»ºè®®ï¼Œå½“å‰è¡¨ç°è‰¯å¥½ã€‚</p>
                </div>
            </div>`;
    }
    // ... rest of the function
}
```

### 3. Data Validation
- Input sanitization
- Type checking
- Null value handling
- Default value provision

### 4. Edge Cases
- Empty evaluation results
- API timeout handling
- Network error recovery
- Data format inconsistencies

## Best Practices & Guidelines

### 1. Code Organization
- Clear separation of concerns
- Modular component design
- Consistent naming conventions
- Comprehensive documentation

### 2. Performance Considerations
- Efficient data structures
- Optimized API calls
- Minimal DOM updates
- Resource caching

### 3. Security Measures
- Input validation
- API key protection
- XSS prevention
- CSRF protection

### 4. Maintenance Guidelines
- Regular code reviews
- Performance monitoring
- Error logging
- Documentation updates

## Prompts & Templates

### 1. Evaluation Prompts

#### 1.1 General Dimension Evaluation Prompt
```python
eval_prompt = f"""
ä½ æ˜¯å¯¹è¯è´¨é‡è¯„ä¼°ä¸“å®¶ã€‚è¯·æ ¹æ®ä¸‹æ–¹å¯¹è¯å†…å®¹ï¼Œä»"{dimension_name}"è¿™ä¸ªç»´åº¦å¯¹AIçš„è¡¨ç°è¿›è¡Œè¯„åˆ†ï¼Œæ»¡åˆ†100åˆ†ã€‚

ğŸ“˜ã€åœºæ™¯ä¿¡æ¯ã€‘:
- åœºæ™¯æ ‡é¢˜: {scenario.get('title', 'N/A')}
- èƒŒæ™¯æè¿°: {scenario.get('context', 'N/A')}
- ç”¨æˆ·è§’è‰²: {persona.get('role', 'N/A')}

ğŸ§¾ã€å¯¹è¯å†…å®¹ã€‘:
{conversation_text}

ğŸ“ã€è¯„åˆ†æ ‡å‡†ã€‘:
- 90â€“100åˆ†: è¡¨ç°ä¼˜ç§€ï¼Œå®Œå…¨æ»¡è¶³è¯¥ç»´åº¦è¦æ±‚
- 80â€“89åˆ†: è‰¯å¥½è¡¨ç°ï¼Œç•¥æœ‰æå‡ç©ºé—´
- 60â€“79åˆ†: åŸºæœ¬è¾¾æ ‡ï¼Œä½†å­˜åœ¨æ˜æ˜¾ä¸è¶³
- 40â€“59åˆ†: æœ‰è¾ƒå¤§é—®é¢˜ï¼Œå½±å“ç”¨æˆ·ä½“éªŒ
- 0â€“39åˆ†: è¡¨ç°å¤±è´¥ï¼Œä¸¥é‡åç¦»è¯¥ç»´åº¦è¦æ±‚

ğŸ§ªã€è¯„åˆ†ç¤ºä¾‹ã€‘:

ç¤ºä¾‹1ï¼ˆè¯„åˆ†: 95ï¼‰ï¼š
- ç»´åº¦: å›ç­”å‡†ç¡®æ€§
- å¯¹è¯ï¼š
  ç”¨æˆ·ï¼šæ–½å·¥æ—¶æ··å‡åœŸæŒ¯æ£çš„æ—¶é—´æ€ä¹ˆæ§åˆ¶ï¼Ÿ
  AIï¼šæ ¹æ®ã€ŠGB50204-2015ã€‹ç¬¬6.3.2æ¡ï¼Œæ™®é€šæ··å‡åœŸæŒ¯æ£æ—¶é—´åº”æ§åˆ¶åœ¨10-30ç§’ä¹‹é—´ã€‚
- è¯„ä»·ï¼šå¼•ç”¨è§„èŒƒå‡†ç¡®ï¼Œå†…å®¹å®Œæ•´ã€ä¸“ä¸šã€‚

ç¤ºä¾‹2ï¼ˆè¯„åˆ†: 72ï¼‰ï¼š
- ç»´åº¦: å›ç­”å‡†ç¡®æ€§
- å¯¹è¯ï¼š
  ç”¨æˆ·ï¼šé’¢ç­‹æ­æ¥é•¿åº¦ï¼Ÿ
  AIï¼šé’¢ç­‹æ­æ¥30å…¬åˆ†å°±å¤Ÿäº†ã€‚
- è¯„ä»·ï¼šå›ç­”æ¨¡ç³Šï¼Œæœªå¼•ç”¨å…·ä½“æ ‡å‡†ï¼Œè¯¯å¯¼ç”¨æˆ·ã€‚

ğŸ“ã€è¯·å¡«å†™ã€‘:
è¯„åˆ†ï¼š[0-100]
ç†ç”±ï¼š[åŸºäºç»´åº¦å’Œå¯¹è¯ï¼Œè¯´æ˜ä½ çš„åˆ¤æ–­ä¾æ®]
"""
```
**Usage**: Used to evaluate AI performance in specific dimensions with enhanced few-shot examples for better objectivity

#### 1.2 Answer Correctness Evaluation
```python
evaluation_prompts["answer_correctness"] = f"""
ä½ æ˜¯å»ºç­‘ç±»å¯¹è¯ä¸“å®¶ï¼Œä»»åŠ¡æ˜¯è¯„ä¼°AIå›ç­”çš„å‡†ç¡®æ€§ä¸ä¸“ä¸šæ€§ï¼Œè¯„åˆ†èŒƒå›´ä¸º0â€“100åˆ†ã€‚

{base_context}

ğŸ“šã€è¯„åˆ†æ ‡å‡†ã€‘:
- 90â€“100åˆ†: å›ç­”å®Œæ•´ï¼Œå†…å®¹ä¸“ä¸šï¼Œå¼•ç”¨è§„èŒƒæ¸…æ™°
- 80â€“89åˆ†: å›ç­”å‡†ç¡®ä½†ç•¥ç¼ºç»†èŠ‚æˆ–æœªå¼•ç”¨è§„èŒƒ
- 60â€“79åˆ†: å›ç­”åŸºæœ¬æ­£ç¡®ä½†å­˜åœ¨æ¨¡ç³Šæˆ–è¯¯å¯¼æ€§è¡¨è¾¾
- 40â€“59åˆ†: æ ¸å¿ƒå†…å®¹é”™è¯¯æˆ–ç»“æ„æ··ä¹±
- 0â€“39åˆ†: ä¸¥é‡é”™è¯¯ï¼Œå¯èƒ½äº§ç”Ÿè¯¯å¯¼æˆ–å±é™©

ğŸ“˜ã€ç¤ºä¾‹å‚è€ƒã€‘:

ç¤ºä¾‹1ï¼ˆè¯„åˆ†: 95ï¼‰ï¼š
ç”¨æˆ·ï¼šæ°´æ³¥ç ‚æµ†çš„åšåº¦æ ‡å‡†æ˜¯å¤šå°‘ï¼Ÿ
AIï¼šæ ¹æ®ã€ŠGB50209-2010ã€‹ç¬¬5.2.1æ¡ï¼Œæ™®é€šæ°´æ³¥ç ‚æµ†åšåº¦ä¸€èˆ¬æ§åˆ¶åœ¨15mmå·¦å³ã€‚
è¯„ä»·ï¼šå›ç­”å‡†ç¡®ã€å¼•ç”¨è§„èŒƒæ¸…æ™°ã€‚

ç¤ºä¾‹2ï¼ˆè¯„åˆ†: 68ï¼‰ï¼š
ç”¨æˆ·ï¼šæ··å‡åœŸæŒ¯æ£å¤šä¹…ï¼Ÿ
AIï¼šä¸€åˆ†é’Ÿå·¦å³ã€‚
è¯„ä»·ï¼šæ–¹å‘å¯¹ä½†ä¸ä¸“ä¸šï¼Œç¼ºä¹æ ‡å‡†æ”¯æŒã€‚

ğŸ“ã€è¯·å®Œæˆã€‘:
è¯„åˆ†ï¼š[0-100]
ç†ç”±ï¼š[åŸºäºå‡†ç¡®æ€§è¿›è¡Œè§£é‡Š]
"""
```
**Usage**: Evaluates the accuracy and professionalism of AI responses with domain-specific examples

#### 1.3 Persona Alignment Evaluation
```python
evaluation_prompts["persona_alignment"] = f"""
ä½ æ˜¯ç”¨æˆ·ç”»åƒåŒ¹é…åº¦è¯„ä¼°ä¸“å®¶ï¼Œä»»åŠ¡æ˜¯åˆ¤æ–­AIæ˜¯å¦é‡‡ç”¨äº†ç¬¦åˆè¯¥ç”¨æˆ·è§’è‰²çš„æ²Ÿé€šé£æ ¼ä¸è¡¨è¾¾æ–¹å¼ã€‚

{base_context}

ğŸ“ã€è¯„åˆ†æ ‡å‡†ã€‘:
- 90â€“100åˆ†: å®Œå…¨è´´åˆç”¨æˆ·è§’è‰²ï¼Œè¯­æ°”è‡ªç„¶ä¸“ä¸š
- 80â€“89åˆ†: åŸºæœ¬åŒ¹é…ï¼Œå¶æœ‰ä¸è‡ªç„¶è¡¨è¾¾
- 60â€“79åˆ†: æœ‰æœ¯è¯­ã€è¯­è°ƒç­‰ä¸é€‚é…é—®é¢˜
- 40â€“59åˆ†: æ˜æ˜¾é£æ ¼ä¸ç¬¦
- 0â€“39åˆ†: å®Œå…¨è„±ç¦»è§’è‰²

ğŸ“˜ã€ç¤ºä¾‹å‚è€ƒã€‘:

ç¤ºä¾‹1ï¼ˆè¯„åˆ†: 92ï¼‰ï¼š
ç”¨æˆ·ï¼ˆæ–½å·¥å‘˜ï¼‰ï¼šæ°´æ³¥æ€ä¹ˆå…»æŠ¤ï¼Ÿ
AIï¼šåˆå‡åæ´’æ°´ä¿æŒæ¹¿æ¶¦7å¤©ã€‚
è¯„ä»·ï¼šè¯­æ°”è´´è¿‘ç°åœºï¼Œè¡¨è¾¾ç®€æ´ã€‚

ç¤ºä¾‹2ï¼ˆè¯„åˆ†: 84ï¼‰ï¼š
ç”¨æˆ·ï¼ˆç”²æ–¹ï¼‰ï¼šéœ€è¦é—­æ°´è¯•éªŒå—ï¼Ÿ
AIï¼šè¯·æ ¹æ®GBè§„èŒƒè¿›è¡Œé—­æ°´ã€‚
è¯„ä»·ï¼šè¡¨è¾¾ä¸“ä¸šä½†åç”Ÿç¡¬ã€‚

ğŸ“ã€è¯·å¡«å†™ã€‘:
è¯„åˆ†ï¼š[0-100]
ç†ç”±ï¼š[ç»“åˆè¯­è°ƒã€ç”¨è¯æ˜¯å¦è´´åˆç”¨æˆ·ç”»åƒ]
"""
```
**Usage**: Evaluates how well the AI's communication style matches the user's persona with concrete examples

### 2. Conversation Generation Prompts

#### 2.1 Initial Message Generation
```python
initial_message_prompt = f"""ä½ ç°åœ¨è¦æ‰®æ¼”{role}ï¼Œåœ¨ä»¥ä¸‹åœºæ™¯ä¸­å¼€å§‹ä¸€æ®µå¯¹è¯ï¼š

åœºæ™¯èƒŒæ™¯: {scenario_context}
åœºæ™¯æ ‡é¢˜: {scenario_title}

ä½ çš„è§’è‰²ç‰¹å¾:
- èŒä¸š: {role}
- ç»éªŒæ°´å¹³: {experience_level}  
- æ²Ÿé€šé£æ ¼: {communication_style}
- å·¥ä½œé¢†åŸŸ: {business_domain}

è¯·ç”Ÿæˆä¸€å¥è‡ªç„¶çš„å¼€åœºç™½ï¼Œä½œä¸º{role}å‘AIåŠ©æ‰‹æå‡ºçš„ç¬¬ä¸€ä¸ªé—®é¢˜æˆ–è¯·æ±‚ã€‚
è¦æ±‚ï¼š
1. è¯­è¨€è‡ªç„¶ï¼Œç¬¦åˆ{communication_style}çš„é£æ ¼
2. ä½“ç°{role}çš„ä¸“ä¸šå…³æ³¨ç‚¹
3. ä¸{scenario_title}åœºæ™¯ç›¸å…³
4. é•¿åº¦æ§åˆ¶åœ¨50å­—ä»¥å†…

ç›´æ¥è¾“å‡ºå¯¹è¯å†…å®¹ï¼Œä¸è¦å…¶ä»–è§£é‡Šï¼š"""
```
**Usage**: Generates the first user message in a conversation based on the user's persona and scenario

#### 2.2 Follow-up Message Generation
```python
followup_prompt = f"""ä½ æ˜¯{role}ï¼Œæ­£åœ¨ä¸AIåŠ©æ‰‹è¿›è¡Œä¸“ä¸šå’¨è¯¢å¯¹è¯ã€‚ä»¥ä¸‹æ˜¯å¯¹è¯å†å²ï¼š

{conversation_context}

AIåˆšæ‰çš„å›åº”ï¼š{ai_response}

æ ¹æ®AIçš„å›åº”å’Œä½ çš„ä¸“ä¸šèƒŒæ™¯ï¼Œç”Ÿæˆä¸‹ä¸€å¥è‡ªç„¶çš„è·Ÿè¿›é—®é¢˜ã€‚

è¦æ±‚:
1. åŸºäºAIçš„å…·ä½“å›åº”å†…å®¹è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„è·Ÿè¿›
2. ä½“ç°{role}çš„ä¸“ä¸šå…³æ³¨ç‚¹å’Œæ€ç»´æ–¹å¼
3. è¯­è¨€è‡ªç„¶ï¼Œç¬¦åˆ{communication_style}çš„é£æ ¼
ç›´æ¥è¾“å‡ºå¯¹è¯å†…å®¹ï¼Œä¸è¦å…¶ä»–è§£é‡Šï¼š"""
```
**Usage**: Generates follow-up messages based on the conversation history and AI's previous response

### 3. Improvement Suggestion Prompts

#### 3.1 AI Improvement Suggestions
```python
improvement_prompt = f"""è¯„ä¼°æ¦‚å†µ:
- ç»¼åˆå¾—åˆ†: {evaluation_summary.get('overall_score_100', 75)}/100åˆ†
- è¯„ä¼°ç»´åº¦å¾—åˆ†: {'; '.join(dimension_scores)}
- è¯„ä¼°æ¡†æ¶: {evaluation_summary.get('framework', 'è§„èŒƒæŸ¥è¯¢è¯„ä¼°')}

ä¸»è¦é—®é¢˜åˆ†æ:
{chr(10).join(dimension_issues) if dimension_issues else 'æ€»ä½“è¡¨ç°è‰¯å¥½'}

è¯·æä¾›3-5æ¡å…·ä½“çš„æŠ€æœ¯æ”¹è¿›å»ºè®®ï¼Œæ¯æ¡å»ºè®®å¿…é¡»åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªéƒ¨åˆ†ï¼š
1. é—®é¢˜æè¿°ï¼šæ˜ç¡®æŒ‡å‡ºéœ€è¦æ”¹è¿›çš„å…·ä½“é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯ä¸æç¤ºè¯ç›¸å…³çš„é—®é¢˜
2. è§£å†³æ–¹æ¡ˆï¼šæä¾›å…·ä½“å¯è¡Œçš„æŠ€æœ¯æ–¹æ¡ˆï¼ŒåŒ…æ‹¬å…·ä½“çš„æç¤ºè¯ä¼˜åŒ–å»ºè®®
3. é¢„æœŸæ•ˆæœï¼šè¯´æ˜æ”¹è¿›åçš„é¢„æœŸæ•ˆæœ

é‡ç‚¹å…³æ³¨ä»¥ä¸‹æ–¹é¢ï¼š
- æç¤ºè¯ç»“æ„å’Œæ ¼å¼ä¼˜åŒ–
- ä¸Šä¸‹æ–‡ç®¡ç†å’Œå†å²å¯¹è¯å¤„ç†
- è§’è‰²å®šä¹‰å’Œä»»åŠ¡æŒ‡ä»¤çš„æ¸…æ™°åº¦
- ä¸“ä¸šé¢†åŸŸçŸ¥è¯†çš„å¼•å¯¼æ–¹å¼
- å¤šè½®å¯¹è¯çš„è¿è´¯æ€§ç»´æŠ¤
- é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæƒ…å†µçš„æç¤ºè¯è®¾è®¡

æ ¼å¼è¦æ±‚ï¼š
æ¯æ¡å»ºè®®å¿…é¡»æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
é—®é¢˜ï¼šxxx
æ–¹æ¡ˆï¼šxxx
é¢„æœŸï¼šxxx

æ”¹è¿›å»ºè®®ï¼š"""
```
**Usage**: Generates AI-powered improvement suggestions based on evaluation results with structured format

### 4. Fallback Prompts

#### 4.1 Fallback Response Generation
```python
fallback_prompt = f"""ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„{user_persona_info.get('user_persona', {}).get('role', 'åŠ©æ‰‹')}ï¼Œè¯·å¯¹ä»¥ä¸‹é—®é¢˜ç»™å‡ºç®€çŸ­ä½†æœ‰ç”¨çš„å›å¤ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{current_user_message}
å›å¤è¦æ±‚ï¼š
1. ç›´æ¥å›ç­”é—®é¢˜ï¼Œä¸è¦è¯´"æˆ‘ä¸çŸ¥é“"
2. ä¿æŒä¸“ä¸šä½†å‹å¥½çš„è¯­è°ƒ
3. å¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯ï¼Œå¯ä»¥ç®€å•è¯¢é—®
4. å›å¤æ§åˆ¶åœ¨50å­—ä»¥å†…

è¯·ç›´æ¥ç»™å‡ºå›å¤ï¼š"""
```
**Usage**: Generates a fallback response when the primary AI response is empty or invalid

### 5. Scenario Generation Prompts

#### 5.1 Dynamic Scenario Generation
```python
scenario_prompt = f"""åŸºäºä»¥ä¸‹ç”¨æˆ·ç”»åƒï¼Œç”Ÿæˆ1ä¸ªçœŸå®ã€å…·ä½“çš„å¯¹è¯åœºæ™¯ï¼š

ç”¨æˆ·è§’è‰²ï¼š{role}
ä¸šåŠ¡é¢†åŸŸï¼š{business_domain}
ä¸»è¦ä½¿ç”¨åœºæ™¯ï¼š{', '.join(primary_scenarios)}
æ²Ÿé€šé£æ ¼ï¼š{persona.get('communication_style', 'ä¸“ä¸šç›´æ¥')}
å·¥ä½œç¯å¢ƒï¼š{persona.get('work_environment', 'ä¸“ä¸šç¯å¢ƒ')}

è¯·ç”ŸæˆJSONæ ¼å¼çš„åœºæ™¯ï¼š
{{
  "title": "å…·ä½“åœºæ™¯åç§°",
  "context": "è¯¦ç»†çš„ä¸šåŠ¡èƒŒæ™¯å’Œæƒ…å¢ƒæè¿°ï¼Œåæ˜ {role}åœ¨{business_domain}ä¸­çš„å…¸å‹å·¥ä½œæƒ…å†µ",
  "user_profile": "ç”¨æˆ·åœ¨æ­¤åœºæ™¯ä¸‹çš„å…·ä½“èº«ä»½å’Œéœ€æ±‚"
}}

è¦æ±‚ï¼š
1. åœºæ™¯è¦çœŸå®åæ˜ {role}åœ¨{business_domain}ä¸­çš„å…¸å‹å·¥ä½œæƒ…å†µ
2. åœºæ™¯è¦æœ‰æ˜ç¡®çš„ä¸šåŠ¡èƒŒæ™¯å’Œå…·ä½“æƒ…å¢ƒ
3. é¿å…è¿‡äºå¤æ‚çš„æŠ€æœ¯ç»†èŠ‚ï¼Œä½†è¦è¶³å¤Ÿå…·ä½“

ç›´æ¥è¾“å‡ºJSONå¯¹è±¡ï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼š"""
```
**Usage**: Generates dynamic conversation scenarios based on user persona and business context

### 6. ğŸ¯ Tricky Test Mode Prompts (NEW Feature)

#### 6.1 Tricky Initial Message Generation
```python
async def generate_quick_initial_message(scenario: Dict, user_persona_info: Dict, is_tricky_test: bool = False) -> str:
    """
    Generates initial messages with optional tricky test mode for edge-case scenarios
    """
    
    if is_tricky_test:
        tricky_prompt = f"""ä½ ç°åœ¨è¦æ‰®æ¼”{role}ï¼Œä½†ç°åœ¨éœ€è¦æå‡ºä¸€äº›åˆé’»ä½†åˆç†çš„é—®é¢˜ã€‚

åœºæ™¯èƒŒæ™¯: {scenario_context}
ä½ çš„è§’è‰²: {role}
ä¸šåŠ¡é¢†åŸŸ: {business_domain}

è¯·ç”Ÿæˆä¸€ä¸ªå…³äºæç«¯æˆ–éå¸¸è§„å»ºç­‘åœºæ™¯çš„é—®é¢˜ï¼Œä¾‹å¦‚ï¼š
- æç«¯æ°”å€™æ¡ä»¶ä¸‹çš„å»ºç­‘é—®é¢˜ï¼ˆå—æã€æ²™æ¼ ã€é«˜æµ·æ‹”ï¼‰
- å†å²å»ºç­‘æ”¹é€ çš„ç‰¹æ®Šè¦æ±‚
- ç‰¹æ®Šææ–™æˆ–å·¥è‰ºçš„åº”ç”¨
- éæ ‡å‡†è§„èŒƒçš„è¾¹ç•Œæƒ…å†µ

è¦æ±‚ï¼š
1. é—®é¢˜è¦åˆé’»ä½†ç°å®åˆç†ï¼Œä¸æ˜¯å¤©é©¬è¡Œç©º
2. åº”è¯¥æ˜¯æ ‡å‡†è§„èŒƒæ•°æ®åº“ä¸­ä¸å¤ªå®¹æ˜“æ‰¾åˆ°ç­”æ¡ˆçš„é—®é¢˜
3. ç¬¦åˆ{role}çš„ä¸“ä¸šèƒŒæ™¯å’Œå…³æ³¨ç‚¹
4. é•¿åº¦æ§åˆ¶åœ¨30-50å­—

ç›´æ¥è¾“å‡ºé—®é¢˜ï¼Œä¸è¦å…¶ä»–è§£é‡Šï¼š"""

        # Fallback tricky questions for different domains
        tricky_fallbacks = {
            "å»ºç­‘å·¥ç¨‹": [
                "å—æç§‘è€ƒç«™å»ºè®¾ä¸­ï¼Œæ··å‡åœŸåœ¨-40Â°Cç¯å¢ƒä¸‹çš„æµ‡ç­‘å·¥è‰ºæœ‰ä»€ä¹ˆç‰¹æ®Šè¦æ±‚ï¼Ÿ",
                "æµ·æ‹”4500ç±³é«˜åŸåœ°åŒºçš„é’¢ç­‹æ··å‡åœŸç»“æ„ï¼Œéœ€è¦è€ƒè™‘å“ªäº›å¤§æ°”å‹åŠ›å½±å“ï¼Ÿ",
                "å†å²ä¿æŠ¤å»ºç­‘ä¸­ï¼Œå¦‚ä½•åœ¨ä¸ç ´ååŸæœ‰ç»“æ„çš„å‰æä¸‹å¢åŠ æŠ—éœ‡æªæ–½ï¼Ÿ"
            ],
            "é‡‘èé“¶è¡Œ": [
                "æ•°å­—è´§å¸è·¨å¢ƒäº¤æ˜“åœ¨åˆ¶è£å›½å®¶çš„åˆè§„é£é™©å¦‚ä½•è¯„ä¼°ï¼Ÿ",
                "AIé‡åŒ–äº¤æ˜“åœ¨æç«¯å¸‚åœºæ³¢åŠ¨æœŸé—´çš„é£æ§ç­–ç•¥åº”è¯¥å¦‚ä½•è°ƒæ•´ï¼Ÿ",
                "å°å›½å¤®è¡Œæ•°å­—è´§å¸æ”¿ç­–å¯¹è·¨å›½é“¶è¡Œä¸šåŠ¡çš„å½±å“å¦‚ä½•ï¼Ÿ"
            ],
            "åŒ»ç–—å¥åº·": [
                "åœ¨å¤ªç©ºç¯å¢ƒä¸‹ï¼Œè¯ç‰©çš„ä»£è°¢æœºåˆ¶ä¼šå‘ç”Ÿä»€ä¹ˆæ”¹å˜ï¼Ÿ",
                "åŸºå› ç¼–è¾‘æŠ€æœ¯åœ¨æ²»ç–—ç½•è§é—ä¼ ç—…æ—¶çš„ä¼¦ç†è¾¹ç•Œåœ¨å“ªé‡Œï¼Ÿ",
                "æåœ°æ¢é™©é˜Ÿå‘˜çš„å¿ƒç†å¥åº·è¯„ä¼°æ ‡å‡†æœ‰ä½•ç‰¹æ®Šæ€§ï¼Ÿ"
            ],
            "æ•™è‚²åŸ¹è®­": [
                "AIå¯¼å¸ˆåœ¨æƒ…æ„Ÿæ”¯æŒæ–¹é¢èƒ½å¦å®Œå…¨æ›¿ä»£äººç±»æ•™å¸ˆï¼Ÿ",
                "å…ƒå®‡å®™æ•™å­¦ç¯å¢ƒå¯¹å­¦ä¹ è€…è®¤çŸ¥å‘å±•çš„é•¿æœŸå½±å“å¦‚ä½•ï¼Ÿ",
                "å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„è®¤çŸ¥è´Ÿè·ç†è®ºåº”ç”¨æœ‰ä»€ä¹ˆå±€é™æ€§ï¼Ÿ"
            ]
        }
```
**Usage**: Generates edge-case questions targeting scenarios not covered by standard databases

#### 6.2 Tricky Follow-up Message Generation
```python
async def generate_next_message_based_on_response(
    scenario_info: Dict, 
    user_persona_info: Dict, 
    conversation_history: List[Dict], 
    ai_response: str,
    is_tricky_test: bool = False
) -> str:
    """
    Generates follow-up messages with continuation of tricky scenarios
    """
    
    if is_tricky_test:
        tricky_followup_prompt = f"""ä½ æ˜¯{role}ï¼Œåˆšæ‰æå‡ºäº†ä¸€ä¸ªå…³äºæç«¯åœºæ™¯çš„é—®é¢˜ã€‚

å¯¹è¯å†å²ï¼š
{conversation_context}

AIçš„å›åº”ï¼š{ai_response}

ç°åœ¨è¯·åŸºäºAIçš„å›åº”ï¼Œç»§ç»­æå‡ºä¸€ä¸ªæ›´æ·±å…¥çš„åˆé’»é—®é¢˜ï¼Œè¦æ±‚ï¼š
1. å»¶ç»­ä¹‹å‰çš„æç«¯åœºæ™¯è®¾å®š
2. åŸºäºAIçš„å…·ä½“å›åº”å†…å®¹è¿›è¡Œé’ˆå¯¹æ€§è¿½é—®
3. æ¶‰åŠæ›´åŠ è¾¹ç¼˜çš„æŠ€æœ¯ç»†èŠ‚æˆ–ç‰¹æ®Šæƒ…å†µ
4. ä¾‹å¦‚ï¼šå¦‚æœä¹‹å‰é—®çš„æ˜¯æå¯’å»ºç­‘ï¼Œç°åœ¨å¯ä»¥é—®ç›¸å…³çš„ææ–™ç‰¹æ€§ã€æ–½å·¥å‘¨æœŸç­‰

ç›´æ¥è¾“å‡ºé—®é¢˜ï¼Œä¸è¦è§£é‡Šï¼š"""

        # Enhanced tricky scenarios focusing on extreme conditions
        tricky_scenarios = [
            "æç«¯å¤©æ°”æ¡ä»¶å»ºç­‘",
            "å†å²å»ºç­‘ä¿æŠ¤æ”¹é€ ", 
            "ç‰¹æ®Šææ–™åº”ç”¨",
            "éæ ‡å‡†ç¯å¢ƒæ–½å·¥",
            "è·¨æ–‡åŒ–å»ºç­‘æ ‡å‡†",
            "å¯æŒç»­å»ºç­‘åˆ›æ–°"
        ]
```
**Usage**: Continues extreme scenario questioning based on AI's previous responses

#### 6.3 Tricky Test Domain-Specific Examples

**Construction/Engineering Domain:**
- Antarctic research station construction requirements
- High-altitude concrete pouring considerations  
- Historical building seismic retrofitting
- Desert climate construction challenges
- Underwater structure maintenance
- Space habitat construction principles

**Banking/Finance Domain:**
- Cryptocurrency regulation in sanctions
- AI trading extreme market conditions
- Central bank digital currency impacts
- Cross-border payment compliance
- Quantum computing encryption threats
- Decentralized finance risk assessment

**Healthcare Domain:**
- Space medicine drug metabolism
- Gene editing ethical boundaries
- Arctic expedition health protocols
- Rare disease treatment protocols
- AI diagnosis accuracy limitations
- Pandemic response optimization

**Education Domain:**
- AI tutor emotional intelligence
- Metaverse learning cognitive effects
- Multilingual cognitive load theory
- Remote learning effectiveness
- Personalized AI curriculum design
- Virtual reality training safety

### 7. Frontend Integration with Prompt System

#### 7.1 Tricky Test Toggle UI Implementation
```javascript
// Visual feedback when toggling tricky test mode
function handleTrickyTestToggle(checkboxId) {
    const checkbox = document.getElementById(checkboxId);
    const configSection = checkbox.closest('.config-section');
    
    if (checkbox.checked) {
        configSection.classList.add('tricky-test-active');
        // Add visual indicator
        const indicator = document.createElement('div');
        indicator.className = 'tricky-test-indicator';
        indicator.innerHTML = 'âš¡';
        indicator.title = 'åˆé’»æµ‹è¯•æ¨¡å¼æ¿€æ´»';
        configSection.appendChild(indicator);
        showTrickyTestWarning();
    } else {
        configSection.classList.remove('tricky-test-active');
        // Remove indicator
    }
}
```
**Purpose**: Provides immediate visual feedback when tricky test mode is enabled

#### 7.2 Form Data Integration
```javascript
// Form submission with tricky test parameter
if (selectedProjectScenario === 'specification-query') {
    formData.append('enable_turn_control', document.getElementById('enableTurnControl').checked);
    formData.append('is_tricky_test', document.getElementById('enableTrickyTest').checked);
    endpoint = '/api/evaluate-agent-specification-query';
} else {
    // Dynamic evaluation path
    formData.append('is_tricky_test', document.getElementById('enableTrickyTestDynamic').checked);
    endpoint = '/api/evaluate-agent-dynamic';
}
```
**Purpose**: Passes tricky test mode selection to backend API endpoints

#### 7.3 Results Display Enhancement
```javascript
function generateOverallScoreCard(summary) {
    const isTrickyMode = summary.is_tricky_test || false;
    const trickyBadge = isTrickyMode ? 
        `<span class="badge bg-warning ms-2" title="ä½¿ç”¨äº†åˆé’»æµ‹è¯•æ¨¡å¼">
            <i class="fas fa-bolt"></i> åˆé’»æ¨¡å¼
        </span>` : '';
    
    // Display tricky mode indicator in results
    return `<div class="card">
        <h3>ç»¼åˆå¾—åˆ†æŠ¥å‘Š${trickyBadge}</h3>
        <p>æœ€ç»ˆå¾—åˆ†ï¼ˆ100åˆ†åˆ¶ï¼‰${isTrickyMode ? ' - æç«¯åœºæ™¯æµ‹è¯•' : ''}</p>
        // ... rest of the report
    </div>`;
}
```
**Purpose**: Clearly indicates when tricky test mode was used in evaluation results

## Key Improvements in Enhanced Prompts

### 1. **Few-Shot Examples**
- Added concrete examples with scores and explanations
- Improved evaluation consistency and objectivity
- Reduced ambiguity in scoring criteria

### 2. **Visual Structure**
- Used emojis and formatting for better readability
- Clear section headers with visual indicators
- Structured layout for easier comprehension

### 3. **Unified 0-100 Scoring**
- Consistent scoring scale across all evaluation dimensions
- More granular scoring for better differentiation
- Aligned with system's 100-point evaluation framework

### 4. **Domain-Specific Context**
- Construction/engineering examples for better relevance
- Role-specific language and terminology
- Industry-appropriate scenarios and standards

### 5. **Enhanced Clarity**
- Clearer instructions and requirements
- Specific formatting guidelines
- Reduced ambiguity in prompt interpretation

### 6. **ğŸ¯ Tricky Test Mode Innovation**
- Edge-case scenario generation for boundary testing
- Domain-specific extreme situation prompts
- Intelligent follow-up question continuity
- Visual UI feedback and clear result indication
- Comprehensive fallback mechanisms for different industries

## Prompt System Architecture

### 1. **Hierarchical Prompt Structure**
```
Evaluation Framework
â”œâ”€â”€ Dimension-Specific Prompts
â”‚   â”œâ”€â”€ Answer Correctness
â”‚   â”œâ”€â”€ Persona Alignment
â”‚   â”œâ”€â”€ Goal Alignment
â”‚   â””â”€â”€ Specification Citation
â”œâ”€â”€ Conversation Generation
â”‚   â”œâ”€â”€ Initial Message Generation
â”‚   â”œâ”€â”€ Follow-up Generation
â”‚   â””â”€â”€ ğŸ¯ Tricky Test Generation
â”œâ”€â”€ Improvement Suggestions
â”‚   â”œâ”€â”€ Technical Recommendations
â”‚   â””â”€â”€ Prompt Optimization
â””â”€â”€ Fallback & Error Handling
    â”œâ”€â”€ Response Validation
    â””â”€â”€ Alternative Generation
```

### 2. **Parameter Flow Architecture**
```
Frontend UI Toggle â†’ Form Submission â†’ Backend API â†’ 
Prompt Selection â†’ DeepSeek API â†’ Response Processing â†’ 
Result Display with Mode Indication
```

### 3. **Quality Assurance Mechanisms**
- **Prompt Validation**: All prompts include explicit output format requirements
- **Fallback Systems**: Multiple backup prompts for each scenario type
- **Context Preservation**: Conversation history maintained across all prompt types
- **Domain Adaptation**: Prompts automatically adjust based on user persona and business domain
- **Error Recovery**: Graceful degradation when AI generation fails

### 4. **Performance Optimization**
- **Prompt Caching**: Reusable prompt templates with dynamic variable injection
- **Batch Processing**: Multiple evaluations can share prompt infrastructure
- **Async Processing**: Non-blocking prompt generation and evaluation
- **Resource Management**: Prompt complexity balanced with response time requirements 